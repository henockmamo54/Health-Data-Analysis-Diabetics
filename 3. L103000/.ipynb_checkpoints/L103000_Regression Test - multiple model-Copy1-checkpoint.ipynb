{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original=pd.read_csv('../_xlable4_withNa_AllColumns.txt')\n",
    "y_original=pd.read_csv('../_targelable4_withNa_AllColumns.txt')\n",
    "\n",
    "\n",
    "x_original['max']=np.min(x_original[['FIELD_6','FIELD_7']],axis=1)\n",
    "x_original=x_original.drop(columns=['FIELD_6','FIELD_7'])\n",
    "x_original=x_original.query('FIELD_16 != 1 and FIELD_23 != 1')\n",
    "\n",
    "y_original['max']=np.min(y_original[['FIELD_6','FIELD_7']],axis=1)\n",
    "y_original=y_original.drop(columns=['FIELD_6','FIELD_7'])\n",
    "y_original=y_original.query('FIELD_16 != 1 and FIELD_23 != 1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159381, 407)\n",
      "(159381, 407)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=x_original[['Unnamed: 0','L103300', 'FIELD_33', 'L100700', 'SEX', 'L190300', 'L190400', 'FIELD_38', 'L190500', \n",
    "              'FIELD_32', 'S000300', 'L103000', 'FIELD_41', 'FIELD_31', 'L101700', 'FIELD_40']]\n",
    "\n",
    "y=y_original[['Unnamed: 0','L103000', ]]\n",
    "\n",
    "print(x_original.shape)\n",
    "print(y_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128201, 18)\n"
     ]
    }
   ],
   "source": [
    "data= pd.merge(x,y, how='inner',left_on='Unnamed: 0', right_on='Unnamed: 0')\n",
    "data=data.dropna(). reset_index()\n",
    "\n",
    "# data=data[data.FIELD_15!=1]\n",
    "# data=data[data.FIELD_17!=1]\n",
    "# data=data[data.FIELD_22!=1]\n",
    "# data=data[data.FIELD_24!=1]\n",
    "\n",
    "# data['max']=np.min(data[['FIELD_6','FIELD_7']],axis=1)\n",
    "# data=data.drop(columns=['FIELD_6','FIELD_7'])\n",
    "# data=data.query('FIELD_16 != 1 and FIELD_23 != 1')\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128201, 18)\n",
      "Index(['index', 'Unnamed: 0', 'L103300', 'FIELD_33', 'L100700', 'SEX',\n",
      "       'L190300', 'L190400', 'FIELD_38', 'L190500', 'FIELD_32', 'S000300',\n",
      "       'L103000_x', 'FIELD_41', 'FIELD_31', 'L101700', 'FIELD_40',\n",
      "       'L103000_y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>L103300</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>L100700</th>\n",
       "      <th>SEX</th>\n",
       "      <th>L190300</th>\n",
       "      <th>L190400</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>L190500</th>\n",
       "      <th>FIELD_32</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>FIELD_41</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>L101700</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>L103000_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.24</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  L103300  FIELD_33  L100700  SEX  L190300  L190400  \\\n",
       "0      0           0      3.1       1.0      3.0  1.0     4.20     12.3   \n",
       "1      1           1      3.3       1.0      3.0  1.0     4.24     13.1   \n",
       "2      2           2      3.4       1.0      3.8  1.0     4.26     12.9   \n",
       "3      3           3      2.8       1.0      3.7  1.0     4.20     13.5   \n",
       "4      4           4      2.9       1.0      3.4  1.0     3.92     12.6   \n",
       "\n",
       "   FIELD_38  L190500  FIELD_32  S000300  L103000_x  FIELD_41  FIELD_31  \\\n",
       "0       1.0     38.2       2.0     20.1       53.0       2.0       1.0   \n",
       "1       1.0     39.0       2.0     19.7       53.0       3.0       0.0   \n",
       "2       2.0     38.4       2.0     20.2       41.0       2.0       0.0   \n",
       "3       0.0     40.3       3.0     24.8       58.0       3.0       1.0   \n",
       "4       0.0     38.6       2.0     25.5       50.0       3.0       0.0   \n",
       "\n",
       "   L101700  FIELD_40  L103000_y  \n",
       "0     13.0       0.0       53.0  \n",
       "1     14.0       1.0       41.0  \n",
       "2     15.0       1.0       50.0  \n",
       "3     10.0       0.0       50.0  \n",
       "4     12.0       1.0       41.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the correlation of the selected feature with the independent variables\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppd=pd.DataFrame(data.copy())\n",
    "temppd['y']=data.L103000_y\n",
    "temppd.head()\n",
    "corval=abs(temppd.corr()).sort_values(by='y', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'L103000_y', 'L103000_x', 'L103300', 'L100700', 'L101700',\n",
       "       'S000300', 'SEX', 'L190400', 'FIELD_33', 'L190300', 'L190500',\n",
       "       'FIELD_38', 'FIELD_32', 'FIELD_31', 'FIELD_41', 'Unnamed: 0', 'index',\n",
       "       'FIELD_40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corval.y[:25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram plot of the features\n",
    "# import matplotlib.pyplot as plt\n",
    "# x[x.dtypes[(x.dtypes==\"float64\")|(x.dtypes==\"int64\")]\n",
    "#                         .index.values].hist(figsize=[11,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[['L103000_y']]\n",
    "\n",
    "# x=data[['L103000_x', 'L103100', 'L100700', 'S000200',\n",
    "#        'L101700', 'S000300', 'S001200', 'SEX', 'L190400', 'FIELD_33',\n",
    "#        'L100800', 'L190300', 'L102900', 'L101300', 'S000501', 'S000502',\n",
    "#        'L190000', 'L190800', 'L101600', 'FIELD_38', 'AGE', 'L100100',\n",
    "#        'FIELD_32']]\n",
    "x=data[['L103300', 'FIELD_33', 'L100700', 'SEX', 'L190300', 'L190400', 'FIELD_38', 'L190500', \n",
    "              'FIELD_32', 'S000300', 'L103000_x', 'FIELD_41', 'FIELD_31', 'L101700', 'FIELD_40']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(x,y)\n",
    "\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "\n",
    "# x=x[x.columns[:15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.1,   1. ,   3. , ...,  20.1,  53. ,  13. ],\n",
       "       [  3.3,   1. ,   3. , ...,  19.7,  53. ,  14. ],\n",
       "       [  3.4,   1. ,   3.8, ...,  20.2,  41. ,  15. ],\n",
       "       ...,\n",
       "       [  5.5,   1. ,   6.3, ...,  21.5, 110. ,  20. ],\n",
       "       [  2.6,   1. ,   4.4, ...,  20.2,  60. ,  16. ],\n",
       "       [  4.6,   3. ,   6.1, ...,  22.7, 107. ,  34. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in x.columns:\n",
    "#     x[i]=np.power(x[i],0.005)\n",
    "    plt.title(i)\n",
    "    plt.scatter(x[i],y)\n",
    "    plt.show()\n",
    "    plt.hist(x[i],bins=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.S000502=np.log10(x.S000502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "lr = RandomForestRegressor()\n",
    "\n",
    "sfs = SFS(lr, \n",
    "          k_features=13, \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=5)\n",
    "\n",
    "sfs = sfs.fit(x, y)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sfs.transform(x)\n",
    "print(sfs.k_feature_names_)\n",
    "print(sfs.k_feature_idx_)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=8)\n",
    "# pca.fit(x)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)   \n",
    "# print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# x=pca.fit_transform(x) \n",
    "# print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()  #StandardScaler()\n",
    "# x = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustring test\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# K = range(1,10)\n",
    "# distortions = []\n",
    "\n",
    "# for k in K:\n",
    "#     kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "#     kmeanModel.fit(x)\n",
    "#     distortions.append(sum(np.min(cdist(x, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / x.shape[0])\n",
    "\n",
    "# # Plot the elbow\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "# x['lbl']=kmeanModel.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylable=y[['L103000_y']]  \n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x, ylable, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=7, random_state=0,verbose =0,n_estimators=200)\n",
    "regr.fit(xtrain, ytrain) \n",
    "print(regr.feature_importances_)\n",
    "ypred=regr.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(30)\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempdata=pd.DataFrame(xtest.copy())\n",
    "# tempdata['ytest']=ytest\n",
    "# # temp=temp.dropna()\n",
    "# # tempdata.head()\n",
    "# # tempdata[tempdata.ytest.isna()].index\n",
    "\n",
    "# tempdata=tempdata.drop(tempdata[tempdata.ytest.isna()].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg boost\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_reg = xgb.XGBRegressor()\n",
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, \n",
    "#                           learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror',max_depth = 10, alpha = 200, n_estimators = 50, \n",
    "                          booster='gbtree',\n",
    "                          colsample_bytree = 0.6,learning_rate = 0.08,gamma=10, tree_method = 'gpu_hist'\n",
    "                         )\n",
    "\n",
    "xg_reg.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred = xg_reg.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "# ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "# ypredPD['t + 1']=ytest.values\n",
    "# ypredPD['pred (t +1)']=ypred\n",
    "# ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytest[ytest.isna()].shape\n",
    "# tempdata.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(input_dim=32,units=128,activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=128, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform'))\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam', metrics=['mean_squared_error' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h=model.fit(xtrain, ytrain, validation_split=.2,epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=h\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPD['diff']=abs(ypredPD['t + 1']- ypredPD['pred (t +1)'])\n",
    "print(np.mean(ypredPD['diff']))\n",
    "print(np.std(ypredPD['diff']))\n",
    "print(100*ypredPD[ypredPD['diff']<=5].shape[0]/ypredPD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# svr_rbf = SVR(kernel='rbf', C=10, gamma=0.02, epsilon=.001)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=svr_rbf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
