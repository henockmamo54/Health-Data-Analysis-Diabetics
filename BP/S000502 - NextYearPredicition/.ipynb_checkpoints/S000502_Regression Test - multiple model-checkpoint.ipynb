{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original=pd.read_csv('_xlable4_withNa_AllColumns.txt')\n",
    "y_original=pd.read_csv('_targelable4_withNa_AllColumns.txt')\n",
    "\n",
    "\n",
    "# x_original=x_original[['Unnamed: 0','S000502', 'S000501', 'S000300', 'L190400', 'L190500', 'L190300', 'SEX',\n",
    "#                        'L100700', 'L103000', 'L103300', 'L100800', 'L101700', 'AGE', 'L100500', 'L101300'\n",
    "#                        ]]\n",
    "\n",
    "x_original=x_original[['Unnamed: 0','S000501', 'S000502', 'S000300', 'L103000', 'L100700', 'L100800',\n",
    "        'L101300', 'AGE', 'L103100', 'L101700', 'L103300',  'FIELD_42', 'L100500'\n",
    "                       ]]\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','S000502']]\n",
    "\n",
    "\n",
    "print(x_original.shape)\n",
    "print(y_original.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,col in enumerate(x_original.columns):\n",
    "    print(col,x_original[col].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=x_original.copy()\n",
    "# conditions = [\n",
    "#     (df.S000501 < 120)  ,\n",
    "#     (df.S000501 >= 120) & (df.S000501 < 130),\n",
    "#     (df.S000501 >=130)]\n",
    "# choices = [0,1,2]\n",
    "# df['sbpG'] = np.select(conditions, choices, default=0)\n",
    "# df.head()\n",
    "# x_original=df.copy()\n",
    "\n",
    "# conditions2 = [\n",
    "#     (df.S000502 < 80)  ,\n",
    "#     (df.S000502 >= 80) & (df.S000502 < 90),\n",
    "#     (df.S000502 >=90)]\n",
    "# choices2 = [0,1,2]\n",
    "# df['dbpG'] = np.select(conditions2, choices2, default=0)\n",
    "# df.head()\n",
    "# x_original=df.copy()\n",
    "\n",
    "# conditions3 = [\n",
    "#     (df.AGE < 30)  ,\n",
    "#     (df.AGE >= 30) & (df.AGE < 40),\n",
    "#     (df.AGE >= 40) & (df.AGE < 50),\n",
    "#     (df.AGE >= 50) & (df.AGE < 60),\n",
    "#     (df.AGE >= 60)]\n",
    "# choices3 = [0,1,2,3,4]\n",
    "# df['AgeG'] = np.select(conditions3, choices3, default=0)\n",
    "# df.head()\n",
    "# x_original=df.copy()\n",
    "\n",
    "\n",
    "# conditions4 = [\n",
    "#     (df.L100800 < 100)  ,\n",
    "#     (df.L100800 >= 100) & (df.L100800 < 126), \n",
    "#     (df.L100800 >= 126)]\n",
    "# choices4 = [0,1,2]\n",
    "# df['CLASS'] = np.select(conditions4, choices4, default=0)\n",
    "# df.head()\n",
    "# x_original=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.merge(x_original,y_original, how='inner',left_on='Unnamed: 0', right_on='Unnamed: 0')\n",
    "data=data.dropna(). reset_index()\n",
    "\n",
    "# data=data[data.AGE_x >= 40]\n",
    "# data=data[data.AGE_x < 50]\n",
    "\n",
    "# data=data[data.CLASS_x==0]\n",
    "# data=data[data.sbpG==0]\n",
    "# data=data[data.dbpG==0]\n",
    "\n",
    "# data=data[data.L100800_y <200]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x=data[['S000501', 'S000502_x', 'S000300', 'L103000', 'L100700', 'L100800',\n",
    "       'S000100', 'L101300', 'AGE', 'L103100', 'L101700', 'L103300', 'S010102',\n",
    "       'S010101', 'FIELD_42', 'L100500']]\n",
    "\n",
    "y=data[['S000502_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the correlation of the selected feature with the independent variables\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppd=pd.DataFrame(x.copy())\n",
    "temppd['y']=y.S000502_y\n",
    "temppd.head()\n",
    "corval=abs(temppd.corr()).sort_values(by='y', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corval.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram plot of the features\n",
    "# import matplotlib.pyplot as plt\n",
    "# x[x.dtypes[(x.dtypes==\"float64\")|(x.dtypes==\"int64\")]\n",
    "#                         .index.values].hist(figsize=[11,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=8)\n",
    "# pca.fit(x)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)   \n",
    "# print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# x=pca.fit_transform(x) \n",
    "# print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()  #StandardScaler()\n",
    "# x = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustring test\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# K = range(1,10)\n",
    "# distortions = []\n",
    "\n",
    "# for k in K:\n",
    "#     kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "#     kmeanModel.fit(x)\n",
    "#     distortions.append(sum(np.min(cdist(x, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / x.shape[0])\n",
    "\n",
    "# # Plot the elbow\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "# x['lbl']=kmeanModel.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylable=y[['S000502_y']]  \n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x, ylable, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=7, random_state=0,verbose =0,n_estimators=500)\n",
    "regr.fit(xtrain, ytrain) \n",
    "print(regr.feature_importances_)\n",
    "ypred=regr.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(30)\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPD[\"diff\"] = abs(ypredPD[\"t + 1\"] - ypredPD[\"pred (t +1)\"])\n",
    "ypredPD[\"diff\"] = abs(ypredPD[\"t + 1\"] - ypredPD[\"pred (t +1)\"])\n",
    "print(\"|Actual - predicted < 5 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 5].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 10 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 10].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 15 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 15].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 20 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 20].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 25 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 25].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 30 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 30].shape[0] / ypredPD.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg boost\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, \n",
    "#                           learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred = xg_reg.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "# ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "# ypredPD['t + 1']=ytest.values\n",
    "# ypredPD['pred (t +1)']=ypred\n",
    "# ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPD[\"diff\"] = abs(ypredPD[\"t + 1\"] - ypredPD[\"pred (t +1)\"])\n",
    "print(\"|Actual - predicted < 5 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 5].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 10 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 10].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 15 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 15].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 20 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 20].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 25 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 25].shape[0] / ypredPD.shape[0]))\n",
    "print(\"|Actual - predicted < 30 mmHg|\", \"{:.1f}%\".format(100 * ypredPD[ypredPD[\"diff\"] < 30].shape[0] / ypredPD.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(input_dim=32,units=128,activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=128, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform'))\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam', metrics=['mean_squared_error' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h=model.fit(xtrain, ytrain, validation_split=.2,epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=h\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPD['diff']=abs(ypredPD['t + 1']- ypredPD['pred (t +1)'])\n",
    "print(np.mean(ypredPD['diff']))\n",
    "print(np.std(ypredPD['diff']))\n",
    "print(100*ypredPD[ypredPD['diff']<=5].shape[0]/ypredPD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# svr_rbf = SVR(kernel='rbf', C=10, gamma=0.02, epsilon=.001)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=svr_rbf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
