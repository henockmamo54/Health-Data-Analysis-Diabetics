{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import yapf.yapflib.yapf_api\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Read the dataset \n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../sep19SexAndAgeAddedFINAL DATASET_ver2.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change field 38 to 3 groups\n",
    "condtion = [\n",
    "    data.FIELD_38 == 0,\n",
    "    (data.FIELD_38 > 0) & (data.FIELD_38 < 4),\n",
    "    data.FIELD_38 >= 4,\n",
    "]\n",
    "choice = [0, 1, 2]\n",
    "data[\"FIELD_38_C\"] = np.select(condtion, choice, default=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535169, 405)\n"
     ]
    }
   ],
   "source": [
    "data[\"max\"] = np.min(\n",
    "    data[[\"FIELD_6\", \"FIELD_7\"]], axis=1\n",
    ")  # combine FIELD_6 and FIELD_7 both represent the same thing (Women's marital status)\n",
    "\n",
    "data = data.drop(columns=[\"FIELD_6\", \"FIELD_7\", \"B_DAY\"])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Class to the dataset\n",
    "_class = []\n",
    "for i in range(data.shape[0]):\n",
    "    if (data.S000501[i] >= 140) | (data.S000502[i] >= 90):\n",
    "        _class.append(2)\n",
    "    elif (data.S000501[i] < 120) & (data.S000502[i] < 80):\n",
    "        _class.append(0)\n",
    "    else:\n",
    "        _class.append(1)\n",
    "data[\"CLASS\"] = _class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465879, 406)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "data = data[data.FIELD_13 != 1]  \n",
    "data = data[data.FIELD_20 != 1]  \n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "data.rename(\n",
    "    columns={\n",
    "        \"L104600\": \"HBA1C\",\n",
    "        \"L103000\": \"Triglycerides\",\n",
    "        \"L100800\": \"fasting glucose\",\n",
    "        \"S000300\": \"BMI\",\n",
    "        \"S000501\": \"SBP\",\n",
    "        \"S000502\": \"DBP\",\n",
    "        \"L101700\": \"r-GTP gamma\",\n",
    "        \"L103300\": \"Cardiac risk factor\",\n",
    "        \"L190400\": \"Hemoglobin\",\n",
    "        \"L190500\": \"HCT\",\n",
    "        \"L100700\": \"Uric Acid\",\n",
    "        \"L101300\": \"SGPT\",\n",
    "        \"L190300\": \"RBC\",\n",
    "        \"L102900\": \"total cholesterol\",\n",
    "        \"L103100\": \"HDL-Cholesterol\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split column types to categorical and numerical\n",
    "numerical_cols = list(data.columns[~data.columns.str.startswith(\"FIELD\")])\n",
    "categorical_cols = list(data.columns[data.columns.str.startswith(\"FIELD\")])\n",
    "categorical_cols.append(\"CLASS\")\n",
    "numerical_cols.remove(\"SEX\")\n",
    "categorical_cols.append(\"SEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465879, 406)\n",
      "CLASS\n",
      "0    239294\n",
      "1    208467\n",
      "2     18118\n",
      "dtype: int64\n",
      "(54354, 406)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.groupby(by='CLASS').size())\n",
    "\n",
    "mydata=data.copy()\n",
    "class2 = mydata[mydata.CLASS == 2]\n",
    "class1 = mydata[mydata.CLASS == 1]\n",
    "class0 = mydata[mydata.CLASS == 0]\n",
    "\n",
    "data = pd.concat([class2, class1.sample(class2.shape[0],random_state=42), \n",
    "                  class0.sample(class2.shape[0],random_state=42)])\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Feature Selection\n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Calculate correlation Value - for numerical values\n",
    "========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 Pearson Correlation\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data[numerical_cols].corr()  # compute the correlation value\n",
    "corr = corr.CLASS  # select the correlation values of the Class\n",
    "\n",
    "# convert correlation values to dataframe\n",
    "corrvalPD = pd.DataFrame()\n",
    "corrvalPD[\"Col\"] = corr.index\n",
    "corrvalPD[\"val\"] = abs(corr.values)\n",
    "\n",
    "corrvalPD = corrvalPD.sort_values(by=\"val\", ascending=False)\n",
    "corrvalPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of none NA values of each feature set\n",
    "mydataset = data.copy()[numerical_cols]\n",
    "colCount = []\n",
    "for i in mydataset.columns:\n",
    "    colCount.append([i, mydataset[i].dropna().shape[0]])\n",
    "\n",
    "colCountPD = pd.DataFrame(colCount, columns=[\"Col\", \"Count\"])\n",
    "colCountPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the correlation value and the total count of the feature\n",
    "mergedColCorrCount = pd.merge(\n",
    "    corrvalPD, colCountPD, how=\"inner\", left_on=\"Col\", right_on=\"Col\"\n",
    ")\n",
    "mergedColCorrCount = mergedColCorrCount[mergedColCorrCount.Count > 50000]\n",
    "mergedColCorrCount = mergedColCorrCount.sort_values(by=\"val\", ascending=False)\n",
    "mergedColCorrCount.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 20 correlated features\n",
    "print(list(mergedColCorrCount.head(16).Col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Anova test\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another option for feature selection of numerical values\n",
    "\n",
    "mydataset = data.copy()[numerical_cols]  # filter only numrical columns\n",
    "colslist = mydataset.columns\n",
    "DiabeticColVals = mydataset.CLASS\n",
    "\n",
    "cor = []\n",
    "pval = []\n",
    "count = []\n",
    "\n",
    "# for each column compute f and p values\n",
    "for i in range(len(colslist)):\n",
    "\n",
    "    temp = pd.DataFrame([])\n",
    "    temp[\"a\"] = DiabeticColVals\n",
    "    temp[\"b\"] = mydataset[colslist[i]]\n",
    "    temp = temp.dropna()\n",
    "\n",
    "    count.append(temp.shape[0])\n",
    "    tempcor = temp.corr()\n",
    "\n",
    "    if tempcor.shape[0] > 1:\n",
    "        F, p = stats.f_oneway(\n",
    "            temp[temp[\"a\"] == 0].b, temp[temp[\"a\"] == 1].b, temp[temp[\"a\"] == 2].b\n",
    "        )\n",
    "        cor.append(F)\n",
    "        pval.append(p)\n",
    "    else:\n",
    "        cor.append(0)\n",
    "        pval.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FvalPvalCorr = pd.DataFrame()\n",
    "FvalPvalCorr[\"Cols\"] = colslist\n",
    "FvalPvalCorr[\"F\"] = cor\n",
    "FvalPvalCorr[\"P\"] = pval\n",
    "FvalPvalCorr[\"Count\"] = count\n",
    "FvalPvalCorr = FvalPvalCorr.sort_values(by=\"F\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 20 features\n",
    "print(list(FvalPvalCorr[FvalPvalCorr.Count > 40000].Cols)[:25])\n",
    "FvalPvalCorr[FvalPvalCorr.Count > 40000].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Correlation for categorical values\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 chi2 method\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename commen field names\n",
    "categorical_cols[categorical_cols.index(\"FIELD_33\")] = \"_4_1_Smoking\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_38\")] = \"Drinking_5_1_days\"\n",
    "categorical_cols[\n",
    "    categorical_cols.index(\"FIELD_40\")\n",
    "] = \"_6_1_of_physical_activity_high_strength\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_31\")] = \"Family_history\"\n",
    "categorical_cols[\n",
    "    categorical_cols.index(\"FIELD_41\")\n",
    "] = \"_6_2_of_physical_activity_moderate\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_27\")] = \"_2_family_history_stroke\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_21\")] = \"_1_medication_heart_disease\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_14\")] = \"Whether_one_diagnosis_disease\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_32\")] = \"_3B_hepatitis\"\n",
    "categorical_cols[\n",
    "    categorical_cols.index(\"FIELD_42\")\n",
    "] = \"_6_3_of_physical_activity_walking\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_4\")] = \"blood_type\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_29\")] = \"_2_family_history_hypertension\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_3\")] = \"Blood_factor_RH_factor\"\n",
    "categorical_cols[categorical_cols.index(\"FIELD_19\")] = \"_1_drug_therapy_stroke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = data.rename(\n",
    "    columns={\n",
    "        \"FIELD_33\": \"_4_1_Smoking\",\n",
    "        \"FIELD_38\": \"Drinking_5_1_days\",\n",
    "        \"FIELD_40\": \"_6_1_of_physical_activity_high_strength\",\n",
    "        \"FIELD_31\": \"Family_history\",\n",
    "        \"FIELD_41\": \"_6_2_of_physical_activity_moderate\",\n",
    "        \"FIELD_27\": \"_2_family_history_stroke\",\n",
    "        \"FIELD_21\": \"_1_medication_heart_disease\",\n",
    "        \"FIELD_14\": \"Whether_one_diagnosis_disease\",\n",
    "        \"FIELD_32\": \"_3B_hepatitis\",\n",
    "        \"FIELD_42\": \"_6_3_of_physical_activity_walking\",\n",
    "        \"FIELD_4\": \"blood_type\",\n",
    "        \"FIELD_29\": \"_2_family_history_hypertension\",\n",
    "        \"FIELD_3\": \"Blood_factor_RH_factor\",\n",
    "        \"FIELD_19\": \"_1_drug_therapy_stroke\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "# mydata=data[categorical_cols] # filter only categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blood_factor_RH_factor</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>FIELD_5</th>\n",
       "      <th>FIELD_9</th>\n",
       "      <th>FIELD_13</th>\n",
       "      <th>Whether_one_diagnosis_disease</th>\n",
       "      <th>FIELD_15</th>\n",
       "      <th>FIELD_16</th>\n",
       "      <th>FIELD_17</th>\n",
       "      <th>FIELD_18</th>\n",
       "      <th>...</th>\n",
       "      <th>FIELD_134</th>\n",
       "      <th>FIELD_135</th>\n",
       "      <th>FIELD_136</th>\n",
       "      <th>FIELD_137</th>\n",
       "      <th>FIELD_138</th>\n",
       "      <th>FIELD_139</th>\n",
       "      <th>FIELD_140</th>\n",
       "      <th>FIELD_38_C</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blood_factor_RH_factor blood_type FIELD_5  FIELD_9  FIELD_13  \\\n",
       "3                     NaN          4     NaN      NaN       0.0   \n",
       "4                     NaN          4     NaN      NaN       0.0   \n",
       "50                      1          3       1      NaN       0.0   \n",
       "82                    NaN          4       1      NaN       0.0   \n",
       "83                      1          4     NaN      NaN       0.0   \n",
       "\n",
       "    Whether_one_diagnosis_disease  FIELD_15  FIELD_16  FIELD_17  FIELD_18  \\\n",
       "3                             0.0       0.0       0.0       0.0       0.0   \n",
       "4                             0.0       0.0       0.0       0.0       0.0   \n",
       "50                            0.0       0.0       0.0       0.0       0.0   \n",
       "82                            0.0       0.0       0.0       0.0       0.0   \n",
       "83                            0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "    ...  FIELD_134  FIELD_135  FIELD_136  FIELD_137  FIELD_138  FIELD_139  \\\n",
       "3   ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4   ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "50  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "82  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "83  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "    FIELD_140  FIELD_38_C  CLASS  SEX  \n",
       "3         NaN         1.0      2  0.0  \n",
       "4         NaN         1.0      2  0.0  \n",
       "50        NaN         1.0      2  1.0  \n",
       "82        NaN         1.0      2  0.0  \n",
       "83        NaN         1.0      2  0.0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only categorical columns\n",
    "mydata = data[categorical_cols]\n",
    "# remove columns with string values as data type\n",
    "mydata = mydata.drop(\n",
    "    columns=[\n",
    "        \"FIELD_1\",\n",
    "        \"FIELD_2\",\n",
    "        \"FIELD_8\",\n",
    "        \"FIELD_10\",\n",
    "        \"FIELD_11\",\n",
    "        \"FIELD_12\",\n",
    "        \"FIELD_39\",\n",
    "        \"FIELD_88\",\n",
    "        \"FIELD_89\",\n",
    "        \"FIELD_109\",\n",
    "        \"FIELD_110\",\n",
    "        \"FIELD_111\",\n",
    "        \"FIELD_70\",\n",
    "        \"FIELD_82\",\n",
    "        \"FIELD_85\",\n",
    "        \"FIELD_91\",\n",
    "        \"FIELD_103\",\n",
    "        \"FIELD_106\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blood_factor_RH_factor</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>FIELD_5</th>\n",
       "      <th>FIELD_9</th>\n",
       "      <th>FIELD_13</th>\n",
       "      <th>Whether_one_diagnosis_disease</th>\n",
       "      <th>FIELD_15</th>\n",
       "      <th>FIELD_16</th>\n",
       "      <th>FIELD_17</th>\n",
       "      <th>FIELD_18</th>\n",
       "      <th>...</th>\n",
       "      <th>FIELD_134</th>\n",
       "      <th>FIELD_135</th>\n",
       "      <th>FIELD_136</th>\n",
       "      <th>FIELD_137</th>\n",
       "      <th>FIELD_138</th>\n",
       "      <th>FIELD_139</th>\n",
       "      <th>FIELD_140</th>\n",
       "      <th>FIELD_38_C</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blood_factor_RH_factor blood_type FIELD_5  FIELD_9  FIELD_13  \\\n",
       "3                     NaN          4     NaN      NaN       0.0   \n",
       "4                     NaN          4     NaN      NaN       0.0   \n",
       "50                      1          3       1      NaN       0.0   \n",
       "82                    NaN          4       1      NaN       0.0   \n",
       "83                      1          4     NaN      NaN       0.0   \n",
       "\n",
       "    Whether_one_diagnosis_disease  FIELD_15  FIELD_16  FIELD_17  FIELD_18  \\\n",
       "3                             0.0       0.0       0.0       0.0       0.0   \n",
       "4                             0.0       0.0       0.0       0.0       0.0   \n",
       "50                            0.0       0.0       0.0       0.0       0.0   \n",
       "82                            0.0       0.0       0.0       0.0       0.0   \n",
       "83                            0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "    ...  FIELD_134  FIELD_135  FIELD_136  FIELD_137  FIELD_138  FIELD_139  \\\n",
       "3   ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4   ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "50  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "82  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "83  ...        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "    FIELD_140  FIELD_38_C  CLASS  SEX  \n",
       "3         NaN         1.0      2  0.0  \n",
       "4         NaN         1.0      2  0.0  \n",
       "50        NaN         1.0      2  1.0  \n",
       "82        NaN         1.0      2  0.0  \n",
       "83        NaN         1.0      2  0.0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data clean up\n",
    "mydata = mydata.drop(\n",
    "    mydata[[\"Blood_factor_RH_factor\"]][mydata[[\"Blood_factor_RH_factor\"]] == \"`\"]\n",
    "    .dropna()\n",
    "    .index\n",
    ")\n",
    "mydata = mydata.drop(\n",
    "    mydata[[\"Blood_factor_RH_factor\"]][mydata[[\"Blood_factor_RH_factor\"]] == \"G\"]\n",
    "    .dropna()\n",
    "    .index\n",
    ")\n",
    "\n",
    "mydata = mydata.drop(\n",
    "    mydata[[\"blood_type\"]][mydata[[\"blood_type\"]] == \".\"].dropna().index\n",
    ")\n",
    "mydata = mydata.drop(mydata[mydata.FIELD_5 == \".\"].index)\n",
    "\n",
    "\n",
    "mydata = mydata.drop(mydata[mydata.FIELD_35 == \"?\"].index)\n",
    "mydata = mydata.drop(mydata[mydata.FIELD_35 == \".\"].index)\n",
    "mydata = mydata.drop(mydata[mydata.FIELD_36 == \".\"].index)\n",
    "mydata = mydata.drop(mydata[mydata.FIELD_37 == \"\\\\\"].index)\n",
    "mydata.head()\n",
    "\n",
    "# mydata=mydata.drop(mydata[mydata.FIELD_39 == '7+' ].index)\n",
    "# mydata=mydata.drop(mydata[mydata.FIELD_39 == '5~7'].index)\n",
    "# mydata=mydata.drop(mydata[mydata.FIELD_39 == '3-4'].index)\n",
    "\n",
    "\n",
    "mydata = mydata.drop(mydata[mydata.FIELD_95 == \".\"].index)\n",
    "mydata.head()\n",
    "\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AllTables = []\n",
    "\n",
    "# prepare the table indicating the number of entries per class and per each column group\n",
    "for j in range(len(mydata.columns)):\n",
    "\n",
    "    columnName = mydata.columns[j]\n",
    "    print(j, columnName)\n",
    "\n",
    "    temp = mydata[columnName].dropna().astype(float).unique()\n",
    "    mytempdata = mydata[[columnName, \"CLASS\"]].dropna()\n",
    "    mytempdata[columnName] = mytempdata[columnName].astype(float)\n",
    "    temptable = []\n",
    "\n",
    "    sumval = 0\n",
    "\n",
    "    for i in range(temp.shape[0]):\n",
    "\n",
    "        temp_i_val = str(temp[i])\n",
    "        class0_count = mytempdata.query(\n",
    "            columnName + \" == \" + (temp_i_val) + \" & CLASS == 0\"\n",
    "        ).shape[0]\n",
    "        class1_count = mytempdata.query(\n",
    "            columnName + \" == \" + (temp_i_val) + \" & CLASS == 1\"\n",
    "        ).shape[0]\n",
    "        class2_count = mytempdata.query(\n",
    "            columnName + \" == \" + (temp_i_val) + \" & CLASS == 2\"\n",
    "        ).shape[0]\n",
    "\n",
    "        sumval = sumval + (class0_count + class1_count + class2_count)\n",
    "\n",
    "        temptable.append([class0_count, class1_count, class2_count])\n",
    "\n",
    "    #     print(sumval,mytempdata.shape[0], mytempdata.shape[0] == sumval)\n",
    "\n",
    "    if len(temptable) > 1:\n",
    "        AllTables.append([temptable, columnName, mytempdata.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the statisitical values\n",
    "statas = []\n",
    "for i in range(len(AllTables)):\n",
    "    #     print(i,AllTables[i][1])\n",
    "    table = AllTables[i][0]\n",
    "    stat, p, dof, expected = chi2_contingency(table)\n",
    "    statas.append(\n",
    "        [\n",
    "            AllTables[i][1],\n",
    "            stat,\n",
    "            p,\n",
    "            dof,\n",
    "            np.sum(table),\n",
    "            AllTables[i][2],\n",
    "            AllTables[i][1],\n",
    "            table,\n",
    "            expected,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the computed status to dataframe\n",
    "finalstat = pd.DataFrame(\n",
    "    statas,\n",
    "    columns=[\n",
    "        \"Name\",\n",
    "        \"stat\",\n",
    "        \"p\",\n",
    "        \"dof\",\n",
    "        \"instances\",\n",
    "        \"orginal\",\n",
    "        \"Name2\",\n",
    "        \"table\",\n",
    "        \"expected\",\n",
    "    ],\n",
    ")\n",
    "finalstat = finalstat[\n",
    "    finalstat.orginal > 40000\n",
    "]  # select columns with count at least 200, 000\n",
    "\n",
    "# sort stat value and select top 20 features\n",
    "finalstat.stat = finalstat.stat.astype(int)\n",
    "finalstat = finalstat.sort_values(by=\"stat\", ascending=False)\n",
    "\n",
    "print(list(finalstat.Name[:15]))\n",
    "finalstat[[\"Name\", \"stat\", \"instances\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Refine the selected numerical and categorical features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the selected columns list from section 2.1.2 and 2.2.1\n",
    "\n",
    "newColList = [\n",
    "    'BMI', 'Uric Acid', 'fasting glucose', 'Triglycerides', 'r-GTP gamma', 'AGE', 'L101600', 'L100500', 'SGPT', \n",
    "    'L101400', 'L190000', 'SEX', '_4_1_Smoking', 'Drinking_5_1_days', 'FIELD_38_C', \n",
    "    '_6_1_of_physical_activity_high_strength', '_2_family_history_hypertension', '_6_2_of_physical_activity_moderate', \n",
    "    '_2_family_history_stroke', '_6_3_of_physical_activity_walking', '_3B_hepatitis', 'FIELD_28', \n",
    "    '_1_medication_heart_disease',\n",
    "    \"CLASS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter a new data based on the selected columns\n",
    "mydata = data[newColList].copy().dropna()\n",
    "\n",
    "print(mydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mydata[\n",
    "    [\n",
    "     'BMI', 'Uric Acid', 'fasting glucose', 'Triglycerides', 'r-GTP gamma', 'AGE', 'L101600', 'L100500', 'SGPT', \n",
    "    'L101400', 'L190000', 'SEX', '_4_1_Smoking', 'Drinking_5_1_days', 'FIELD_38_C', \n",
    "    '_6_1_of_physical_activity_high_strength', '_2_family_history_hypertension', '_6_2_of_physical_activity_moderate', \n",
    "    '_2_family_history_stroke', '_6_3_of_physical_activity_walking', '_3B_hepatitis', 'FIELD_28', \n",
    "    '_1_medication_heart_disease',\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "y = mydata[[\"CLASS\"]]\n",
    "\n",
    "print(x.shape)\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 ExtraTreesClassifier feature_importances method\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x, y)\n",
    "\n",
    "print(\n",
    "    model.feature_importances_\n",
    ")  # use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "# plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(17).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 SelectKBest method\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(x, y)\n",
    "\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = [\"Specs\", \"Score\"]  # naming the dataframe columns\n",
    "\n",
    "# x=x[x.columns[:15]]\n",
    "print(list(x.columns[:16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 variance inflation factor \n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function computes vif value which help us to remove columns with redundant information ( to avoid Multicollinearity)\n",
    "# Multicollinearity occurs when two or more predictors in the model are correlated and provide redundant information about the response.\n",
    "# Multicollinearity was measured by variance inflation factors (VIF) and tolerance\n",
    "\n",
    "\n",
    "def vifcal(inputdata, depcol):\n",
    "    vifL5 = []\n",
    "    import statsmodels.formula.api as sm\n",
    "\n",
    "    xvars = inputdata.drop([depcol], axis=1)\n",
    "    xvarnames = xvars.columns\n",
    "    for i in range(0, xvarnames.shape[0]):\n",
    "        _y = xvars[xvarnames[i]]\n",
    "        _x = xvars[xvarnames.drop(xvarnames[i])]\n",
    "        rsq = sm.ols(formula=\"_y~_x\", data=xvars).fit().rsquared\n",
    "        vif = round(1 / (1 - rsq), 2)\n",
    "        print(i, \", \", xvarnames[i], \" VIF = \", vif)\n",
    "        if vif < 5:\n",
    "            vifL5.append(xvarnames[i])\n",
    "    return vifL5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new columns are selcted from section 3.2\n",
    "# newcols = vifcal(mydata[['L104600', 'L103000', 'S000300', 'S000501', 'S000502', 'L101700', 'L103300', 'SEX',\n",
    "#                          'L190400', 'AGE', 'L190500', 'L100700', 'L101300', 'L190300', 'L102900', 'L103100',\n",
    "#                          'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_31','CLASS']],'CLASS')\n",
    "\n",
    "newcols = vifcal(\n",
    "    mydata[\n",
    "        [\n",
    "        'BMI', 'Hemoglobin', 'RBC', 'HCT', 'Uric Acid', 'fasting glucose', 'Triglycerides', 'Cardiac risk factor', \n",
    "    'r-GTP gamma', 'AGE', 'L101600', 'total cholesterol', 'L100500', 'HDL-Cholesterol', \n",
    "    'SGPT', 'L101400', 'L190000', 'L190800',\n",
    "    'SEX', '_4_1_Smoking', 'Drinking_5_1_days', 'FIELD_38_C', \n",
    "    '_6_1_of_physical_activity_high_strength', '_2_family_history_hypertension', '_6_2_of_physical_activity_moderate', \n",
    "    '_2_family_history_stroke', '_6_3_of_physical_activity_walking', '_3B_hepatitis', 'FIELD_28', \n",
    "    '_1_medication_heart_disease',\n",
    "            \"CLASS\",\n",
    "        ]\n",
    "    ],\n",
    "    \"CLASS\",\n",
    ")\n",
    "print(newcols, len(newcols))\n",
    "\n",
    "# we need to exclude features with vif value >5\n",
    "# L190400  ,L103300,L190500,L190300,L102900,L103100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Final Selected Features\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the out put of section of 3.2 and 3.3 the following features are selected\n",
    "\n",
    "\n",
    "finalFeatures = [\n",
    "    'BMI', 'r-GTP gamma', 'fasting glucose', 'Triglycerides', 'AGE', 'SGPT',\n",
    "       'SEX', 'L101400', 'Uric Acid', 'L101600', 'L100500',\n",
    "       '_6_1_of_physical_activity_high_strength', '_4_1_Smoking',\n",
    "       'FIELD_38_C',\n",
    "    'CLASS'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# finalFeatures=['HBA1C', 'Triglycerides', 'BMI',  'r-GTP gamma', 'SEX', 'AGE', 'Uric Acid',\n",
    "#                '_4_1_Smoking', 'Drinking_5_1_days', '_6_1_of_physical_activity_high_strength', 'Family_history','CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Model Test Based on the features \n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42416, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>r-GTP gamma</th>\n",
       "      <th>fasting glucose</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SGPT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>L101400</th>\n",
       "      <th>Uric Acid</th>\n",
       "      <th>L101600</th>\n",
       "      <th>L100500</th>\n",
       "      <th>_6_1_of_physical_activity_high_strength</th>\n",
       "      <th>_4_1_Smoking</th>\n",
       "      <th>FIELD_38_C</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>21.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>26.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>26.3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BMI  r-GTP gamma  fasting glucose  Triglycerides   AGE  SGPT  SEX  \\\n",
       "3   24.3         39.0            105.0          130.0  49.0  15.0  0.0   \n",
       "4   23.7         24.0            118.0           92.0  50.0  12.0  0.0   \n",
       "50  21.7         12.0             95.0           64.0  46.0  13.0  1.0   \n",
       "82  26.4         40.0             98.0          187.0  48.0  19.0  0.0   \n",
       "83  26.3         41.0            104.0           99.0  49.0  19.0  0.0   \n",
       "\n",
       "    L101400  Uric Acid  L101600  L100500  \\\n",
       "3     288.0        2.0     53.0      1.0   \n",
       "4     264.0        2.8     49.0      1.0   \n",
       "50    218.0        2.5     24.0      0.8   \n",
       "82    418.0        8.4     72.0      1.4   \n",
       "83    374.0        9.2     70.0      1.3   \n",
       "\n",
       "    _6_1_of_physical_activity_high_strength  _4_1_Smoking  FIELD_38_C  CLASS  \n",
       "3                                       3.0           2.0         1.0      2  \n",
       "4                                       2.0           2.0         1.0      2  \n",
       "50                                      3.0           1.0         1.0      2  \n",
       "82                                      1.0           1.0         1.0      2  \n",
       "83                                      1.0           3.0         1.0      2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomseed = 7\n",
    "mydata = data[finalFeatures].copy().dropna()\n",
    "print(mydata.shape)\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14170 14015 14231\n"
     ]
    }
   ],
   "source": [
    "class2 = mydata[mydata.CLASS == 2]\n",
    "class1 = mydata[mydata.CLASS == 1]\n",
    "class0 = mydata[mydata.CLASS == 0]\n",
    "\n",
    "print(class2.shape[0], class1.shape[0], class0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_test = class2.sample(1000, random_state=randomseed)\n",
    "class1_test = class1.sample(1000, random_state=randomseed)\n",
    "class0_test = class0.sample(1000, random_state=randomseed)\n",
    "test = pd.concat([class2_test, class1_test, class0_test])\n",
    "test=shuffle(test)\n",
    "\n",
    "class2_train = class2.drop(class2_test.index)\n",
    "\n",
    "class1_train = class1.drop(class1_test.index) #.sample( class2_train.shape[0], random_state=randomseed)\n",
    "\n",
    "class0_train = class0.drop(class0_test.index) #.sample( class2_train.shape[0], random_state=randomseed)\n",
    "train = pd.concat([class2_train, class1_train, class0_train])\n",
    "train=shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate synthetic dataset to overcome class imbalance\n",
    "# from collections import Counter\n",
    "# from numpy.random import RandomState\n",
    "# from sklearn.datasets import make_classification\n",
    "# from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# sm = SMOTENC(random_state=42, categorical_features=[5, 6, 7, 8])\n",
    "# X_res, y_res = sm.fit_resample(train.iloc[:, :-1], train.iloc[:, -1])\n",
    "# print(\"Resampled dataset samples per class {}\".format(Counter(y_res)))\n",
    "\n",
    "# train = pd.DataFrame(X_res, columns=list(train.columns[:-1]))\n",
    "# train[\"CLASS\"] = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# transformer = RobustScaler()\n",
    "# transformer.fit(train.iloc[:, :-1])\n",
    "# train.iloc[:, :-1] = transformer.transform(train.iloc[:, :-1])\n",
    "# test.iloc[:, :-1] = transformer.transform(test.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=randomseed, n_estimators=100, max_depth=10)\n",
    "rf.fit(train.iloc[:, :-1], train.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rf.predict(test.iloc[:, :-1])\n",
    "\n",
    "score = rf.score(test.iloc[:, :-1], test.iloc[:, -1])\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)\n",
    "\n",
    "print(np.sum(feat_importances.nlargest(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test.iloc[:, -1], ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Accuracy on training set: {:.3f}\".format(\n",
    "        rf.score(train.iloc[:, :-1], train.iloc[:, -1])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Accuracy on test set: {:.3f}\".format(rf.score(test.iloc[:, :-1], test.iloc[:, -1]))\n",
    ")\n",
    "ypred = rf.predict(test.iloc[:, :-1])\n",
    "\n",
    "confmatrx = pd.DataFrame(confusion_matrix(test.iloc[:, -1], ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test.iloc[:, -1], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed, num_class=3)\n",
    "\n",
    "xgb_model.fit(train.iloc[:, :-1], train.iloc[:, -1])\n",
    "\n",
    "y_pred = xgb_model.predict((test.iloc[:, :-1]))\n",
    "\n",
    "print(\n",
    "    \"Accuracy on training set: {:.3f}\".format(\n",
    "        xgb_model.score(train.iloc[:, :-1], train.iloc[:, -1])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Accuracy on test set: {:.3f}\".format(xgb_model.score(test.iloc[:, :-1], test.iloc[:, -1]))\n",
    ")\n",
    "confmatrx = pd.DataFrame(confusion_matrix(test.iloc[:, -1], y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.iloc[:, -1], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(train.iloc[:, :-1], train.iloc[:, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=clf.predict((test.iloc[:, :-1]))\n",
    "\n",
    "print(\n",
    "    \"Accuracy on training set: {:.3f}\".format(\n",
    "        clf.score(train.iloc[:, :-1], train.iloc[:, -1])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Accuracy on test set: {:.3f}\".format(clf.score(test.iloc[:, :-1], test.iloc[:, -1]))\n",
    ")\n",
    "\n",
    "confmatrx = pd.DataFrame(confusion_matrix(test.iloc[:, -1], y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.iloc[:, -1], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.txt',sep=',')\n",
    "test.to_csv('test.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(by='Class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===============================\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr  \n",
    "temp=train.copy()\n",
    "\n",
    "con=[]\n",
    "for i in range(temp.shape[0]):\n",
    "    con.append ([pearsonr(temp.iloc[0,:-1].values,\n",
    "                    temp.iloc[i,:-1].values)[0],i,temp.iloc[i,-1],temp.index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=pd.DataFrame(con,columns=['val','index','class','ai'])\n",
    "con=con.sort_values(by='val', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.index.isin( list(con.head(15).ai) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(con.tail(10).ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(con.head().ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
