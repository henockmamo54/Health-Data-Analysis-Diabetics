{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('../_xlable4_withNa_AllColumns.txt')\n",
    "y=pd.read_csv('../_targelable4_withNa_AllColumns.txt')\n",
    "\n",
    "y=y[['Unnamed: 0','L190300']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.merge(x,y, how='inner',left_on='Unnamed: 0', right_on='Unnamed: 0')\n",
    "data['max']=np.min(data[['FIELD_6','FIELD_7']],axis=1)\n",
    "data=data.drop(columns=['FIELD_6','FIELD_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.query('FIELD_15 !=1 and FIELD_17 !=1 and FIELD_22 != 1 and FIELD_24 != 1 and FIELD_16 != 1 and FIELD_23 != 1')\n",
    "# data=data.query('FIELD_16 != 1 and FIELD_23 != 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159381, 408)\n"
     ]
    }
   ],
   "source": [
    "# data=data[data.SEX==0]\n",
    "# data=data[data.FIELD_15!=1]\n",
    "# data=data[data.FIELD_17!=1]\n",
    "# data=data[data.FIELD_22!=1]\n",
    "# data=data[data.FIELD_24!=1]\n",
    "# data=data[data.AGE>=40]\n",
    "# data=data[data.AGE<50]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split column types to categorical and numerical\n",
    "numerical_cols = list(data.columns[~data.columns.str.startswith('FIELD')])\n",
    "categorical_cols = list(data.columns[data.columns.str.startswith('FIELD')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation Value - for numerical values\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>L393800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>L190300_y</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>L511300</td>\n",
       "      <td>0.869595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>L190300_x</td>\n",
       "      <td>0.854068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>L501900</td>\n",
       "      <td>0.800859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Col       val\n",
       "134    L393800  1.000000\n",
       "278  L190300_y  1.000000\n",
       "176    L511300  0.869595\n",
       "93   L190300_x  0.854068\n",
       "153    L501900  0.800859"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=data[numerical_cols].corr()\n",
    "corr=corr.L190300_y\n",
    "corrvalPD=pd.DataFrame()\n",
    "corrvalPD['Col']=corr.index\n",
    "corrvalPD['val']=abs(corr.values)\n",
    "\n",
    "corrvalPD=corrvalPD.sort_values(by='val',ascending=False)\n",
    "corrvalPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>159381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>index</td>\n",
       "      <td>159381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMPARE</td>\n",
       "      <td>159381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE</td>\n",
       "      <td>159381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_DAY</td>\n",
       "      <td>159381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col   Count\n",
       "0  Unnamed: 0  159381\n",
       "1       index  159381\n",
       "2     COMPARE  159381\n",
       "3         AGE  159381\n",
       "4       B_DAY  159381"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of none NA values of feature set\n",
    "mydataset=data.copy()[numerical_cols]\n",
    "colCount=[]\n",
    "for i in mydataset.columns:\n",
    "    colCount.append([i,mydataset[i].dropna().shape[0]])\n",
    "\n",
    "colCountPD=pd.DataFrame(colCount,columns=['Col','Count'])\n",
    "colCountPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>val</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L190300_y</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L190300_x</td>\n",
       "      <td>0.854068</td>\n",
       "      <td>159204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L190500</td>\n",
       "      <td>0.735728</td>\n",
       "      <td>159204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L190400</td>\n",
       "      <td>0.721104</td>\n",
       "      <td>159241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEX</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>159381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>S000100</td>\n",
       "      <td>0.496809</td>\n",
       "      <td>159302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>L100700</td>\n",
       "      <td>0.481208</td>\n",
       "      <td>152474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>L100500</td>\n",
       "      <td>0.479179</td>\n",
       "      <td>158954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S000300</td>\n",
       "      <td>0.379807</td>\n",
       "      <td>159075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>L103300</td>\n",
       "      <td>0.379130</td>\n",
       "      <td>135222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S000501</td>\n",
       "      <td>0.354820</td>\n",
       "      <td>159305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>L103100</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>158880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>S000502</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>159305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>L101300</td>\n",
       "      <td>0.295146</td>\n",
       "      <td>159247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>L103000</td>\n",
       "      <td>0.281001</td>\n",
       "      <td>158939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>L101600</td>\n",
       "      <td>0.249431</td>\n",
       "      <td>152251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>L190600</td>\n",
       "      <td>0.242206</td>\n",
       "      <td>145182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>L101700</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>158951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>L107400</td>\n",
       "      <td>0.222615</td>\n",
       "      <td>148029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>L100200</td>\n",
       "      <td>0.220498</td>\n",
       "      <td>148627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Col       val   Count\n",
       "1   L190300_y  1.000000  159192\n",
       "3   L190300_x  0.854068  159204\n",
       "6     L190500  0.735728  159204\n",
       "7     L190400  0.721104  159241\n",
       "9         SEX  0.664207  159381\n",
       "14    S000100  0.496809  159302\n",
       "15    L100700  0.481208  152474\n",
       "16    L100500  0.479179  158954\n",
       "25    S000300  0.379807  159075\n",
       "26    L103300  0.379130  135222\n",
       "28    S000501  0.354820  159305\n",
       "30    L103100  0.349650  158880\n",
       "37    S000502  0.302857  159305\n",
       "41    L101300  0.295146  159247\n",
       "46    L103000  0.281001  158939\n",
       "48    L101600  0.249431  152251\n",
       "49    L190600  0.242206  145182\n",
       "51    L101700  0.226851  158951\n",
       "52    L107400  0.222615  148029\n",
       "55    L100200  0.220498  148627"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedColCorrCount=pd.merge(corrvalPD,colCountPD,how='inner',left_on='Col',right_on='Col')\n",
    "mergedColCorrCount=mergedColCorrCount[mergedColCorrCount.Count>50000]\n",
    "mergedColCorrCount=mergedColCorrCount.sort_values(by='val', ascending=False)\n",
    "mergedColCorrCount.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L190300_y', 'L190300_x', 'L190500', 'L190400', 'SEX', 'S000100', 'L100700', 'L100500', 'S000300', 'L103300', 'S000501', 'L103100', 'S000502', 'L101300', 'L103000', 'L101600', 'L190600', 'L101700', 'L107400', 'L100200']\n"
     ]
    }
   ],
   "source": [
    "print(list(mergedColCorrCount.head(20).Col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anova test - For categorical values [Questionnaire answers]\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset=data.copy()[categorical_cols] #[np.insert(categorical_cols,0,'L100800')]\n",
    "\n",
    "# mydataset=mydataset.drop(columns=['FIELD_1','FIELD_2','FIELD_8','FIELD_10','FIELD_11','FIELD_12','FIELD_39','FIELD_88',\n",
    "#                            'FIELD_89','FIELD_109','FIELD_110','FIELD_111','FIELD_70','FIELD_82','FIELD_85','FIELD_91',\n",
    "#                            'FIELD_103','FIELD_106'])\n",
    "\n",
    "# mydataset=mydataset.drop(columns=['FIELD_1','FIELD_2','FIELD_87','FIELD_8','FIELD_10','FIELD_11','FIELD_12','FIELD_39',\n",
    "#                                   'FIELD_88','FIELD_89', 'FIELD_108','FIELD_109','FIELD_110','FIELD_111','FIELD_82',\n",
    "#                                  'FIELD_91','FIELD_103','FIELD_118','FIELD_119','FIELD_120','FIELD_121','FIELD_122',\n",
    "#                                  'FIELD_123','FIELD_124','FIELD_125','FIELD_126','FIELD_127','FIELD_128','FIELD_129',\n",
    "#                                  'FIELD_130','FIELD_131','FIELD_132','FIELD_133','FIELD_134','FIELD_135','FIELD_136',\n",
    "#                                   'FIELD_137','FIELD_138','FIELD_139','FIELD_140'])\n",
    "\n",
    "\n",
    "mydataset=mydataset.drop(columns=['FIELD_1','FIELD_2','FIELD_87','FIELD_8','FIELD_10','FIELD_11','FIELD_12','FIELD_39',\n",
    "                                  'FIELD_88','FIELD_89', 'FIELD_108','FIELD_109','FIELD_110','FIELD_111','FIELD_82',\n",
    "                                 'FIELD_91','FIELD_103','FIELD_118','FIELD_119','FIELD_120','FIELD_121','FIELD_122',\n",
    "                                 'FIELD_123','FIELD_124','FIELD_125','FIELD_126','FIELD_127','FIELD_128','FIELD_129',\n",
    "                                 'FIELD_130','FIELD_131','FIELD_132','FIELD_133','FIELD_134','FIELD_135','FIELD_136',\n",
    "                                  'FIELD_137','FIELD_138','FIELD_139','FIELD_140',\n",
    "                                  'FIELD_64','FIELD_65','FIELD_66','FIELD_67','FIELD_68','FIELD_69','FIELD_70','FIELD_72',\n",
    "                                  'FIELD_73','FIELD_74','FIELD_75','FIELD_76','FIELD_77','FIELD_80','FIELD_81','FIELD_84',\n",
    "                                  'FIELD_85','FIELD_90','FIELD_93','FIELD_94','FIELD_95','FIELD_96','FIELD_97','FIELD_98',\n",
    "                                  'FIELD_101','FIELD_102','FIELD_105','FIELD_106','FIELD_112','FIELD_113','FIELD_114',\n",
    "                                  'FIELD_115','FIELD_116','FIELD_117','FIELD_118','FIELD_119','FIELD_9'\n",
    "                                 ])\n",
    "\n",
    "\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_3=='`'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_3=='G'].index)\n",
    "\n",
    "\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_4=='.'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_5=='.'].index)\n",
    "\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_35=='?'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_35=='.'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_36=='.'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_37=='\\\\'].index)\n",
    " \n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_39 == '7+' ].index)\n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_39 == '5~7'].index)\n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_39 == '3-4'].index)\n",
    "\n",
    "\n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_95=='.'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 FIELD_3\n",
      "1 FIELD_4\n",
      "2 FIELD_5\n",
      "3 FIELD_13\n",
      "4 FIELD_14\n",
      "5 FIELD_15\n",
      "6 FIELD_16\n",
      "7 FIELD_17\n",
      "8 FIELD_18\n",
      "9 FIELD_19\n",
      "10 FIELD_20\n",
      "11 FIELD_21\n",
      "12 FIELD_22\n",
      "13 FIELD_23\n",
      "14 FIELD_24\n",
      "15 FIELD_25\n",
      "16 FIELD_26\n",
      "17 FIELD_27\n",
      "18 FIELD_28\n",
      "19 FIELD_29\n",
      "20 FIELD_30\n",
      "21 FIELD_31\n",
      "22 FIELD_32\n",
      "23 FIELD_33\n",
      "24 FIELD_34\n",
      "25 FIELD_35\n",
      "26 FIELD_36\n",
      "27 FIELD_37\n",
      "28 FIELD_38\n",
      "29 FIELD_40\n",
      "30 FIELD_41\n",
      "31 FIELD_42\n",
      "32 FIELD_43\n",
      "33 FIELD_44\n",
      "34 FIELD_45\n",
      "35 FIELD_46\n",
      "36 FIELD_47\n",
      "37 FIELD_48\n",
      "38 FIELD_49\n",
      "39 FIELD_50\n",
      "40 FIELD_51\n",
      "41 FIELD_52\n",
      "42 FIELD_53\n",
      "43 FIELD_54\n",
      "44 FIELD_55\n",
      "45 FIELD_56\n",
      "46 FIELD_57\n",
      "47 FIELD_58\n",
      "48 FIELD_59\n",
      "49 FIELD_60\n",
      "50 FIELD_61\n",
      "51 FIELD_62\n",
      "52 FIELD_63\n"
     ]
    }
   ],
   "source": [
    "colslist=mydataset.columns\n",
    "DiabeticColVals=data.L190300_y\n",
    "\n",
    "cor=[]\n",
    "pval=[]\n",
    "count=[]\n",
    "\n",
    "for i in range(len(colslist)):\n",
    "    print(i,colslist[i])\n",
    "    \n",
    "    temp=pd.DataFrame([])\n",
    "    temp['a']=DiabeticColVals\n",
    "    temp['b']=mydataset[colslist[i]].astype(float)\n",
    "    temp=temp.dropna()\n",
    "    count.append(temp.shape[0])\n",
    "    \n",
    "    uniquevalues=temp.b.unique()\n",
    "    \n",
    "    selectedGroupVals=[]\n",
    "    for k in range(len(uniquevalues)):\n",
    "        selectedGroupVals.append(np.asarray(temp[temp['b']==uniquevalues[k]].a))\n",
    "\n",
    "    F, p = stats.f_oneway(*selectedGroupVals)\n",
    "    cor.append(F)\n",
    "    pval.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FvalPvalCorr=pd.DataFrame()    \n",
    "FvalPvalCorr['Cols']=colslist\n",
    "FvalPvalCorr['F']=cor\n",
    "FvalPvalCorr['P']=pval\n",
    "FvalPvalCorr['Count']=count\n",
    "FvalPvalCorr=FvalPvalCorr.sort_values(by='F', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cols</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FIELD_33</td>\n",
       "      <td>4964.044303</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FIELD_38</td>\n",
       "      <td>1070.883824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>158887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FIELD_40</td>\n",
       "      <td>368.215496</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>158893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FIELD_18</td>\n",
       "      <td>263.524602</td>\n",
       "      <td>3.265370e-59</td>\n",
       "      <td>159174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FIELD_25</td>\n",
       "      <td>217.734052</td>\n",
       "      <td>3.042708e-49</td>\n",
       "      <td>159175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FIELD_29</td>\n",
       "      <td>183.058075</td>\n",
       "      <td>1.098596e-41</td>\n",
       "      <td>159174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FIELD_41</td>\n",
       "      <td>164.578913</td>\n",
       "      <td>1.292287e-243</td>\n",
       "      <td>158863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIELD_4</td>\n",
       "      <td>86.455955</td>\n",
       "      <td>3.290966e-126</td>\n",
       "      <td>156773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FIELD_42</td>\n",
       "      <td>44.232545</td>\n",
       "      <td>1.642250e-71</td>\n",
       "      <td>158842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FIELD_32</td>\n",
       "      <td>23.229836</td>\n",
       "      <td>9.419573e-32</td>\n",
       "      <td>158679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cols            F              P   Count\n",
       "23  FIELD_33  4964.044303   0.000000e+00  158879\n",
       "28  FIELD_38  1070.883824   0.000000e+00  158887\n",
       "29  FIELD_40   368.215496   0.000000e+00  158893\n",
       "8   FIELD_18   263.524602   3.265370e-59  159174\n",
       "15  FIELD_25   217.734052   3.042708e-49  159175\n",
       "19  FIELD_29   183.058075   1.098596e-41  159174\n",
       "30  FIELD_41   164.578913  1.292287e-243  158863\n",
       "1    FIELD_4    86.455955  3.290966e-126  156773\n",
       "31  FIELD_42    44.232545   1.642250e-71  158842\n",
       "22  FIELD_32    23.229836   9.419573e-32  158679"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FvalPvalCorr[FvalPvalCorr.Count>50000].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_18', 'FIELD_25', 'FIELD_29', 'FIELD_41', 'FIELD_4', 'FIELD_42', 'FIELD_32']\n"
     ]
    }
   ],
   "source": [
    "print(list(FvalPvalCorr[FvalPvalCorr.Count>50000].Cols)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================= LASSO method\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124360, 30)\n"
     ]
    }
   ],
   "source": [
    "selectedcols=['L190300_y', 'L190300_x', 'L190500', 'L190400', 'SEX', 'S000100', 'L100700', 'L100500', 'S000300', \n",
    "              'L103300', 'S000501', 'L103100', 'S000502', 'L101300', 'L103000', 'L101600', 'L190600', 'L101700', \n",
    "              'L107400', 'L100200','FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_18', 'FIELD_25', 'FIELD_29', \n",
    "              'FIELD_41', 'FIELD_4', 'FIELD_42', 'FIELD_32'\n",
    "             ]\n",
    "data2=data[selectedcols].copy().dropna()\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data2[[ 'L190300_x', 'L190500', 'L190400', 'SEX', 'S000100', 'L100700', 'L100500', 'S000300', \n",
    "              'L103300', 'S000501', 'L103100', 'S000502', 'L101300', 'L103000', 'L101600', 'L190600', 'L101700', \n",
    "              'L107400', 'L100200','FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_18', 'FIELD_25', 'FIELD_29', \n",
    "              'FIELD_41', 'FIELD_4', 'FIELD_42', 'FIELD_32'\n",
    "        ]]\n",
    "y=data2.L190500_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(x,y)\n",
    "\n",
    "print(clf.coef_)\n",
    "\n",
    "print(clf.intercept_)  \n",
    "\n",
    "# pd.DataFrame([x.columns.ravel(),clf.coef_.ravel()],columns=['Name','coeff'])\n",
    "\n",
    "lassod=pd.DataFrame()\n",
    "lassod['Name']=x.columns\n",
    "lassod['coeff']=clf.coef_\n",
    "lassod\n",
    "\n",
    "lassod=lassod.drop(lassod[lassod.coeff==0].index)\n",
    "lassod.coeff=abs(lassod.coeff)\n",
    "lassod=lassod.sort_values(by='coeff', ascending=False)\n",
    "lassod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(lassod.Name[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================== SelectKBest method\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=f_regression, k=10)\n",
    "fit = bestfeatures.fit(x,y)\n",
    "\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "\n",
    "# x=x[x.columns[:15]]\n",
    "print(list(x.columns[:16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================= LinearSVC\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(x, y)\n",
    "# model = SelectFromModel(lsvc, prefit=True)\n",
    "# X_new = model.transform(x)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================ SequentialFeatureSelector \n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# lr = RandomForestRegressor()\n",
    "\n",
    "# sfs = SFS(lr, \n",
    "#           k_features=13, \n",
    "#           forward=True, \n",
    "#           floating=False, \n",
    "#           scoring='neg_mean_squared_error',\n",
    "#           cv=5)\n",
    "\n",
    "# sfs = sfs.fit(x, y)\n",
    "# fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "# plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================= feature_importances\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(16).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================= Backward Elimination\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.regression.linear_model as sm\n",
    "temp=x.copy()\n",
    "temp['const']=np.ones((x.shape[0],1))\n",
    "regressor_OLS = sm.OLS(endog = y, exog = temp).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=temp.drop(columns=['L103100', 'S000300','L190400','L102900','L101300','S000501','S000502','L100500','FIELD_40',\n",
    "#                         'FIELD_41','FIELD_29','FIELD_18','FIELD_31','FIELD_27','FIELD_25','SEX'])\n",
    "# regressor_OLS = sm.OLS(endog = y, exog = temp).fit()\n",
    "# regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=temp.drop(columns=['FIELD_33'])\n",
    "# regressor_OLS = sm.OLS(endog = y, exog = temp).fit()\n",
    "# regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.columns.shape)\n",
    "temp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================== Check Variance inflation factor and multi collinearity\n",
    "==================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppd=pd.DataFrame(data2[['S000501_x', 'S000502', 'S000300', 'SEX', 'L190400', 'L190300', 'L190500', 'L100700', \n",
    "              'L103300', 'L100500', 'S000100', 'L100800', 'L103000', 'L101700', 'L101300', 'L103100', 'max',\n",
    "              'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_29', 'FIELD_41', 'FIELD_27', 'FIELD_42', 'FIELD_5', \n",
    "              'FIELD_18', 'FIELD_25'\n",
    "                          ]]).dropna()  \n",
    "temppd['y']=data.S000501_y\n",
    " \n",
    "\n",
    "corr = (temppd.corr())\n",
    "sns.heatmap(corr, vmin=-1, vmax=1) \n",
    "\n",
    "corr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vifcal(inputdata,depcol):\n",
    "    vifL5=[]\n",
    "    import statsmodels.formula.api as sm\n",
    "    xvars=inputdata.drop([depcol],axis=1)\n",
    "    xvarnames=xvars.columns\n",
    "    for i in range(0,xvarnames.shape[0]):\n",
    "        _y=xvars[xvarnames[i]]\n",
    "        _x=xvars[xvarnames.drop(xvarnames[i])]\n",
    "        rsq=sm.ols(formula=\"_y~_x\",data=xvars).fit().rsquared\n",
    "        vif=round(1/(1-rsq),2)\n",
    "        print(i,', ',xvarnames[i],\" VIF = \",vif)\n",
    "        if(vif<5):\n",
    "            vifL5.append(xvarnames[i])\n",
    "    return vifL5\n",
    "    \n",
    "    \n",
    "newcols = vifcal(temppd,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newcols,len(newcols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
