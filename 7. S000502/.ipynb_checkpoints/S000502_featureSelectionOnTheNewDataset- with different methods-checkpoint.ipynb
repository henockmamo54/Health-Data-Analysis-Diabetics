{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('../_xlable4_withNa_AllColumns.txt')\n",
    "y=pd.read_csv('../_targelable4_withNa_AllColumns.txt')\n",
    "\n",
    "y=y[['Unnamed: 0','S000502']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.merge(x,y, how='inner',left_on='Unnamed: 0', right_on='Unnamed: 0')\n",
    "data['max']=np.min(data[['FIELD_6','FIELD_7']],axis=1)\n",
    "data=data.drop(columns=['FIELD_6','FIELD_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.query('FIELD_15 !=1 and FIELD_17 !=1 and FIELD_22 != 1 and FIELD_24 != 1 and FIELD_16 != 1 and FIELD_23 != 1')\n",
    "# data=data.query('FIELD_16 != 1 and FIELD_23 != 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=data[data.SEX==0]\n",
    "# data=data[data.FIELD_15!=1]\n",
    "# data=data[data.FIELD_17!=1]\n",
    "# data=data[data.FIELD_22!=1]\n",
    "# data=data[data.FIELD_24!=1]\n",
    "# data=data[data.AGE>=40]\n",
    "# data=data[data.AGE<50]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split column types to categorical and numerical\n",
    "numerical_cols = list(data.columns[~data.columns.str.startswith('FIELD')])\n",
    "categorical_cols = list(data.columns[data.columns.str.startswith('FIELD')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation Value - for numerical values\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>S000502_y</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>L393800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>L122000</td>\n",
       "      <td>0.895956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>L501900</td>\n",
       "      <td>0.858531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>L359000</td>\n",
       "      <td>0.800269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Col       val\n",
       "278  S000502_y  1.000000\n",
       "134    L393800  1.000000\n",
       "71     L122000  0.895956\n",
       "153    L501900  0.858531\n",
       "129    L359000  0.800269"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=data[numerical_cols].corr()\n",
    "corr=corr.S000502_y\n",
    "corrvalPD=pd.DataFrame()\n",
    "corrvalPD['Col']=corr.index\n",
    "corrvalPD['val']=abs(corr.values)\n",
    "\n",
    "corrvalPD=corrvalPD.sort_values(by='val',ascending=False)\n",
    "corrvalPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of none NA values of feature set\n",
    "mydataset=data.copy()[numerical_cols]\n",
    "colCount=[]\n",
    "for i in mydataset.columns:\n",
    "    colCount.append([i,mydataset[i].dropna().shape[0]])\n",
    "\n",
    "colCountPD=pd.DataFrame(colCount,columns=['Col','Count'])\n",
    "colCountPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedColCorrCount=pd.merge(corrvalPD,colCountPD,how='inner',left_on='Col',right_on='Col')\n",
    "mergedColCorrCount=mergedColCorrCount[mergedColCorrCount.Count>50000]\n",
    "mergedColCorrCount=mergedColCorrCount.sort_values(by='val', ascending=False)\n",
    "mergedColCorrCount.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mergedColCorrCount.head(18).Col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anova test - For categorical values [Questionnaire answers]\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset=data.copy()[categorical_cols] #[np.insert(categorical_cols,0,'L100800')]\n",
    "\n",
    "# mydataset=mydataset.drop(columns=['FIELD_1','FIELD_2','FIELD_8','FIELD_10','FIELD_11','FIELD_12','FIELD_39','FIELD_88',\n",
    "#                            'FIELD_89','FIELD_109','FIELD_110','FIELD_111','FIELD_70','FIELD_82','FIELD_85','FIELD_91',\n",
    "#                            'FIELD_103','FIELD_106'])\n",
    "\n",
    "# mydataset=mydataset.drop(columns=['FIELD_1','FIELD_2','FIELD_87','FIELD_8','FIELD_10','FIELD_11','FIELD_12','FIELD_39',\n",
    "#                                   'FIELD_88','FIELD_89', 'FIELD_108','FIELD_109','FIELD_110','FIELD_111','FIELD_82',\n",
    "#                                  'FIELD_91','FIELD_103','FIELD_118','FIELD_119','FIELD_120','FIELD_121','FIELD_122',\n",
    "#                                  'FIELD_123','FIELD_124','FIELD_125','FIELD_126','FIELD_127','FIELD_128','FIELD_129',\n",
    "#                                  'FIELD_130','FIELD_131','FIELD_132','FIELD_133','FIELD_134','FIELD_135','FIELD_136',\n",
    "#                                   'FIELD_137','FIELD_138','FIELD_139','FIELD_140'])\n",
    "\n",
    "\n",
    "mydataset=mydataset.drop(columns=['FIELD_1','FIELD_2','FIELD_87','FIELD_8','FIELD_10','FIELD_11','FIELD_12','FIELD_39',\n",
    "                                  'FIELD_88','FIELD_89', 'FIELD_108','FIELD_109','FIELD_110','FIELD_111','FIELD_82',\n",
    "                                 'FIELD_91','FIELD_103','FIELD_118','FIELD_119','FIELD_120','FIELD_121','FIELD_122',\n",
    "                                 'FIELD_123','FIELD_124','FIELD_125','FIELD_126','FIELD_127','FIELD_128','FIELD_129',\n",
    "                                 'FIELD_130','FIELD_131','FIELD_132','FIELD_133','FIELD_134','FIELD_135','FIELD_136',\n",
    "                                  'FIELD_137','FIELD_138','FIELD_139','FIELD_140',\n",
    "                                  'FIELD_64','FIELD_65','FIELD_66','FIELD_67','FIELD_68','FIELD_69','FIELD_70','FIELD_72',\n",
    "                                  'FIELD_73','FIELD_74','FIELD_75','FIELD_76','FIELD_77','FIELD_80','FIELD_81','FIELD_84',\n",
    "                                  'FIELD_85','FIELD_90','FIELD_93','FIELD_94','FIELD_95','FIELD_96','FIELD_97','FIELD_98',\n",
    "                                  'FIELD_101','FIELD_102','FIELD_105','FIELD_106','FIELD_112','FIELD_113','FIELD_114',\n",
    "                                  'FIELD_115','FIELD_116','FIELD_117','FIELD_118','FIELD_119','FIELD_9'\n",
    "                                 ])\n",
    "\n",
    "\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_3=='`'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_3=='G'].index)\n",
    "\n",
    "\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_4=='.'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_5=='.'].index)\n",
    "\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_35=='?'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_35=='.'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_36=='.'].index)\n",
    "mydataset=mydataset.drop(mydataset[mydataset.FIELD_37=='\\\\'].index)\n",
    " \n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_39 == '7+' ].index)\n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_39 == '5~7'].index)\n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_39 == '3-4'].index)\n",
    "\n",
    "\n",
    "# mydataset=mydataset.drop(mydataset[mydataset.FIELD_95=='.'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colslist=mydataset.columns\n",
    "DiabeticColVals=data.S000501_y\n",
    "\n",
    "cor=[]\n",
    "pval=[]\n",
    "count=[]\n",
    "\n",
    "for i in range(len(colslist)):\n",
    "    print(i,colslist[i])\n",
    "    \n",
    "    temp=pd.DataFrame([])\n",
    "    temp['a']=DiabeticColVals\n",
    "    temp['b']=mydataset[colslist[i]].astype(float)\n",
    "    temp=temp.dropna()\n",
    "    count.append(temp.shape[0])\n",
    "    \n",
    "    uniquevalues=temp.b.unique()\n",
    "    \n",
    "    selectedGroupVals=[]\n",
    "    for k in range(len(uniquevalues)):\n",
    "        selectedGroupVals.append(np.asarray(temp[temp['b']==uniquevalues[k]].a))\n",
    "\n",
    "    F, p = stats.f_oneway(*selectedGroupVals)\n",
    "    cor.append(F)\n",
    "    pval.append(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FvalPvalCorr=pd.DataFrame()    \n",
    "FvalPvalCorr['Cols']=colslist\n",
    "FvalPvalCorr['F']=cor\n",
    "FvalPvalCorr['P']=pval\n",
    "FvalPvalCorr['Count']=count\n",
    "FvalPvalCorr=FvalPvalCorr.sort_values(by='F', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FvalPvalCorr[FvalPvalCorr.Count>50000].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(FvalPvalCorr[FvalPvalCorr.Count>50000].Cols)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================= LASSO method\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedcols=['S000501_y', 'S000501_x', 'S000502', 'S000300', 'SEX', 'L190400', 'L190300', 'L190500', 'L100700', \n",
    "              'L103300', 'L100500', 'S000100', 'L100800', 'L103000', 'L101700', 'L101300', 'L103100', 'max',\n",
    "              'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_29', 'FIELD_41', 'FIELD_27', 'FIELD_42', 'FIELD_5', \n",
    "              'FIELD_18', 'FIELD_25'\n",
    "             ]\n",
    "data2=data[selectedcols].copy().dropna()\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data2[['S000501_x', 'S000502', 'S000300', 'SEX', 'L190400', 'L190300', 'L190500', 'L100700', \n",
    "              'L103300', 'L100500', 'S000100', 'L100800', 'L103000', 'L101700', 'L101300', 'L103100', 'max',\n",
    "              'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_29', 'FIELD_41', 'FIELD_27', 'FIELD_42', 'FIELD_5', \n",
    "              'FIELD_18', 'FIELD_25'\n",
    "        ]]\n",
    "y=data2.S000501_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(x,y)\n",
    "\n",
    "print(clf.coef_)\n",
    "\n",
    "print(clf.intercept_)  \n",
    "\n",
    "# pd.DataFrame([x.columns.ravel(),clf.coef_.ravel()],columns=['Name','coeff'])\n",
    "\n",
    "lassod=pd.DataFrame()\n",
    "lassod['Name']=x.columns\n",
    "lassod['coeff']=clf.coef_\n",
    "lassod\n",
    "\n",
    "lassod=lassod.drop(lassod[lassod.coeff==0].index)\n",
    "lassod.coeff=abs(lassod.coeff)\n",
    "lassod=lassod.sort_values(by='coeff', ascending=False)\n",
    "lassod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(lassod.Name[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================== SelectKBest method\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=f_regression, k=10)\n",
    "fit = bestfeatures.fit(x,y)\n",
    "\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "\n",
    "# x=x[x.columns[:15]]\n",
    "print(list(x.columns[:16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================= LinearSVC\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(x, y)\n",
    "# model = SelectFromModel(lsvc, prefit=True)\n",
    "# X_new = model.transform(x)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================ SequentialFeatureSelector \n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# lr = RandomForestRegressor()\n",
    "\n",
    "# sfs = SFS(lr, \n",
    "#           k_features=13, \n",
    "#           forward=True, \n",
    "#           floating=False, \n",
    "#           scoring='neg_mean_squared_error',\n",
    "#           cv=5)\n",
    "\n",
    "# sfs = sfs.fit(x, y)\n",
    "# fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "# plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================= feature_importances\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(16).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================= Backward Elimination\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.regression.linear_model as sm\n",
    "temp=x.copy()\n",
    "temp['const']=np.ones((x.shape[0],1))\n",
    "regressor_OLS = sm.OLS(endog = y, exog = temp).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=temp.drop(columns=['L103100', 'S000300','L190400','L102900','L101300','S000501','S000502','L100500','FIELD_40',\n",
    "#                         'FIELD_41','FIELD_29','FIELD_18','FIELD_31','FIELD_27','FIELD_25','SEX'])\n",
    "# regressor_OLS = sm.OLS(endog = y, exog = temp).fit()\n",
    "# regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=temp.drop(columns=['FIELD_33'])\n",
    "# regressor_OLS = sm.OLS(endog = y, exog = temp).fit()\n",
    "# regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.columns.shape)\n",
    "temp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================== Check Variance inflation factor and multi collinearity\n",
    "==================== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppd=pd.DataFrame(data2[['S000501_x', 'S000502', 'S000300', 'SEX', 'L190400', 'L190300', 'L190500', 'L100700', \n",
    "              'L103300', 'L100500', 'S000100', 'L100800', 'L103000', 'L101700', 'L101300', 'L103100', 'max',\n",
    "              'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_29', 'FIELD_41', 'FIELD_27', 'FIELD_42', 'FIELD_5', \n",
    "              'FIELD_18', 'FIELD_25'\n",
    "                          ]]).dropna()  \n",
    "temppd['y']=data.S000501_y\n",
    " \n",
    "\n",
    "corr = (temppd.corr())\n",
    "sns.heatmap(corr, vmin=-1, vmax=1) \n",
    "\n",
    "corr.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vifcal(inputdata,depcol):\n",
    "    vifL5=[]\n",
    "    import statsmodels.formula.api as sm\n",
    "    xvars=inputdata.drop([depcol],axis=1)\n",
    "    xvarnames=xvars.columns\n",
    "    for i in range(0,xvarnames.shape[0]):\n",
    "        _y=xvars[xvarnames[i]]\n",
    "        _x=xvars[xvarnames.drop(xvarnames[i])]\n",
    "        rsq=sm.ols(formula=\"_y~_x\",data=xvars).fit().rsquared\n",
    "        vif=round(1/(1-rsq),2)\n",
    "        print(i,', ',xvarnames[i],\" VIF = \",vif)\n",
    "        if(vif<5):\n",
    "            vifL5.append(xvarnames[i])\n",
    "    return vifL5\n",
    "    \n",
    "    \n",
    "newcols = vifcal(temppd,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newcols,len(newcols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
