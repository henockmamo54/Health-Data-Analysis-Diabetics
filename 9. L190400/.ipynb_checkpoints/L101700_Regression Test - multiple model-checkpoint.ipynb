{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159381, 29)\n",
      "(159381, 29)\n"
     ]
    }
   ],
   "source": [
    "x_original=pd.read_csv('_xlable4_withNa_AllColumns.txt')\n",
    "y_original=pd.read_csv('_targelable4_withNa_AllColumns.txt')\n",
    "\n",
    "x_original=x_original[['Unnamed: 0','L101700', 'L101300', 'L103000', 'L100700', 'SEX', 'L101200', 'L190400', 'L190500', \n",
    "                       'L101600', 'S000300', 'L103300', 'S000501', 'S000502', 'L100800', 'L190300', 'AGE', 'S000100',\n",
    "                       'FIELD_33', 'FIELD_38', 'FIELD_7', 'FIELD_40', 'FIELD_6', 'FIELD_18', 'FIELD_29', 'FIELD_41', \n",
    "                       'FIELD_21', 'FIELD_25', 'FIELD_27']]\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','L101700', 'L101300', 'L103000', 'L100700', 'SEX', 'L101200', 'L190400', 'L190500', \n",
    "                       'L101600', 'S000300', 'L103300', 'S000501', 'S000502', 'L100800', 'L190300', 'AGE', 'S000100',\n",
    "                       'FIELD_33', 'FIELD_38', 'FIELD_7', 'FIELD_40', 'FIELD_6', 'FIELD_18', 'FIELD_29', 'FIELD_41', \n",
    "                       'FIELD_21', 'FIELD_25', 'FIELD_27']]\n",
    "\n",
    "print(x_original.shape)\n",
    "print(y_original.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 159381\n",
      "L101700 158951\n",
      "L101300 159247\n",
      "L103000 158939\n",
      "L100700 152474\n",
      "SEX 159381\n",
      "L101200 159247\n",
      "L190400 159241\n",
      "L190500 159204\n",
      "L101600 152251\n",
      "S000300 159075\n",
      "L103300 135222\n",
      "S000501 159305\n",
      "S000502 159305\n",
      "L100800 159236\n",
      "L190300 159204\n",
      "AGE 159381\n",
      "S000100 159302\n",
      "FIELD_33 159069\n",
      "FIELD_38 159077\n",
      "FIELD_7 58317\n",
      "FIELD_40 159083\n",
      "FIELD_6 47002\n",
      "FIELD_18 159365\n",
      "FIELD_29 159365\n",
      "FIELD_41 159053\n",
      "FIELD_21 159366\n",
      "FIELD_25 159366\n",
      "FIELD_27 159365\n"
     ]
    }
   ],
   "source": [
    "for index,col in enumerate(x_original.columns):\n",
    "    print(col,x_original[col].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=x_original.copy()\n",
    "conditions = [\n",
    "    (df.S000501 < 120)  ,\n",
    "    (df.S000501 >= 120) & (df.S000501 < 130),\n",
    "    (df.S000501 >=130)]\n",
    "choices = [0,1,2]\n",
    "df['sbpG'] = np.select(conditions, choices, default=0)\n",
    "df.head()\n",
    "x_original=df.copy()\n",
    "\n",
    "conditions2 = [\n",
    "    (df.S000502 < 80)  ,\n",
    "    (df.S000502 >= 80) & (df.S000502 < 90),\n",
    "    (df.S000502 >=90)]\n",
    "choices2 = [0,1,2]\n",
    "df['dbpG'] = np.select(conditions2, choices2, default=0)\n",
    "df.head()\n",
    "x_original=df.copy()\n",
    "\n",
    "conditions3 = [\n",
    "    (df.AGE < 30)  ,\n",
    "    (df.AGE >= 30) & (df.AGE < 40),\n",
    "    (df.AGE >= 40) & (df.AGE < 50),\n",
    "    (df.AGE >= 50) & (df.AGE < 60),\n",
    "    (df.AGE >= 60)]\n",
    "choices3 = [0,1,2,3,4]\n",
    "df['AgeG'] = np.select(conditions3, choices3, default=0)\n",
    "df.head()\n",
    "x_original=df.copy()\n",
    "\n",
    "\n",
    "conditions4 = [\n",
    "    (df.L100800 < 100)  ,\n",
    "    (df.L100800 >= 100) & (df.L100800 < 126), \n",
    "    (df.L100800 >= 126)]\n",
    "choices4 = [0,1,2]\n",
    "df['CLASS'] = np.select(conditions4, choices4, default=0)\n",
    "df.head()\n",
    "x_original=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35987, 62)\n"
     ]
    }
   ],
   "source": [
    "data= pd.merge(x_original,y_original, how='inner',left_on='Unnamed: 0', right_on='Unnamed: 0')\n",
    "data=data.dropna(). reset_index()\n",
    "\n",
    "# data=data[data.AGE_x >= 40]\n",
    "# data=data[data.AGE_x < 50]\n",
    "\n",
    "# data=data[data.CLASS_x==0]\n",
    "# data=data[data.sbpG==0]\n",
    "# data=data[data.dbpG==0]\n",
    "\n",
    "# data=data[data.L100800_y <200]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35987, 62)\n",
      "Index(['index', 'Unnamed: 0', 'L101700_x', 'L101300_x', 'L103000_x',\n",
      "       'L100700_x', 'SEX_x', 'L101200_x', 'L190400_x', 'L190500_x',\n",
      "       'L101600_x', 'S000300_x', 'L103300_x', 'S000501_x', 'S000502_x',\n",
      "       'L100800_x', 'L190300_x', 'AGE_x', 'S000100_x', 'FIELD_33_x',\n",
      "       'FIELD_38_x', 'FIELD_7_x', 'FIELD_40_x', 'FIELD_6_x', 'FIELD_18_x',\n",
      "       'FIELD_29_x', 'FIELD_41_x', 'FIELD_21_x', 'FIELD_25_x', 'FIELD_27_x',\n",
      "       'sbpG', 'dbpG', 'AgeG', 'CLASS', 'L101700_y', 'L101300_y', 'L103000_y',\n",
      "       'L100700_y', 'SEX_y', 'L101200_y', 'L190400_y', 'L190500_y',\n",
      "       'L101600_y', 'S000300_y', 'L103300_y', 'S000501_y', 'S000502_y',\n",
      "       'L100800_y', 'L190300_y', 'AGE_y', 'S000100_y', 'FIELD_33_y',\n",
      "       'FIELD_38_y', 'FIELD_7_y', 'FIELD_40_y', 'FIELD_6_y', 'FIELD_18_y',\n",
      "       'FIELD_29_y', 'FIELD_41_y', 'FIELD_21_y', 'FIELD_25_y', 'FIELD_27_y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L101300_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>SEX_x</th>\n",
       "      <th>L101200_x</th>\n",
       "      <th>L190400_x</th>\n",
       "      <th>L190500_x</th>\n",
       "      <th>...</th>\n",
       "      <th>FIELD_38_y</th>\n",
       "      <th>FIELD_7_y</th>\n",
       "      <th>FIELD_40_y</th>\n",
       "      <th>FIELD_6_y</th>\n",
       "      <th>FIELD_18_y</th>\n",
       "      <th>FIELD_29_y</th>\n",
       "      <th>FIELD_41_y</th>\n",
       "      <th>FIELD_21_y</th>\n",
       "      <th>FIELD_25_y</th>\n",
       "      <th>FIELD_27_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>40.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>38.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>39.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  L101700_x  L101300_x  L103000_x  L100700_x  SEX_x  \\\n",
       "0      1           1       14.0        9.0       53.0        3.0    1.0   \n",
       "1      2           2       15.0       10.0       41.0        3.8    1.0   \n",
       "2      3           3       10.0       12.0       58.0        3.7    1.0   \n",
       "3      4           4       12.0       12.0       50.0        3.4    1.0   \n",
       "4      6           6       17.0        9.0       44.0        3.1    1.0   \n",
       "\n",
       "   L101200_x  L190400_x  L190500_x  ...  FIELD_38_y  FIELD_7_y  FIELD_40_y  \\\n",
       "0       21.0       13.1       39.0  ...         2.0        1.0         1.0   \n",
       "1       19.0       12.9       38.4  ...         2.0        1.0         0.0   \n",
       "2       15.0       13.5       40.3  ...         0.0        2.0         1.0   \n",
       "3       16.0       12.6       38.6  ...         0.0        2.0         0.0   \n",
       "4       13.0       13.3       39.5  ...         0.0        1.0         1.0   \n",
       "\n",
       "   FIELD_6_y  FIELD_18_y  FIELD_29_y  FIELD_41_y  FIELD_21_y  FIELD_25_y  \\\n",
       "0        2.0         0.0         0.0         2.0         0.0         0.0   \n",
       "1        2.0         0.0         0.0         3.0         0.0         0.0   \n",
       "2        2.0         0.0         0.0         3.0         0.0         0.0   \n",
       "3        2.0         0.0         1.0         5.0         0.0         0.0   \n",
       "4        2.0         0.0         1.0         2.0         0.0         0.0   \n",
       "\n",
       "   FIELD_27_y  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         1.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[['L101700_x', 'L101300_x', 'L103000_x', 'L100700_x', 'SEX_x', 'L101200_x', 'L190400_x', 'L190500_x', \n",
    "        'L101600_x', 'S000300_x', 'L103300_x', 'S000501_x', 'S000502_x', 'L100800_x', 'L190300_x', 'AGE_x', 'S000100_x',\n",
    "        'FIELD_33_x', 'FIELD_38_x', 'FIELD_7_x', 'FIELD_40_x', 'FIELD_6_x', 'FIELD_18_x', 'FIELD_29_x', 'FIELD_41_x', \n",
    "        'FIELD_21_x', 'FIELD_25_x', 'FIELD_27_x',\n",
    "        'CLASS','sbpG','dbpG','AgeG']]\n",
    "\n",
    "y=data[['L101700_y', 'L101300_y', 'L103000_y', 'L100700_y', 'SEX_y', 'L101200_y', 'L190400_y', 'L190500_y', \n",
    "        'L101600_y', 'S000300_y', 'L103300_y', 'S000501_y', 'S000502_y', 'L100800_y', 'L190300_y', 'AGE_y', 'S000100_y',\n",
    "        'FIELD_33_y', 'FIELD_38_y', 'FIELD_7_y', 'FIELD_40_y', 'FIELD_6_y', 'FIELD_18_y', 'FIELD_29_y', 'FIELD_41_y', \n",
    "        'FIELD_21_y', 'FIELD_25_y', 'FIELD_27_y'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the correlation of the selected feature with the independent variables\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'S000501_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-95061f30a495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtemppd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtemppd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS000501_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtemppd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcorval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemppd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'S000501_y'"
     ]
    }
   ],
   "source": [
    "temppd=pd.DataFrame(x.copy())\n",
    "temppd['y']=y.S000501_y\n",
    "temppd.head()\n",
    "corval=abs(temppd.corr()).sort_values(by='y', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corval.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram plot of the features\n",
    "# import matplotlib.pyplot as plt\n",
    "# x[x.dtypes[(x.dtypes==\"float64\")|(x.dtypes==\"int64\")]\n",
    "#                         .index.values].hist(figsize=[11,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=8)\n",
    "# pca.fit(x)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)   \n",
    "# print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# x=pca.fit_transform(x) \n",
    "# print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()  #StandardScaler()\n",
    "# x = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustring test\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# K = range(1,10)\n",
    "# distortions = []\n",
    "\n",
    "# for k in K:\n",
    "#     kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "#     kmeanModel.fit(x)\n",
    "#     distortions.append(sum(np.min(cdist(x, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / x.shape[0])\n",
    "\n",
    "# # Plot the elbow\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "# x['lbl']=kmeanModel.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylable=y[['S000501_y']]  \n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x, ylable, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=7, random_state=0,verbose =0,n_estimators=500)\n",
    "regr.fit(xtrain, ytrain) \n",
    "print(regr.feature_importances_)\n",
    "ypred=regr.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(30)\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempdata=pd.DataFrame(xtest.copy())\n",
    "# tempdata['ytest']=ytest\n",
    "# # temp=temp.dropna()\n",
    "# # tempdata.head()\n",
    "# # tempdata[tempdata.ytest.isna()].index\n",
    "\n",
    "# tempdata=tempdata.drop(tempdata[tempdata.ytest.isna()].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg boost\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor()\n",
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, \n",
    "#                           learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred = xg_reg.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "# ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "# ypredPD['t + 1']=ytest.values\n",
    "# ypredPD['pred (t +1)']=ypred\n",
    "# ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytest[ytest.isna()].shape\n",
    "# tempdata.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(input_dim=32,units=128,activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=128, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform'))\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam', metrics=['mean_squared_error' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h=model.fit(xtrain, ytrain, validation_split=.2,epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=h\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPD['diff']=abs(ypredPD['t + 1']- ypredPD['pred (t +1)'])\n",
    "print(np.mean(ypredPD['diff']))\n",
    "print(np.std(ypredPD['diff']))\n",
    "print(100*ypredPD[ypredPD['diff']<=5].shape[0]/ypredPD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# svr_rbf = SVR(kernel='rbf', C=10, gamma=0.02, epsilon=.001)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=svr_rbf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
