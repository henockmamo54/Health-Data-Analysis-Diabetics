{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import itertools\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Read the dataset and preprocess\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','L103000','S000300','L101700','L100700','FIELD_33',\n",
    "                       'FIELD_38','FIELD_40','FIELD_31','SEX','AGE',#'CLASS',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56542, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[['L100800','L104600', 'L103000', 'S000300', 'L101700', 'L100700',\n",
    "       'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_31', 'SEX', 'AGE','CLASS']]\n",
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 17331 38166\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0]\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17131, 1: 17131, 0: 17131})\n",
      "17131 17131 17131\n",
      "(51393, 12) (51393,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[6,7,8,9,10],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Generate the classifier models based on the selected 12 features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "rf_12 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100, \n",
    "    max_depth=12,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "xgb_model_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "SVC_clf_12=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr\n",
    "lr_12=LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "kneigh_12 = KNeighborsClassifier(n_neighbors=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking classfier\n",
    "\n",
    "lr2_12 = LogisticRegression()\n",
    "temprf_12=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2_12=RandomForestClassifier()\n",
    "tempsvC_12= SVC()\n",
    "\n",
    "estimators_12 = [\n",
    "    rf_12,\n",
    "    xgb_model_12,\n",
    "    SVC_clf_12,\n",
    "    lr_12,\n",
    "    kneigh_12\n",
    "]\n",
    "stackingc_12 = StackingClassifier(\n",
    "    classifiers=estimators_12,\n",
    "    meta_classifier=tempsvC_12,\n",
    "    verbose=2 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=12,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=10,\n",
       "                                                       min_samples_split=3,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_...\n",
       "                   drop_last_proba=False,\n",
       "                   meta_classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                       coef0=0.0, decision_function_shape='ovr',\n",
       "                                       degree=3, gamma='auto_deprecated',\n",
       "                                       kernel='rbf', max_iter=-1,\n",
       "                                       probability=False, random_state=None,\n",
       "                                       shrinking=True, tol=0.001,\n",
       "                                       verbose=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackingc_12.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   51    1\n",
       "1   54  128   18\n",
       "2    4   30  166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackingc_12.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Generate the classifier models based on the selected 5 features\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100, \n",
    "    max_depth=12,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_5 = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf_5=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_5=LogisticRegression(random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneigh_5 = KNeighborsClassifier(n_neighbors=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_5 = LogisticRegression()\n",
    "temprf_5=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2_5=RandomForestClassifier()\n",
    "tempsvC_5= SVC()\n",
    "\n",
    "estimators_5 = [\n",
    "    rf_5,\n",
    "    xgb_model_5,\n",
    "    SVC_clf_5,\n",
    "    lr_5,\n",
    "    kneigh_5\n",
    "]\n",
    "stackingc_5 = StackingClassifier(\n",
    "    classifiers=estimators_5, \n",
    "    meta_classifier=tempsvC_5,\n",
    "    verbose=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softmax', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=12,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=10,\n",
       "                                                       min_samples_split=3,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_...\n",
       "                   drop_last_proba=False,\n",
       "                   meta_classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                       coef0=0.0, decision_function_shape='ovr',\n",
       "                                       degree=3, gamma='auto_deprecated',\n",
       "                                       kernel='rbf', max_iter=-1,\n",
       "                                       probability=False, random_state=None,\n",
       "                                       shrinking=True, tol=0.001,\n",
       "                                       verbose=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackingc_5.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   51    1\n",
       "1   54  128   18\n",
       "2    4   30  166"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackingc_5.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.64      0.63       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  150   49    1\n",
       "1   54  120   26\n",
       "2    3   25  172"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=stackingc_5.clfs_[2].predict((xtest))\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Generate multiple weak models using the existing features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "combcols=(list(combinations(np.arange(0,12,1), 5)))\n",
    "len(combcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakmodles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(combcols)):\n",
    "#     print(combcols[i])\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=combcols[i]), xgb_model_5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf1 = StackingCVClassifier(classifiers=weakmodles,verbose=2,\n",
    "                           meta_classifier=LogisticRegression(),random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 792 classifiers...\n",
      "Fitting classifier1: pipeline (1/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: pipeline (2/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: pipeline (3/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier4: pipeline (4/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier5: pipeline (5/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier6: pipeline (6/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier7: pipeline (7/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier8: pipeline (8/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier9: pipeline (9/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier10: pipeline (10/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier11: pipeline (11/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier12: pipeline (12/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier13: pipeline (13/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier14: pipeline (14/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier15: pipeline (15/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier16: pipeline (16/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier17: pipeline (17/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier18: pipeline (18/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier19: pipeline (19/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier20: pipeline (20/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier21: pipeline (21/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier22: pipeline (22/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier23: pipeline (23/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier24: pipeline (24/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier25: pipeline (25/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier26: pipeline (26/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier27: pipeline (27/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier28: pipeline (28/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier29: pipeline (29/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier30: pipeline (30/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier31: pipeline (31/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier32: pipeline (32/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier33: pipeline (33/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier34: pipeline (34/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier35: pipeline (35/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier36: pipeline (36/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier37: pipeline (37/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier38: pipeline (38/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier39: pipeline (39/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier40: pipeline (40/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier41: pipeline (41/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier42: pipeline (42/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier43: pipeline (43/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier44: pipeline (44/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier45: pipeline (45/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier46: pipeline (46/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier47: pipeline (47/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier48: pipeline (48/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier49: pipeline (49/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier50: pipeline (50/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier51: pipeline (51/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier52: pipeline (52/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier53: pipeline (53/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier54: pipeline (54/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier55: pipeline (55/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier56: pipeline (56/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier57: pipeline (57/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier58: pipeline (58/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier59: pipeline (59/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier60: pipeline (60/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier61: pipeline (61/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier62: pipeline (62/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier63: pipeline (63/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier64: pipeline (64/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier65: pipeline (65/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier66: pipeline (66/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier67: pipeline (67/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier68: pipeline (68/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier69: pipeline (69/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier70: pipeline (70/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier71: pipeline (71/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier72: pipeline (72/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier73: pipeline (73/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier74: pipeline (74/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier75: pipeline (75/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier76: pipeline (76/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier77: pipeline (77/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier78: pipeline (78/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier79: pipeline (79/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier80: pipeline (80/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier81: pipeline (81/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier82: pipeline (82/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier83: pipeline (83/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier84: pipeline (84/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier85: pipeline (85/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier86: pipeline (86/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier87: pipeline (87/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier88: pipeline (88/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier89: pipeline (89/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier90: pipeline (90/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier91: pipeline (91/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier92: pipeline (92/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier93: pipeline (93/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier94: pipeline (94/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier95: pipeline (95/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier96: pipeline (96/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier97: pipeline (97/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier98: pipeline (98/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier99: pipeline (99/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier100: pipeline (100/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier101: pipeline (101/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier102: pipeline (102/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier103: pipeline (103/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier104: pipeline (104/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier105: pipeline (105/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier106: pipeline (106/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier107: pipeline (107/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier108: pipeline (108/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier109: pipeline (109/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier110: pipeline (110/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier111: pipeline (111/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier112: pipeline (112/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier113: pipeline (113/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier114: pipeline (114/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier115: pipeline (115/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier116: pipeline (116/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier117: pipeline (117/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier118: pipeline (118/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier119: pipeline (119/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier120: pipeline (120/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier121: pipeline (121/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier122: pipeline (122/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier123: pipeline (123/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier124: pipeline (124/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier125: pipeline (125/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier126: pipeline (126/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier127: pipeline (127/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier128: pipeline (128/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier129: pipeline (129/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier130: pipeline (130/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier131: pipeline (131/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier132: pipeline (132/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier133: pipeline (133/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier134: pipeline (134/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier135: pipeline (135/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier136: pipeline (136/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier137: pipeline (137/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier138: pipeline (138/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier139: pipeline (139/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier140: pipeline (140/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier141: pipeline (141/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier142: pipeline (142/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier143: pipeline (143/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier144: pipeline (144/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier145: pipeline (145/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier146: pipeline (146/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier147: pipeline (147/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier148: pipeline (148/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier149: pipeline (149/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier150: pipeline (150/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier151: pipeline (151/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier152: pipeline (152/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier153: pipeline (153/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier154: pipeline (154/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier155: pipeline (155/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier156: pipeline (156/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier157: pipeline (157/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier158: pipeline (158/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier159: pipeline (159/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier160: pipeline (160/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier161: pipeline (161/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier162: pipeline (162/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier163: pipeline (163/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier164: pipeline (164/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier165: pipeline (165/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier166: pipeline (166/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier167: pipeline (167/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier168: pipeline (168/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier169: pipeline (169/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier170: pipeline (170/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier171: pipeline (171/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier172: pipeline (172/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier173: pipeline (173/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier174: pipeline (174/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier175: pipeline (175/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier176: pipeline (176/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier177: pipeline (177/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier178: pipeline (178/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier179: pipeline (179/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier180: pipeline (180/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier181: pipeline (181/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier182: pipeline (182/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier183: pipeline (183/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier184: pipeline (184/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier185: pipeline (185/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier186: pipeline (186/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier187: pipeline (187/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier188: pipeline (188/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier189: pipeline (189/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier190: pipeline (190/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier191: pipeline (191/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier192: pipeline (192/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier193: pipeline (193/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier194: pipeline (194/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier195: pipeline (195/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier196: pipeline (196/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier197: pipeline (197/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier198: pipeline (198/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier199: pipeline (199/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier200: pipeline (200/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier201: pipeline (201/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier202: pipeline (202/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier203: pipeline (203/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier204: pipeline (204/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier205: pipeline (205/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier206: pipeline (206/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier207: pipeline (207/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier208: pipeline (208/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier209: pipeline (209/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier210: pipeline (210/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier211: pipeline (211/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier212: pipeline (212/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier213: pipeline (213/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier214: pipeline (214/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier215: pipeline (215/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier216: pipeline (216/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier217: pipeline (217/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier218: pipeline (218/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier219: pipeline (219/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier220: pipeline (220/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier221: pipeline (221/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier222: pipeline (222/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier223: pipeline (223/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier224: pipeline (224/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier225: pipeline (225/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier226: pipeline (226/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier227: pipeline (227/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier228: pipeline (228/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier229: pipeline (229/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier230: pipeline (230/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier231: pipeline (231/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier232: pipeline (232/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier233: pipeline (233/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier234: pipeline (234/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier235: pipeline (235/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier236: pipeline (236/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier237: pipeline (237/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier238: pipeline (238/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier239: pipeline (239/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier240: pipeline (240/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier241: pipeline (241/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier242: pipeline (242/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier243: pipeline (243/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier244: pipeline (244/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier245: pipeline (245/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier246: pipeline (246/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier247: pipeline (247/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier248: pipeline (248/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier249: pipeline (249/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier250: pipeline (250/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier251: pipeline (251/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier252: pipeline (252/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier253: pipeline (253/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier254: pipeline (254/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier255: pipeline (255/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier256: pipeline (256/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier257: pipeline (257/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier258: pipeline (258/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier259: pipeline (259/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier260: pipeline (260/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier261: pipeline (261/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier262: pipeline (262/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier263: pipeline (263/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier264: pipeline (264/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier265: pipeline (265/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier266: pipeline (266/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier267: pipeline (267/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier268: pipeline (268/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier269: pipeline (269/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier270: pipeline (270/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier271: pipeline (271/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier272: pipeline (272/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier273: pipeline (273/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier274: pipeline (274/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier275: pipeline (275/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier276: pipeline (276/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier277: pipeline (277/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier278: pipeline (278/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier279: pipeline (279/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier280: pipeline (280/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier281: pipeline (281/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier282: pipeline (282/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier283: pipeline (283/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier284: pipeline (284/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier285: pipeline (285/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier286: pipeline (286/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier287: pipeline (287/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier288: pipeline (288/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier289: pipeline (289/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier290: pipeline (290/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier291: pipeline (291/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier292: pipeline (292/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier293: pipeline (293/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier294: pipeline (294/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier295: pipeline (295/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier296: pipeline (296/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier297: pipeline (297/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier298: pipeline (298/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier299: pipeline (299/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier300: pipeline (300/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier301: pipeline (301/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier302: pipeline (302/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier303: pipeline (303/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier304: pipeline (304/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier305: pipeline (305/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier306: pipeline (306/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier307: pipeline (307/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier308: pipeline (308/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier309: pipeline (309/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier310: pipeline (310/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier311: pipeline (311/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier312: pipeline (312/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier313: pipeline (313/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier314: pipeline (314/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier315: pipeline (315/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier316: pipeline (316/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier317: pipeline (317/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier318: pipeline (318/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier319: pipeline (319/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier320: pipeline (320/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier321: pipeline (321/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier322: pipeline (322/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier323: pipeline (323/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier324: pipeline (324/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier325: pipeline (325/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier326: pipeline (326/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier327: pipeline (327/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier328: pipeline (328/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier329: pipeline (329/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier330: pipeline (330/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier331: pipeline (331/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier332: pipeline (332/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier333: pipeline (333/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier334: pipeline (334/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier335: pipeline (335/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier336: pipeline (336/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier337: pipeline (337/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier338: pipeline (338/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier339: pipeline (339/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier340: pipeline (340/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier341: pipeline (341/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier342: pipeline (342/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier343: pipeline (343/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier344: pipeline (344/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier345: pipeline (345/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier346: pipeline (346/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier347: pipeline (347/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier348: pipeline (348/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier349: pipeline (349/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier350: pipeline (350/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier351: pipeline (351/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier352: pipeline (352/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier353: pipeline (353/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier354: pipeline (354/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier355: pipeline (355/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier356: pipeline (356/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier357: pipeline (357/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier358: pipeline (358/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier359: pipeline (359/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier360: pipeline (360/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier361: pipeline (361/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier362: pipeline (362/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier363: pipeline (363/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier364: pipeline (364/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier365: pipeline (365/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier366: pipeline (366/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier367: pipeline (367/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier368: pipeline (368/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier369: pipeline (369/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier370: pipeline (370/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier371: pipeline (371/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier372: pipeline (372/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier373: pipeline (373/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier374: pipeline (374/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier375: pipeline (375/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier376: pipeline (376/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier377: pipeline (377/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier378: pipeline (378/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier379: pipeline (379/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier380: pipeline (380/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier381: pipeline (381/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier382: pipeline (382/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier383: pipeline (383/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier384: pipeline (384/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier385: pipeline (385/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier386: pipeline (386/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier387: pipeline (387/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier388: pipeline (388/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier389: pipeline (389/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier390: pipeline (390/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier391: pipeline (391/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier392: pipeline (392/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier393: pipeline (393/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier394: pipeline (394/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier395: pipeline (395/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier396: pipeline (396/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier397: pipeline (397/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier398: pipeline (398/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier399: pipeline (399/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier400: pipeline (400/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier401: pipeline (401/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier402: pipeline (402/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier403: pipeline (403/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier404: pipeline (404/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier405: pipeline (405/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier406: pipeline (406/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier407: pipeline (407/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier408: pipeline (408/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier409: pipeline (409/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier410: pipeline (410/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier411: pipeline (411/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier412: pipeline (412/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier413: pipeline (413/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier414: pipeline (414/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier415: pipeline (415/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier416: pipeline (416/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier417: pipeline (417/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier418: pipeline (418/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier419: pipeline (419/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier420: pipeline (420/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier421: pipeline (421/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier422: pipeline (422/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier423: pipeline (423/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier424: pipeline (424/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier425: pipeline (425/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier426: pipeline (426/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier427: pipeline (427/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier428: pipeline (428/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier429: pipeline (429/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier430: pipeline (430/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier431: pipeline (431/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier432: pipeline (432/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier433: pipeline (433/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier434: pipeline (434/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier435: pipeline (435/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier436: pipeline (436/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier437: pipeline (437/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier438: pipeline (438/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier439: pipeline (439/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier440: pipeline (440/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier441: pipeline (441/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier442: pipeline (442/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier443: pipeline (443/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier444: pipeline (444/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier445: pipeline (445/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier446: pipeline (446/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier447: pipeline (447/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier448: pipeline (448/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier449: pipeline (449/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier450: pipeline (450/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier451: pipeline (451/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier452: pipeline (452/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier453: pipeline (453/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier454: pipeline (454/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier455: pipeline (455/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier456: pipeline (456/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier457: pipeline (457/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier458: pipeline (458/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier459: pipeline (459/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier460: pipeline (460/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier461: pipeline (461/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier462: pipeline (462/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier463: pipeline (463/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier464: pipeline (464/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier465: pipeline (465/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier466: pipeline (466/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier467: pipeline (467/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier468: pipeline (468/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier469: pipeline (469/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier470: pipeline (470/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier471: pipeline (471/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier472: pipeline (472/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier473: pipeline (473/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier474: pipeline (474/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier475: pipeline (475/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier476: pipeline (476/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier477: pipeline (477/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier478: pipeline (478/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier479: pipeline (479/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier480: pipeline (480/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier481: pipeline (481/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier482: pipeline (482/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier483: pipeline (483/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier484: pipeline (484/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier485: pipeline (485/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier486: pipeline (486/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier487: pipeline (487/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier488: pipeline (488/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier489: pipeline (489/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier490: pipeline (490/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier491: pipeline (491/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier492: pipeline (492/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier493: pipeline (493/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier494: pipeline (494/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier495: pipeline (495/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier496: pipeline (496/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier497: pipeline (497/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier498: pipeline (498/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier499: pipeline (499/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier500: pipeline (500/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier501: pipeline (501/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier502: pipeline (502/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier503: pipeline (503/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier504: pipeline (504/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier505: pipeline (505/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier506: pipeline (506/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier507: pipeline (507/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier508: pipeline (508/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier509: pipeline (509/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier510: pipeline (510/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier511: pipeline (511/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier512: pipeline (512/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier513: pipeline (513/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier514: pipeline (514/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier515: pipeline (515/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier516: pipeline (516/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier517: pipeline (517/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier518: pipeline (518/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier519: pipeline (519/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier520: pipeline (520/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier521: pipeline (521/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier522: pipeline (522/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier523: pipeline (523/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier524: pipeline (524/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier525: pipeline (525/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 5, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier526: pipeline (526/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier527: pipeline (527/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier528: pipeline (528/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier529: pipeline (529/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier530: pipeline (530/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier531: pipeline (531/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier532: pipeline (532/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier533: pipeline (533/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier534: pipeline (534/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier535: pipeline (535/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier536: pipeline (536/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier537: pipeline (537/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier538: pipeline (538/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier539: pipeline (539/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier540: pipeline (540/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier541: pipeline (541/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier542: pipeline (542/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier543: pipeline (543/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier544: pipeline (544/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier545: pipeline (545/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier546: pipeline (546/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier547: pipeline (547/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier548: pipeline (548/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier549: pipeline (549/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier550: pipeline (550/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier551: pipeline (551/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier552: pipeline (552/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier553: pipeline (553/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier554: pipeline (554/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier555: pipeline (555/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier556: pipeline (556/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier557: pipeline (557/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier558: pipeline (558/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier559: pipeline (559/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier560: pipeline (560/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier561: pipeline (561/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier562: pipeline (562/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier563: pipeline (563/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier564: pipeline (564/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier565: pipeline (565/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier566: pipeline (566/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier567: pipeline (567/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier568: pipeline (568/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier569: pipeline (569/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier570: pipeline (570/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier571: pipeline (571/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier572: pipeline (572/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier573: pipeline (573/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier574: pipeline (574/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier575: pipeline (575/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier576: pipeline (576/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier577: pipeline (577/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier578: pipeline (578/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier579: pipeline (579/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier580: pipeline (580/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier581: pipeline (581/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier582: pipeline (582/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier583: pipeline (583/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier584: pipeline (584/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier585: pipeline (585/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier586: pipeline (586/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier587: pipeline (587/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier588: pipeline (588/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier589: pipeline (589/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier590: pipeline (590/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier591: pipeline (591/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier592: pipeline (592/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier593: pipeline (593/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier594: pipeline (594/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier595: pipeline (595/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier596: pipeline (596/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 3, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier597: pipeline (597/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier598: pipeline (598/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier599: pipeline (599/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier600: pipeline (600/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier601: pipeline (601/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier602: pipeline (602/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier603: pipeline (603/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier604: pipeline (604/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier605: pipeline (605/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier606: pipeline (606/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier607: pipeline (607/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier608: pipeline (608/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier609: pipeline (609/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier610: pipeline (610/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier611: pipeline (611/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier612: pipeline (612/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier613: pipeline (613/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier614: pipeline (614/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier615: pipeline (615/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier616: pipeline (616/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier617: pipeline (617/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier618: pipeline (618/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier619: pipeline (619/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier620: pipeline (620/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier621: pipeline (621/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier622: pipeline (622/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier623: pipeline (623/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier624: pipeline (624/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier625: pipeline (625/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier626: pipeline (626/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier627: pipeline (627/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier628: pipeline (628/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier629: pipeline (629/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier630: pipeline (630/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier631: pipeline (631/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 4, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier632: pipeline (632/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier633: pipeline (633/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier634: pipeline (634/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier635: pipeline (635/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier636: pipeline (636/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier637: pipeline (637/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier638: pipeline (638/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier639: pipeline (639/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier640: pipeline (640/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier641: pipeline (641/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier642: pipeline (642/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier643: pipeline (643/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier644: pipeline (644/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier645: pipeline (645/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier646: pipeline (646/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier647: pipeline (647/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier648: pipeline (648/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier649: pipeline (649/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier650: pipeline (650/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier651: pipeline (651/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 5, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier652: pipeline (652/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier653: pipeline (653/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier654: pipeline (654/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier655: pipeline (655/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier656: pipeline (656/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier657: pipeline (657/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier658: pipeline (658/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier659: pipeline (659/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier660: pipeline (660/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier661: pipeline (661/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier662: pipeline (662/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier663: pipeline (663/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier664: pipeline (664/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier665: pipeline (665/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier666: pipeline (666/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(2, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier667: pipeline (667/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier668: pipeline (668/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier669: pipeline (669/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier670: pipeline (670/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier671: pipeline (671/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier672: pipeline (672/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier673: pipeline (673/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier674: pipeline (674/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier675: pipeline (675/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier676: pipeline (676/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier677: pipeline (677/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier678: pipeline (678/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier679: pipeline (679/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier680: pipeline (680/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier681: pipeline (681/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier682: pipeline (682/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier683: pipeline (683/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier684: pipeline (684/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier685: pipeline (685/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier686: pipeline (686/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier687: pipeline (687/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier688: pipeline (688/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier689: pipeline (689/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier690: pipeline (690/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier691: pipeline (691/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier692: pipeline (692/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier693: pipeline (693/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier694: pipeline (694/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier695: pipeline (695/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier696: pipeline (696/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier697: pipeline (697/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier698: pipeline (698/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier699: pipeline (699/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier700: pipeline (700/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier701: pipeline (701/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 4, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier702: pipeline (702/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier703: pipeline (703/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier704: pipeline (704/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier705: pipeline (705/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier706: pipeline (706/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier707: pipeline (707/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier708: pipeline (708/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier709: pipeline (709/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier710: pipeline (710/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier711: pipeline (711/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier712: pipeline (712/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier713: pipeline (713/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier714: pipeline (714/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier715: pipeline (715/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier716: pipeline (716/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier717: pipeline (717/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier718: pipeline (718/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier719: pipeline (719/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier720: pipeline (720/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier721: pipeline (721/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 5, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier722: pipeline (722/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier723: pipeline (723/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier724: pipeline (724/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier725: pipeline (725/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier726: pipeline (726/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier727: pipeline (727/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier728: pipeline (728/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier729: pipeline (729/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier730: pipeline (730/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier731: pipeline (731/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier732: pipeline (732/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier733: pipeline (733/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier734: pipeline (734/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier735: pipeline (735/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier736: pipeline (736/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(3, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier737: pipeline (737/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier738: pipeline (738/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier739: pipeline (739/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier740: pipeline (740/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier741: pipeline (741/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier742: pipeline (742/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier743: pipeline (743/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier744: pipeline (744/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier745: pipeline (745/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier746: pipeline (746/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier747: pipeline (747/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier748: pipeline (748/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier749: pipeline (749/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier750: pipeline (750/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier751: pipeline (751/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier752: pipeline (752/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier753: pipeline (753/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier754: pipeline (754/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier755: pipeline (755/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier756: pipeline (756/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 5, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier757: pipeline (757/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier758: pipeline (758/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier759: pipeline (759/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier760: pipeline (760/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier761: pipeline (761/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier762: pipeline (762/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier763: pipeline (763/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier764: pipeline (764/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier765: pipeline (765/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier766: pipeline (766/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier767: pipeline (767/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier768: pipeline (768/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier769: pipeline (769/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier770: pipeline (770/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier771: pipeline (771/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(4, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier772: pipeline (772/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier773: pipeline (773/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier774: pipeline (774/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier775: pipeline (775/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier776: pipeline (776/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier777: pipeline (777/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier778: pipeline (778/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier779: pipeline (779/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier780: pipeline (780/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier781: pipeline (781/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier782: pipeline (782/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier783: pipeline (783/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier784: pipeline (784/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier785: pipeline (785/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier786: pipeline (786/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(5, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier787: pipeline (787/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(6, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier788: pipeline (788/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(6, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier789: pipeline (789/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(6, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier790: pipeline (790/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(6, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier791: pipeline (791/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(6, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier792: pipeline (792/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(7, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingCVClassifier(classifiers=[Pipeline(memory=None,\n",
       "                                           steps=[('columnselector',\n",
       "                                                   ColumnSelector(cols=(0, 1, 2,\n",
       "                                                                        3, 4),\n",
       "                                                                  drop_axis=False)),\n",
       "                                                  ('xgbclassifier',\n",
       "                                                   XGBClassifier(base_score=0.5,\n",
       "                                                                 booster='gbtree',\n",
       "                                                                 colsample_bylevel=1,\n",
       "                                                                 colsample_bynode=1,\n",
       "                                                                 colsample_bytree=1,\n",
       "                                                                 gamma=0,\n",
       "                                                                 learning_rate=0.1,\n",
       "                                                                 max_delta_step=0,\n",
       "                                                                 max_depth=3,\n",
       "                                                                 min_child_weight=1,\n",
       "                                                                 missing=None,\n",
       "                                                                 n_estimators...\n",
       "                                                        fit_intercept=True,\n",
       "                                                        intercept_scaling=1,\n",
       "                                                        l1_ratio=None,\n",
       "                                                        max_iter=100,\n",
       "                                                        multi_class='warn',\n",
       "                                                        n_jobs=None,\n",
       "                                                        penalty='l2',\n",
       "                                                        random_state=None,\n",
       "                                                        solver='warn',\n",
       "                                                        tol=0.0001, verbose=0,\n",
       "                                                        warm_start=False),\n",
       "                     n_jobs=None, pre_dispatch='2*n_jobs', random_state=42,\n",
       "                     shuffle=True, store_train_meta_features=False,\n",
       "                     stratify=True, use_clones=True,\n",
       "                     use_features_in_secondary=False, use_probas=False,\n",
       "                     verbose=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7016666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1    2\n",
       "0  158  38    4\n",
       "1   74  95   31\n",
       "2    5  27  168"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sclf1.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(sclf,\n",
    "                         xtrain,ytrain,\n",
    "                         cv=5,\n",
    "                         scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sclf1.clfs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "for i in range(len(sclf1.clfs_)):\n",
    "    model=sclf1.clfs_[i]\n",
    "    y_pred = model.predict((xtest))\n",
    "    accuracy.append(m.accuracy_score(ytest, y_pred))\n",
    "#     print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>index</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731667</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 1, 2, 3, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.726667</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 1, 2, 3, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.726667</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1, 2, 3, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721667</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 2, 3, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728333</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 1, 2, 3, 8)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  index             cols\n",
       "0  0.731667      0  (0, 1, 2, 3, 4)\n",
       "1  0.726667      1  (0, 1, 2, 3, 5)\n",
       "2  0.726667      2  (0, 1, 2, 3, 6)\n",
       "3  0.721667      3  (0, 1, 2, 3, 7)\n",
       "4  0.728333      4  (0, 1, 2, 3, 8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracypd= pd.DataFrame()\n",
    "accuracypd['accuracy']=accuracy\n",
    "accuracypd['index']=np.arange(0,len(accuracy),1)\n",
    "accuracypd['cols']=combcols\n",
    "accuracypd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>index</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>116</td>\n",
       "      <td>(0, 1, 8, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>105</td>\n",
       "      <td>(0, 1, 6, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>113</td>\n",
       "      <td>(0, 1, 7, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>31</td>\n",
       "      <td>(0, 1, 2, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>95</td>\n",
       "      <td>(0, 1, 5, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>89</td>\n",
       "      <td>(0, 1, 5, 6, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>111</td>\n",
       "      <td>(0, 1, 7, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>119</td>\n",
       "      <td>(0, 1, 9, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>99</td>\n",
       "      <td>(0, 1, 5, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>20</td>\n",
       "      <td>(0, 1, 2, 5, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>92</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>92</td>\n",
       "      <td>(0, 1, 5, 7, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>88</td>\n",
       "      <td>(0, 1, 5, 6, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>47</td>\n",
       "      <td>(0, 1, 3, 5, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>118</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>118</td>\n",
       "      <td>(0, 1, 8, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>75</td>\n",
       "      <td>(0, 1, 4, 7, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>107</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>107</td>\n",
       "      <td>(0, 1, 6, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>97</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>97</td>\n",
       "      <td>(0, 1, 5, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>100</td>\n",
       "      <td>(0, 1, 6, 7, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>52</td>\n",
       "      <td>(0, 1, 3, 6, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>104</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>104</td>\n",
       "      <td>(0, 1, 6, 8, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>85</td>\n",
       "      <td>(0, 1, 5, 6, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>59</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>59</td>\n",
       "      <td>(0, 1, 3, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>63</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>63</td>\n",
       "      <td>(0, 1, 3, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>19</td>\n",
       "      <td>(0, 1, 2, 5, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>90</td>\n",
       "      <td>(0, 1, 5, 7, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>24</td>\n",
       "      <td>(0, 1, 2, 6, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>33</td>\n",
       "      <td>(0, 1, 2, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>102</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>102</td>\n",
       "      <td>(0, 1, 6, 7, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>11</td>\n",
       "      <td>(0, 1, 2, 4, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>255</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>255</td>\n",
       "      <td>(0, 3, 7, 10, 11)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0  accuracy  index               cols\n",
       "0       116  0.753333    116   (0, 1, 8, 9, 10)\n",
       "1       105  0.746667    105   (0, 1, 6, 8, 10)\n",
       "2       113  0.746667    113   (0, 1, 7, 9, 10)\n",
       "3        31  0.745000     31   (0, 1, 2, 8, 10)\n",
       "4        95  0.745000     95   (0, 1, 5, 8, 10)\n",
       "5        89  0.745000     89   (0, 1, 5, 6, 11)\n",
       "6       111  0.743333    111   (0, 1, 7, 8, 10)\n",
       "7       119  0.743333    119  (0, 1, 9, 10, 11)\n",
       "8        99  0.743333     99  (0, 1, 5, 10, 11)\n",
       "9        20  0.741667     20   (0, 1, 2, 5, 11)\n",
       "10       92  0.741667     92   (0, 1, 5, 7, 10)\n",
       "11       88  0.741667     88   (0, 1, 5, 6, 10)\n",
       "12       47  0.740000     47   (0, 1, 3, 5, 10)\n",
       "13      118  0.740000    118  (0, 1, 8, 10, 11)\n",
       "14       75  0.740000     75    (0, 1, 4, 7, 8)\n",
       "15      107  0.740000    107   (0, 1, 6, 9, 10)\n",
       "16       97  0.740000     97   (0, 1, 5, 9, 10)\n",
       "17      100  0.740000    100    (0, 1, 6, 7, 8)\n",
       "18       52  0.740000     52   (0, 1, 3, 6, 10)\n",
       "19      104  0.738333    104    (0, 1, 6, 8, 9)\n",
       "20       85  0.738333     85    (0, 1, 5, 6, 7)\n",
       "21       59  0.738333     59   (0, 1, 3, 8, 10)\n",
       "22       63  0.738333     63  (0, 1, 3, 10, 11)\n",
       "23       19  0.738333     19   (0, 1, 2, 5, 10)\n",
       "24       90  0.738333     90    (0, 1, 5, 7, 8)\n",
       "25       24  0.738333     24   (0, 1, 2, 6, 10)\n",
       "26       33  0.738333     33   (0, 1, 2, 9, 10)\n",
       "27      102  0.738333    102   (0, 1, 6, 7, 10)\n",
       "28       11  0.738333     11    (0, 1, 2, 4, 8)\n",
       "29      255  0.738333    255  (0, 3, 7, 10, 11)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedclassifiers_info=accuracypd[accuracypd.accuracy>0.73].sort_values(by='accuracy',ascending=False).reset_index()\n",
    "selectedclassifiers_info.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([116, 105, 113,  31,  95,  89, 111, 119,  99,  20,  92,  88,  47,\n",
       "            118,  75, 107,  97, 100,  52, 104,  85,  59,  63,  19,  90,  24,\n",
       "             33, 102,  11, 255,  60, 132, 109, 115, 233, 106,  78,  61, 103,\n",
       "            101,  84,  80, 249,  77,  76,  73, 108, 110,  13, 252, 146, 223,\n",
       "             36,  35,  28, 236, 147, 259,  82, 285,  96,  62,  10,  22,  38,\n",
       "             41,  45,  53,  40,  68,  69,  70,  71,   6,  25,   7, 258,  86,\n",
       "             17, 248, 238,  23, 218,  37,  56, 199,  79,  39, 141,  93,  43,\n",
       "             50,   0],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedclassifiers_index=selectedclassifiers_info.index\n",
    "selectedclassifiers_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1, 8, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1, 6, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 1, 7, 9, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1, 2, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1, 5, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 1, 5, 6, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 1, 7, 8, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0, 1, 9, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0, 1, 5, 10, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0, 1, 2, 5, 11)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cols\n",
       "0   (0, 1, 8, 9, 10)\n",
       "1   (0, 1, 6, 8, 10)\n",
       "2   (0, 1, 7, 9, 10)\n",
       "3   (0, 1, 2, 8, 10)\n",
       "4   (0, 1, 5, 8, 10)\n",
       "5   (0, 1, 5, 6, 11)\n",
       "6   (0, 1, 7, 8, 10)\n",
       "7  (0, 1, 9, 10, 11)\n",
       "8  (0, 1, 5, 10, 11)\n",
       "9   (0, 1, 2, 5, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp= pd.DataFrame() \n",
    "temp['cols']=[\n",
    "    (0, 1, 8, 9, 10),(0, 1, 6, 8, 10),(0, 1, 7, 9, 10),(0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),(0, 1, 5, 6, 11),(0, 1, 7, 8, 10),(0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),(0, 1, 2, 5, 11)\n",
    "]\n",
    "\n",
    "selectedclassifiers_info=temp\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Use only selected classifier from the previous model which have >73% accuracy\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakmodles2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(selectedclassifiers_index)):\n",
    "for i in range(10):\n",
    "#     print(combcols[i])\n",
    "    weakmodles2.append(make_pipeline(ColumnSelector(cols=selectedclassifiers_info.cols[i]), \n",
    "                                     xgb_model_5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf2 = StackingCVClassifier(classifiers=weakmodles2,verbose=2,\n",
    "                           meta_classifier=xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed),\n",
    "#                              LogisticRegression(),\n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 classifiers...\n",
      "Fitting classifier1: pipeline (1/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: pipeline (2/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: pipeline (3/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier4: pipeline (4/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier5: pipeline (5/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier6: pipeline (6/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier7: pipeline (7/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier8: pipeline (8/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier9: pipeline (9/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier10: pipeline (10/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingCVClassifier(classifiers=[Pipeline(memory=None,\n",
       "                                           steps=[('columnselector',\n",
       "                                                   ColumnSelector(cols=(0, 1, 8,\n",
       "                                                                        9, 10),\n",
       "                                                                  drop_axis=False)),\n",
       "                                                  ('xgbclassifier',\n",
       "                                                   XGBClassifier(base_score=0.5,\n",
       "                                                                 booster='gbtree',\n",
       "                                                                 colsample_bylevel=1,\n",
       "                                                                 colsample_bynode=1,\n",
       "                                                                 colsample_bytree=1,\n",
       "                                                                 gamma=0,\n",
       "                                                                 learning_rate=0.1,\n",
       "                                                                 max_delta_step=0,\n",
       "                                                                 max_depth=3,\n",
       "                                                                 min_child_weight=1,\n",
       "                                                                 missing=None,\n",
       "                                                                 n_estimator...\n",
       "                                                   n_estimators=100, n_jobs=1,\n",
       "                                                   nthread=None,\n",
       "                                                   objective='multi:softmax',\n",
       "                                                   random_state=42, reg_alpha=0,\n",
       "                                                   reg_lambda=1,\n",
       "                                                   scale_pos_weight=1,\n",
       "                                                   seed=None, silent=None,\n",
       "                                                   subsample=1, verbosity=1),\n",
       "                     n_jobs=None, pre_dispatch='2*n_jobs', random_state=42,\n",
       "                     shuffle=True, store_train_meta_features=False,\n",
       "                     stratify=True, use_clones=True,\n",
       "                     use_features_in_secondary=False, use_probas=False,\n",
       "                     verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf2.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.745\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>123</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  152   48    0\n",
       "1   55  123   22\n",
       "2    3   25  172"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sclf2.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter max_depth for estimator StackingCVClassifier(classifiers=[Pipeline(memory=None,\n                                           steps=[('columnselector',\n                                                   ColumnSelector(cols=(0, 1, 8,\n                                                                        9, 10),\n                                                                  drop_axis=False)),\n                                                  ('xgbclassifier',\n                                                   XGBClassifier(base_score=0.5,\n                                                                 booster='gbtree',\n                                                                 colsample_bylevel=1,\n                                                                 colsample_bynode=1,\n                                                                 colsample_bytree=1,\n                                                                 gamma=0,\n                                                                 learning_rate=0.1,\n                                                                 max_delta_step=0,\n                                                                 max_depth=3,\n                                                                 min_child_weight=1,\n                                                                 missing=None,\n                                                                 n_estimator...\n                                                   n_estimators=100, n_jobs=1,\n                                                   nthread=None,\n                                                   objective='multi:softmax',\n                                                   random_state=42, reg_alpha=0,\n                                                   reg_lambda=1,\n                                                   scale_pos_weight=1,\n                                                   seed=None, silent=None,\n                                                   subsample=1, verbosity=1),\n                     n_jobs=None, pre_dispatch='2*n_jobs', random_state=42,\n                     shuffle=True, store_train_meta_features=False,\n                     stratify=True, use_clones=True,\n                     use_features_in_secondary=False, use_probas=False,\n                     verbose=2). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1cfd3077e62c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mxgb_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxgb_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msclf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlxtend\\classifier\\stacking_cv_classification.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifiers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'named_classifiers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlxtend\\utils\\base_compostion.py\u001b[0m in \u001b[0;36m_set_params\u001b[1;34m(self, attr, named_attr, **params)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# 3. estimator parameters and other initialisation arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseXComposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    222\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                                  (key, self))\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter max_depth for estimator StackingCVClassifier(classifiers=[Pipeline(memory=None,\n                                           steps=[('columnselector',\n                                                   ColumnSelector(cols=(0, 1, 8,\n                                                                        9, 10),\n                                                                  drop_axis=False)),\n                                                  ('xgbclassifier',\n                                                   XGBClassifier(base_score=0.5,\n                                                                 booster='gbtree',\n                                                                 colsample_bylevel=1,\n                                                                 colsample_bynode=1,\n                                                                 colsample_bytree=1,\n                                                                 gamma=0,\n                                                                 learning_rate=0.1,\n                                                                 max_delta_step=0,\n                                                                 max_depth=3,\n                                                                 min_child_weight=1,\n                                                                 missing=None,\n                                                                 n_estimator...\n                                                   n_estimators=100, n_jobs=1,\n                                                   nthread=None,\n                                                   objective='multi:softmax',\n                                                   random_state=42, reg_alpha=0,\n                                                   reg_lambda=1,\n                                                   scale_pos_weight=1,\n                                                   seed=None, silent=None,\n                                                   subsample=1, verbosity=1),\n                     n_jobs=None, pre_dispatch='2*n_jobs', random_state=42,\n                     shuffle=True, store_train_meta_features=False,\n                     stratify=True, use_clones=True,\n                     use_features_in_secondary=False, use_probas=False,\n                     verbose=2). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# Define parameter grid \n",
    "params = {\"meta_classifier__max_depth\":[3,5,7,9],\n",
    "          \"meta_classifier__n_estimators\":[10,50,100,200,700]}\n",
    "\n",
    "# parameters = {'max_depth':[3,5,7,9],\n",
    "#               'n_estimators':[10,50,100,200,700]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid = GridSearchCV(estimator = sclf2, \n",
    "                    param_grid = params, \n",
    "                    cv = 5,\n",
    "                    scoring = \"roc_auc\",\n",
    "                    verbose = 10,\n",
    "                    n_jobs = -1)\n",
    "\n",
    "# Fit GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Combine the 3 stacking classifiers\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_3 = LogisticRegression()\n",
    "temprf_3=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2_3=RandomForestClassifier()\n",
    "tempsvC_3= SVC()\n",
    "\n",
    "estimators_3 = [\n",
    "    sclf2,  stackingc_5,stackingc_12    \n",
    "\n",
    "]\n",
    "stackingc_3 = StackingClassifier(\n",
    "    classifiers=estimators_3, \n",
    "    meta_classifier=xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed),\n",
    "#     meta_classifier=temprf2_3,\n",
    "    verbose=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: stackingcvclassifier (1/3)\n",
      "StackingCVClassifier(classifiers=[Pipeline(memory=None,\n",
      "                                           steps=[('columnselector',\n",
      "                                                   ColumnSelector(cols=(0, 1, 8,\n",
      "                                                                        9, 10),\n",
      "                                                                  drop_axis=False)),\n",
      "                                                  ('xgbclassifier',\n",
      "                                                   XGBClassifier(base_score=0.5,\n",
      "                                                                 booster='gbtree',\n",
      "                                                                 colsample_bylevel=1,\n",
      "                                                                 colsample_bynode=1,\n",
      "                                                                 colsample_bytree=1,\n",
      "                                                                 gamma=0,\n",
      "                                                                 learning_rate=0.1,\n",
      "                                                                 max_delta_step=0,\n",
      "                                                                 max_depth=3,\n",
      "                                                                 min_child_weight=1,\n",
      "                                                                 missing=None,\n",
      "                                                                 n_estimator...\n",
      "                                                   n_estimators=100, n_jobs=1,\n",
      "                                                   nthread=None,\n",
      "                                                   objective='multi:softmax',\n",
      "                                                   random_state=7, reg_alpha=0,\n",
      "                                                   reg_lambda=1,\n",
      "                                                   scale_pos_weight=1,\n",
      "                                                   seed=None, silent=None,\n",
      "                                                   subsample=1, verbosity=1),\n",
      "                     n_jobs=None, pre_dispatch='2*n_jobs', random_state=42,\n",
      "                     shuffle=True, store_train_meta_features=False,\n",
      "                     stratify=True, use_clones=True,\n",
      "                     use_features_in_secondary=False, use_probas=False,\n",
      "                     verbose=2)\n",
      "Fitting 30 classifiers...\n",
      "Fitting classifier1: pipeline (1/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: pipeline (2/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: pipeline (3/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier4: pipeline (4/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier5: pipeline (5/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier6: pipeline (6/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier7: pipeline (7/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier8: pipeline (8/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier9: pipeline (9/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier10: pipeline (10/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier11: pipeline (11/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier12: pipeline (12/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier13: pipeline (13/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier14: pipeline (14/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier15: pipeline (15/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier16: pipeline (16/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier17: pipeline (17/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier18: pipeline (18/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier19: pipeline (19/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier20: pipeline (20/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier21: pipeline (21/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier22: pipeline (22/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier23: pipeline (23/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier24: pipeline (24/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier25: pipeline (25/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier26: pipeline (26/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier27: pipeline (27/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier28: pipeline (28/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier29: pipeline (29/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier30: pipeline (30/30)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: stackingclassifier (2/3)\n",
      "StackingClassifier(average_probas=False,\n",
      "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
      "                                                       class_weight=None,\n",
      "                                                       criterion='gini',\n",
      "                                                       max_depth=12,\n",
      "                                                       max_features='auto',\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=10,\n",
      "                                                       min_samples_split=3,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       n_estimators=100,\n",
      "                                                       n_jobs=None,\n",
      "                                                       oob_score=False,\n",
      "                                                       random_...\n",
      "                   drop_last_proba=False,\n",
      "                   meta_classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
      "                                       coef0=0.0, decision_function_shape='ovr',\n",
      "                                       degree=3, gamma='auto_deprecated',\n",
      "                                       kernel='rbf', max_iter=-1,\n",
      "                                       probability=False, random_state=None,\n",
      "                                       shrinking=True, tol=0.001,\n",
      "                                       verbose=False),\n",
      "                   store_train_meta_features=False, use_clones=True,\n",
      "                   use_features_in_secondary=False, use_probas=False,\n",
      "                   verbose=2)\n",
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softmax', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n",
      "Fitting classifier3: stackingclassifier (3/3)\n",
      "StackingClassifier(average_probas=False,\n",
      "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
      "                                                       class_weight=None,\n",
      "                                                       criterion='gini',\n",
      "                                                       max_depth=12,\n",
      "                                                       max_features='auto',\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=10,\n",
      "                                                       min_samples_split=3,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       n_estimators=100,\n",
      "                                                       n_jobs=None,\n",
      "                                                       oob_score=False,\n",
      "                                                       random_...\n",
      "                   drop_last_proba=False,\n",
      "                   meta_classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
      "                                       coef0=0.0, decision_function_shape='ovr',\n",
      "                                       degree=3, gamma='auto_deprecated',\n",
      "                                       kernel='rbf', max_iter=-1,\n",
      "                                       probability=False, random_state=None,\n",
      "                                       shrinking=True, tol=0.001,\n",
      "                                       verbose=False),\n",
      "                   store_train_meta_features=False, use_clones=True,\n",
      "                   use_features_in_secondary=False, use_probas=False,\n",
      "                   verbose=2)\n",
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[StackingCVClassifier(classifiers=[Pipeline(memory=None,\n",
       "                                                                           steps=[('columnselector',\n",
       "                                                                                   ColumnSelector(cols=(0,\n",
       "                                                                                                        1,\n",
       "                                                                                                        8,\n",
       "                                                                                                        9,\n",
       "                                                                                                        10),\n",
       "                                                                                                  drop_axis=False)),\n",
       "                                                                                  ('xgbclassifier',\n",
       "                                                                                   XGBClassifier(base_score=0.5,\n",
       "                                                                                                 booster='gbtree',\n",
       "                                                                                                 colsample_bylevel=1,\n",
       "                                                                                                 colsample_bynode=1,\n",
       "                                                                                                 colsample_bytree=1,\n",
       "                                                                                                 gamma=0,\n",
       "                                                                                                 learning_rate=0.1,\n",
       "                                                                                                 max_delta_step=0,\n",
       "                                                                                                 ma...\n",
       "                                                 learning_rate=0.1,\n",
       "                                                 max_delta_step=0, max_depth=3,\n",
       "                                                 min_child_weight=1,\n",
       "                                                 missing=None, n_estimators=100,\n",
       "                                                 n_jobs=1, nthread=None,\n",
       "                                                 objective='multi:softmax',\n",
       "                                                 random_state=7, reg_alpha=0,\n",
       "                                                 reg_lambda=1,\n",
       "                                                 scale_pos_weight=1, seed=None,\n",
       "                                                 silent=None, subsample=1,\n",
       "                                                 verbosity=1),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackingc_3.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   51    1\n",
       "1   54  128   18\n",
       "2    4   30  166"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackingc_3.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from mlxtend.feature_selection import ColumnSelector\n",
    "# from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "# pipe1 = make_pipeline(rf)\n",
    "# pipe11 = make_pipeline( xgb_model)\n",
    "# pipe12 = make_pipeline( SVC_clf)\n",
    "# pipe13 = make_pipeline( LogisticRegression())\n",
    "\n",
    "# pipe2 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), rf )\n",
    "# pipe21 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), xgb_model )\n",
    "# pipe22 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), SVC_clf )\n",
    "# pipe22 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), LogisticRegression() )\n",
    "\n",
    "\n",
    "\n",
    "# sclf1 = StackingCVClassifier(classifiers=[    pipe1,    pipe11,    pipe12 ],\n",
    "#                            meta_classifier=LogisticRegression(),random_state=42)\n",
    "\n",
    "# sclf2 = StackingCVClassifier(classifiers=[    pipe2,    pipe21,    pipe22],\n",
    "#                            meta_classifier=LogisticRegression(),random_state=42)\n",
    "\n",
    "# sclf = StackingCVClassifier(classifiers=[\n",
    "#    sclf1,sclf2\n",
    "# ], \n",
    "#                             meta_classifier=LogisticRegression(),\n",
    "#                             random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
