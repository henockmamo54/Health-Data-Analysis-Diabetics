{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Read the dataset and preprocess\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','S000300','AGE','SEX',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 13)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60141, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>S000300</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>20.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>25.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>21.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>24.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  S000300   AGE  SEX  CLASS\n",
       "2      78.0     5.28     20.2  46.0  1.0      0\n",
       "5      90.0     5.74     25.5  52.0  1.0      0\n",
       "10     86.0     5.83     21.2  37.0  1.0      0\n",
       "11     86.0     4.73     22.0  39.0  1.0      0\n",
       "20     87.0     5.60     24.6  59.0  1.0      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=data[['L100800','L104600','S000300','AGE','SEX','CLASS']]\n",
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    40247\n",
       "1    18735\n",
       "2     1159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='CLASS').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159 18735 40247\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0]\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 18535, 1: 18535, 0: 18535})\n",
      "18535 18535 18535\n",
      "(55605, 5) (55605,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[4],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Generate the classifier models based on the selected 12 features\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamter serach using grid search\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)\n",
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     random_state=randomseed,\n",
    "#     n_estimators=100, \n",
    "#     max_depth=12,\n",
    "#     min_samples_split=3,\n",
    "#     min_samples_leaf=10,\n",
    "#     max_features=\"auto\",\n",
    "# )\n",
    "\n",
    "# rf=rf_clf.best_estimator_\n",
    "rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation test for the model\n",
    "\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain,cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'S000300', 'AGE', 'SEX'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of the model using the test data\n",
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.795\n",
      "Accuracy on test set: 0.722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  138   60    2\n",
       "1   54  134   12\n",
       "2    3   36  161"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       200\n",
      "           1       0.58      0.67      0.62       200\n",
      "           2       0.92      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.74      0.72      0.73       600\n",
      "weighted avg       0.74      0.72      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[3,5,7,9],\n",
    "              'n_estimators':[10,50,100,200,700]}\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = GridSearchCV(xgb_clf, parameters)\n",
    "xgb_clf.fit(xtrain, ytrain)\n",
    "xgb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed)\n",
    "# objective=\"multi:softmax\"\n",
    "# objective=\"binary:logistic\"\n",
    "# objective='multi:softprob'\n",
    "\n",
    "\n",
    "# xgb_model=xgb_clf.best_estimator_\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC_clf = SVC_clf2.best_estimator_\n",
    "SVC_clf=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>131</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  136   60    4\n",
       "1   51  131   18\n",
       "2    3   29  168"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       200\n",
      "           1       0.60      0.66      0.62       200\n",
      "           2       0.88      0.84      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.72      0.73       600\n",
      "weighted avg       0.73      0.72      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=0)\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=150)\n",
    "neigh.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression()\n",
    "temprf=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2=RandomForestClassifier()\n",
    "tempsvC= SVC()\n",
    "\n",
    "estimators = [\n",
    "    rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,\n",
    "    lr,\n",
    "    neigh\n",
    "]\n",
    "stackingc = StackingClassifier(\n",
    "    classifiers=estimators, \n",
    "    meta_classifier=lr2,\n",
    "    verbose=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stackingc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stackingc.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=stackingc.clfs_[2].predict((xtest))\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('10-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,\n",
    "    lr,\n",
    "    neigh,\n",
    "    stackingc], \n",
    "                      ['rf',\n",
    "    'xgb_model',\n",
    "    'SVC_clf','lr','neigh','StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy: 0.74 (+/- 0.04) [rf]\n",
    "Accuracy: 0.70 (+/- 0.04) [xgb_model]\n",
    "Accuracy: 0.72 (+/- 0.03) [SVC_clf]\n",
    "Accuracy: 0.70 (+/- 0.04) [lr]\n",
    "Accuracy: 0.68 (+/- 0.04) [neigh]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
