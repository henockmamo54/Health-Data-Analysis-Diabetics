{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import itertools\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Read the dataset and preprocess\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','L103000','S000300','L101700','L100700','FIELD_33',\n",
    "                       'FIELD_38','FIELD_40','FIELD_31','SEX','AGE',#'CLASS',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56542, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[['L100800','L104600', 'L103000', 'S000300', 'L101700', 'L100700',\n",
    "       'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_31', 'SEX', 'AGE','CLASS']]\n",
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 17331 38166\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0]\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17131, 1: 17131, 0: 17131})\n",
      "17131 17131 17131\n",
      "(51393, 12) (51393,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[6,7,8,9,10],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Generate the classifier models based on the selected 12 features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "rf_12 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100, \n",
    "    max_depth=12,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "xgb_model_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "SVC_clf_12=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr\n",
    "lr_12=LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "kneigh_12 = KNeighborsClassifier(n_neighbors=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking classfier\n",
    "\n",
    "lr2_12 = LogisticRegression()\n",
    "temprf_12=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2_12=RandomForestClassifier()\n",
    "tempsvC_12= SVC()\n",
    "\n",
    "estimators_12 = [\n",
    "    rf_12,\n",
    "    xgb_model_12,\n",
    "    SVC_clf_12,\n",
    "    lr_12,\n",
    "    kneigh_12\n",
    "]\n",
    "stackingc_12 = StackingClassifier(\n",
    "    classifiers=estimators_12,\n",
    "    meta_classifier=tempsvC_12,\n",
    "    verbose=2 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=12,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=10,\n",
       "                                                       min_samples_split=3,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_...\n",
       "                   drop_last_proba=False,\n",
       "                   meta_classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                       coef0=0.0, decision_function_shape='ovr',\n",
       "                                       degree=3, gamma='auto_deprecated',\n",
       "                                       kernel='rbf', max_iter=-1,\n",
       "                                       probability=False, random_state=None,\n",
       "                                       shrinking=True, tol=0.001,\n",
       "                                       verbose=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackingc_12.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   51    1\n",
       "1   54  128   18\n",
       "2    4   30  166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackingc_12.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Generate the classifier models based on the selected 5 features\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100, \n",
    "    max_depth=12,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_5 = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf_5=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_5=LogisticRegression(random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneigh_5 = KNeighborsClassifier(n_neighbors=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_5 = LogisticRegression()\n",
    "temprf_5=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2_5=RandomForestClassifier()\n",
    "tempsvC_5= SVC()\n",
    "\n",
    "estimators_5 = [\n",
    "    rf_5,\n",
    "    xgb_model_5,\n",
    "    SVC_clf_5,\n",
    "    lr_5,\n",
    "    kneigh_5\n",
    "]\n",
    "stackingc_5 = StackingClassifier(\n",
    "    classifiers=estimators_5, \n",
    "    meta_classifier=tempsvC_5,\n",
    "    verbose=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softmax', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=12,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=10,\n",
       "                                                       min_samples_split=3,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_...\n",
       "                   drop_last_proba=False,\n",
       "                   meta_classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                       coef0=0.0, decision_function_shape='ovr',\n",
       "                                       degree=3, gamma='auto_deprecated',\n",
       "                                       kernel='rbf', max_iter=-1,\n",
       "                                       probability=False, random_state=None,\n",
       "                                       shrinking=True, tol=0.001,\n",
       "                                       verbose=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackingc_5.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   51    1\n",
       "1   54  128   18\n",
       "2    4   30  166"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stackingc_5.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.64      0.63       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  150   49    1\n",
       "1   54  120   26\n",
       "2    3   25  172"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=stackingc_5.clfs_[2].predict((xtest))\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Generate multiple weak models using the existing features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "combcols=(list(combinations(np.arange(0,12,1), 5)))\n",
    "len(combcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakmodles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(combcols)):\n",
    "#     print(combcols[i])\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=combcols[i]), xgb_model_5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf1 = StackingCVClassifier(classifiers=weakmodles,verbose=2,\n",
    "                           meta_classifier=LogisticRegression(),random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 792 classifiers...\n",
      "Fitting classifier1: pipeline (1/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: pipeline (2/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: pipeline (3/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier4: pipeline (4/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier5: pipeline (5/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier6: pipeline (6/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier7: pipeline (7/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier8: pipeline (8/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier9: pipeline (9/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier10: pipeline (10/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier11: pipeline (11/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier12: pipeline (12/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier13: pipeline (13/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier14: pipeline (14/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier15: pipeline (15/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier16: pipeline (16/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier17: pipeline (17/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier18: pipeline (18/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier19: pipeline (19/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier20: pipeline (20/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier21: pipeline (21/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier22: pipeline (22/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier23: pipeline (23/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier24: pipeline (24/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier25: pipeline (25/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier26: pipeline (26/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier27: pipeline (27/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier28: pipeline (28/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier29: pipeline (29/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier30: pipeline (30/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier31: pipeline (31/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier32: pipeline (32/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier33: pipeline (33/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier34: pipeline (34/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier35: pipeline (35/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier36: pipeline (36/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier37: pipeline (37/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier38: pipeline (38/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier39: pipeline (39/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier40: pipeline (40/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier41: pipeline (41/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier42: pipeline (42/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier43: pipeline (43/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier44: pipeline (44/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier45: pipeline (45/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier46: pipeline (46/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier47: pipeline (47/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier48: pipeline (48/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier49: pipeline (49/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier50: pipeline (50/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier51: pipeline (51/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier52: pipeline (52/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier53: pipeline (53/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier54: pipeline (54/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier55: pipeline (55/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier56: pipeline (56/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier57: pipeline (57/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier58: pipeline (58/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier59: pipeline (59/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier60: pipeline (60/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier61: pipeline (61/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier62: pipeline (62/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier63: pipeline (63/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier64: pipeline (64/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier65: pipeline (65/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier66: pipeline (66/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier67: pipeline (67/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier68: pipeline (68/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier69: pipeline (69/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier70: pipeline (70/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier71: pipeline (71/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier72: pipeline (72/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier73: pipeline (73/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier74: pipeline (74/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier75: pipeline (75/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier76: pipeline (76/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier77: pipeline (77/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier78: pipeline (78/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier79: pipeline (79/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier80: pipeline (80/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier81: pipeline (81/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier82: pipeline (82/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier83: pipeline (83/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier84: pipeline (84/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier85: pipeline (85/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier86: pipeline (86/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier87: pipeline (87/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier88: pipeline (88/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier89: pipeline (89/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier90: pipeline (90/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier91: pipeline (91/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier92: pipeline (92/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier93: pipeline (93/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier94: pipeline (94/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier95: pipeline (95/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier96: pipeline (96/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier97: pipeline (97/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier98: pipeline (98/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier99: pipeline (99/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier100: pipeline (100/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier101: pipeline (101/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier102: pipeline (102/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier103: pipeline (103/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier104: pipeline (104/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier105: pipeline (105/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier106: pipeline (106/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier107: pipeline (107/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier108: pipeline (108/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier109: pipeline (109/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier110: pipeline (110/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier111: pipeline (111/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier112: pipeline (112/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier113: pipeline (113/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier114: pipeline (114/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier115: pipeline (115/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier116: pipeline (116/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier117: pipeline (117/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier118: pipeline (118/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier119: pipeline (119/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier120: pipeline (120/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier121: pipeline (121/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier122: pipeline (122/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier123: pipeline (123/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier124: pipeline (124/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier125: pipeline (125/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier126: pipeline (126/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier127: pipeline (127/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier128: pipeline (128/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier129: pipeline (129/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier130: pipeline (130/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier131: pipeline (131/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier132: pipeline (132/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier133: pipeline (133/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier134: pipeline (134/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier135: pipeline (135/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier136: pipeline (136/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier137: pipeline (137/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier138: pipeline (138/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier139: pipeline (139/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier140: pipeline (140/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier141: pipeline (141/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier142: pipeline (142/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier143: pipeline (143/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier144: pipeline (144/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier145: pipeline (145/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier146: pipeline (146/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier147: pipeline (147/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier148: pipeline (148/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier149: pipeline (149/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier150: pipeline (150/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier151: pipeline (151/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier152: pipeline (152/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier153: pipeline (153/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier154: pipeline (154/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier155: pipeline (155/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier156: pipeline (156/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier157: pipeline (157/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier158: pipeline (158/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier159: pipeline (159/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier160: pipeline (160/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier161: pipeline (161/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier162: pipeline (162/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier163: pipeline (163/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier164: pipeline (164/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier165: pipeline (165/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier166: pipeline (166/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier167: pipeline (167/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier168: pipeline (168/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier169: pipeline (169/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier170: pipeline (170/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier171: pipeline (171/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier172: pipeline (172/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier173: pipeline (173/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier174: pipeline (174/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier175: pipeline (175/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier176: pipeline (176/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier177: pipeline (177/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier178: pipeline (178/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier179: pipeline (179/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier180: pipeline (180/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier181: pipeline (181/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier182: pipeline (182/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier183: pipeline (183/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier184: pipeline (184/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier185: pipeline (185/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier186: pipeline (186/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier187: pipeline (187/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier188: pipeline (188/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier189: pipeline (189/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier190: pipeline (190/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier191: pipeline (191/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier192: pipeline (192/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier193: pipeline (193/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier194: pipeline (194/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier195: pipeline (195/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier196: pipeline (196/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier197: pipeline (197/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier198: pipeline (198/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier199: pipeline (199/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier200: pipeline (200/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier201: pipeline (201/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier202: pipeline (202/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier203: pipeline (203/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier204: pipeline (204/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 2, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier205: pipeline (205/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier206: pipeline (206/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier207: pipeline (207/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier208: pipeline (208/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier209: pipeline (209/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier210: pipeline (210/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier211: pipeline (211/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier212: pipeline (212/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier213: pipeline (213/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier214: pipeline (214/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier215: pipeline (215/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier216: pipeline (216/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier217: pipeline (217/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier218: pipeline (218/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier219: pipeline (219/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier220: pipeline (220/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier221: pipeline (221/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier222: pipeline (222/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier223: pipeline (223/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier224: pipeline (224/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier225: pipeline (225/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier226: pipeline (226/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier227: pipeline (227/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier228: pipeline (228/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier229: pipeline (229/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier230: pipeline (230/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier231: pipeline (231/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier232: pipeline (232/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier233: pipeline (233/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier234: pipeline (234/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier235: pipeline (235/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier236: pipeline (236/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier237: pipeline (237/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier238: pipeline (238/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier239: pipeline (239/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier240: pipeline (240/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier241: pipeline (241/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier242: pipeline (242/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier243: pipeline (243/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier244: pipeline (244/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier245: pipeline (245/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier246: pipeline (246/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier247: pipeline (247/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier248: pipeline (248/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier249: pipeline (249/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier250: pipeline (250/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier251: pipeline (251/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier252: pipeline (252/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier253: pipeline (253/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier254: pipeline (254/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier255: pipeline (255/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier256: pipeline (256/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier257: pipeline (257/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier258: pipeline (258/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier259: pipeline (259/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier260: pipeline (260/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 3, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier261: pipeline (261/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier262: pipeline (262/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier263: pipeline (263/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier264: pipeline (264/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier265: pipeline (265/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier266: pipeline (266/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier267: pipeline (267/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier268: pipeline (268/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier269: pipeline (269/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier270: pipeline (270/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier271: pipeline (271/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier272: pipeline (272/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier273: pipeline (273/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier274: pipeline (274/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier275: pipeline (275/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier276: pipeline (276/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier277: pipeline (277/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier278: pipeline (278/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier279: pipeline (279/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier280: pipeline (280/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier281: pipeline (281/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier282: pipeline (282/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier283: pipeline (283/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier284: pipeline (284/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier285: pipeline (285/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier286: pipeline (286/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier287: pipeline (287/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier288: pipeline (288/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier289: pipeline (289/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier290: pipeline (290/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier291: pipeline (291/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier292: pipeline (292/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier293: pipeline (293/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier294: pipeline (294/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier295: pipeline (295/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 4, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier296: pipeline (296/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier297: pipeline (297/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier298: pipeline (298/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier299: pipeline (299/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier300: pipeline (300/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier301: pipeline (301/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier302: pipeline (302/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier303: pipeline (303/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier304: pipeline (304/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier305: pipeline (305/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier306: pipeline (306/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier307: pipeline (307/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier308: pipeline (308/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier309: pipeline (309/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier310: pipeline (310/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier311: pipeline (311/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier312: pipeline (312/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier313: pipeline (313/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier314: pipeline (314/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier315: pipeline (315/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 5, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier316: pipeline (316/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier317: pipeline (317/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier318: pipeline (318/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier319: pipeline (319/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier320: pipeline (320/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier321: pipeline (321/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier322: pipeline (322/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier323: pipeline (323/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier324: pipeline (324/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier325: pipeline (325/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 6, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier326: pipeline (326/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier327: pipeline (327/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier328: pipeline (328/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier329: pipeline (329/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 7, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier330: pipeline (330/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 8, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier331: pipeline (331/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 5), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier332: pipeline (332/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier333: pipeline (333/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier334: pipeline (334/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier335: pipeline (335/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier336: pipeline (336/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier337: pipeline (337/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 4, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier338: pipeline (338/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier339: pipeline (339/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier340: pipeline (340/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier341: pipeline (341/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier342: pipeline (342/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier343: pipeline (343/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier344: pipeline (344/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier345: pipeline (345/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier346: pipeline (346/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier347: pipeline (347/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier348: pipeline (348/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier349: pipeline (349/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier350: pipeline (350/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier351: pipeline (351/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier352: pipeline (352/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier353: pipeline (353/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier354: pipeline (354/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier355: pipeline (355/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier356: pipeline (356/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier357: pipeline (357/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier358: pipeline (358/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier359: pipeline (359/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier360: pipeline (360/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier361: pipeline (361/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier362: pipeline (362/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier363: pipeline (363/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier364: pipeline (364/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier365: pipeline (365/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier366: pipeline (366/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier367: pipeline (367/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier368: pipeline (368/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier369: pipeline (369/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier370: pipeline (370/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier371: pipeline (371/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier372: pipeline (372/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier373: pipeline (373/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier374: pipeline (374/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier375: pipeline (375/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier376: pipeline (376/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier377: pipeline (377/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier378: pipeline (378/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier379: pipeline (379/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier380: pipeline (380/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier381: pipeline (381/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier382: pipeline (382/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier383: pipeline (383/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier384: pipeline (384/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier385: pipeline (385/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier386: pipeline (386/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier387: pipeline (387/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier388: pipeline (388/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier389: pipeline (389/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier390: pipeline (390/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier391: pipeline (391/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier392: pipeline (392/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier393: pipeline (393/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier394: pipeline (394/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier395: pipeline (395/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier396: pipeline (396/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier397: pipeline (397/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier398: pipeline (398/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier399: pipeline (399/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier400: pipeline (400/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier401: pipeline (401/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier402: pipeline (402/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier403: pipeline (403/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier404: pipeline (404/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier405: pipeline (405/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier406: pipeline (406/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier407: pipeline (407/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier408: pipeline (408/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier409: pipeline (409/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier410: pipeline (410/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier411: pipeline (411/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier412: pipeline (412/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier413: pipeline (413/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier414: pipeline (414/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 2, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier415: pipeline (415/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 6), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier416: pipeline (416/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier417: pipeline (417/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier418: pipeline (418/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier419: pipeline (419/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier420: pipeline (420/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier421: pipeline (421/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier422: pipeline (422/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier423: pipeline (423/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier424: pipeline (424/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier425: pipeline (425/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier426: pipeline (426/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier427: pipeline (427/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier428: pipeline (428/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier429: pipeline (429/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier430: pipeline (430/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier431: pipeline (431/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier432: pipeline (432/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier433: pipeline (433/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier434: pipeline (434/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier435: pipeline (435/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier436: pipeline (436/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier437: pipeline (437/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier438: pipeline (438/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier439: pipeline (439/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier440: pipeline (440/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier441: pipeline (441/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier442: pipeline (442/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier443: pipeline (443/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier444: pipeline (444/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier445: pipeline (445/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier446: pipeline (446/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier447: pipeline (447/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier448: pipeline (448/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier449: pipeline (449/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier450: pipeline (450/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier451: pipeline (451/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier452: pipeline (452/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier453: pipeline (453/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier454: pipeline (454/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier455: pipeline (455/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier456: pipeline (456/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier457: pipeline (457/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier458: pipeline (458/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier459: pipeline (459/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier460: pipeline (460/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier461: pipeline (461/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier462: pipeline (462/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier463: pipeline (463/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 8, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier464: pipeline (464/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier465: pipeline (465/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier466: pipeline (466/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 7, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier467: pipeline (467/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier468: pipeline (468/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 8, 9, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier469: pipeline (469/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier470: pipeline (470/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 3, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier471: pipeline (471/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 7), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier472: pipeline (472/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier473: pipeline (473/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier474: pipeline (474/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier475: pipeline (475/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier476: pipeline (476/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 8), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier477: pipeline (477/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier478: pipeline (478/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier479: pipeline (479/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 7, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier480: pipeline (480/792)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(1, 4, 5, 8, 9), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softmax', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "sclf1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sclf1.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(sclf,\n",
    "                         xtrain,ytrain,\n",
    "                         cv=5,\n",
    "                         scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Combine the 3 stacking classifiers\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_3 = LogisticRegression()\n",
    "temprf_3=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2_3=RandomForestClassifier()\n",
    "tempsvC_3= SVC()\n",
    "\n",
    "estimators_3 = [\n",
    "    rf_3,\n",
    "    xgb_model_3,\n",
    "    SVC_clf_3,\n",
    "    lr_3,\n",
    "    kneigh_3\n",
    "]\n",
    "stackingc_5 = StackingClassifier(\n",
    "    classifiers=estimators_3, \n",
    "    meta_classifier=tempsvC_3,\n",
    "    verbose=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from mlxtend.feature_selection import ColumnSelector\n",
    "# from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "# pipe1 = make_pipeline(rf)\n",
    "# pipe11 = make_pipeline( xgb_model)\n",
    "# pipe12 = make_pipeline( SVC_clf)\n",
    "# pipe13 = make_pipeline( LogisticRegression())\n",
    "\n",
    "# pipe2 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), rf )\n",
    "# pipe21 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), xgb_model )\n",
    "# pipe22 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), SVC_clf )\n",
    "# pipe22 = make_pipeline(ColumnSelector(cols=(0,1,2,9,10)), LogisticRegression() )\n",
    "\n",
    "\n",
    "\n",
    "# sclf1 = StackingCVClassifier(classifiers=[    pipe1,    pipe11,    pipe12 ],\n",
    "#                            meta_classifier=LogisticRegression(),random_state=42)\n",
    "\n",
    "# sclf2 = StackingCVClassifier(classifiers=[    pipe2,    pipe21,    pipe22],\n",
    "#                            meta_classifier=LogisticRegression(),random_state=42)\n",
    "\n",
    "# sclf = StackingCVClassifier(classifiers=[\n",
    "#    sclf1,sclf2\n",
    "# ], \n",
    "#                             meta_classifier=LogisticRegression(),\n",
    "#                             random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
