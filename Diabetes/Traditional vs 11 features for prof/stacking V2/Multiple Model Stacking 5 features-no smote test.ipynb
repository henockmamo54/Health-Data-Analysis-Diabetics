{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Read the dataset and preprocess\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','S000300','AGE','SEX',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 13)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60141, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>S000300</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>20.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>25.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>21.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>24.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  S000300   AGE  SEX  CLASS\n",
       "2      78.0     5.28     20.2  46.0  1.0      0\n",
       "5      90.0     5.74     25.5  52.0  1.0      0\n",
       "10     86.0     5.83     21.2  37.0  1.0      0\n",
       "11     86.0     4.73     22.0  39.0  1.0      0\n",
       "20     87.0     5.60     24.6  59.0  1.0      0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=data[['L100800','L104600','S000300','AGE','SEX','CLASS']]\n",
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    40247\n",
       "1    18735\n",
       "2     1159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='CLASS').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159 18735 40247\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0]\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 18535, 1: 18535, 0: 18535})\n",
      "18535 18535 18535\n",
      "(55605, 5) (55605,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[4],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Generate the classifier models based on the selected 12 features\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamter serach using grid search\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)\n",
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     random_state=randomseed,\n",
    "#     n_estimators=100, \n",
    "#     max_depth=12,\n",
    "#     min_samples_split=3,\n",
    "#     min_samples_leaf=10,\n",
    "#     max_features=\"auto\",\n",
    "# )\n",
    "\n",
    "# rf=rf_clf.best_estimator_\n",
    "rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation test for the model\n",
    "\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain,cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'S000300', 'AGE', 'SEX'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of the model using the test data\n",
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.999\n",
      "Accuracy on test set: 0.667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>132</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  137   62    1\n",
       "1   61  132    7\n",
       "2    4   65  131"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       200\n",
      "           1       0.51      0.66      0.58       200\n",
      "           2       0.94      0.66      0.77       200\n",
      "\n",
      "    accuracy                           0.67       600\n",
      "   macro avg       0.71      0.67      0.68       600\n",
      "weighted avg       0.71      0.67      0.68       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[3,5,7,9],\n",
    "              'n_estimators':[10,50,100,200,700]}\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = GridSearchCV(xgb_clf, parameters)\n",
    "xgb_clf.fit(xtrain, ytrain)\n",
    "xgb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed)\n",
    "# objective=\"multi:softmax\"\n",
    "# objective=\"binary:logistic\"\n",
    "# objective='multi:softprob'\n",
    "\n",
    "\n",
    "# xgb_model=xgb_clf.best_estimator_\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC_clf = SVC_clf2.best_estimator_\n",
    "SVC_clf=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>131</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  136   60    4\n",
       "1   51  131   18\n",
       "2    3   29  168"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       200\n",
      "           1       0.60      0.66      0.62       200\n",
      "           2       0.88      0.84      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.72      0.73       600\n",
      "weighted avg       0.73      0.72      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=0)\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=150)\n",
    "neigh.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression()\n",
    "temprf=RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "temprf2=RandomForestClassifier()\n",
    "tempsvC= SVC()\n",
    "\n",
    "estimators = [\n",
    "    rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,\n",
    "    lr,\n",
    "    neigh\n",
    "]\n",
    "stackingc = StackingClassifier(\n",
    "    classifiers=estimators, \n",
    "    meta_classifier=lr2,\n",
    "    verbose=2 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stackingc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stackingc.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=stackingc.clfs_[2].predict((xtest))\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('10-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,\n",
    "    lr,\n",
    "    neigh,\n",
    "    stackingc], \n",
    "                      ['rf',\n",
    "    'xgb_model',\n",
    "    'SVC_clf','lr','neigh','StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy: 0.74 (+/- 0.04) [rf]\n",
    "Accuracy: 0.70 (+/- 0.04) [xgb_model]\n",
    "Accuracy: 0.72 (+/- 0.03) [SVC_clf]\n",
    "Accuracy: 0.70 (+/- 0.04) [lr]\n",
    "Accuracy: 0.68 (+/- 0.04) [neigh]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
