{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prediction model tires to model the current year feature values with the next year's class value\n",
    "# with out any prediction for the feature values\n",
    "# smotenc added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Read dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','S000300','AGE','SEX',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 13)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60035, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>S000300</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>20.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>25.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>21.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>24.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  S000300   AGE  SEX  CLASS\n",
       "2      78.0     5.28     20.2  46.0  1.0      0\n",
       "5      90.0     5.74     25.5  52.0  1.0      0\n",
       "10     86.0     5.83     21.2  37.0  1.0      0\n",
       "11     86.0     4.73     22.0  39.0  1.0      0\n",
       "20     87.0     5.60     24.6  59.0  1.0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data=data[['L100800','L104600','S000300','AGE','SEX','CLASS']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    40171\n",
       "1    18708\n",
       "2     1156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='CLASS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156 18708 40171\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0]\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 18508, 1: 18508, 0: 18508})\n",
      "18508 18508 18508\n",
      "(55524, 5) (55524,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[2],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': [10, 50, 100, 150, 200, 300, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(\n",
    "#     random_state=randomseed,\n",
    "#     n_estimators=100,\n",
    "#     max_depth=12,\n",
    "#     min_samples_split=2,\n",
    "#     min_samples_leaf=10,\n",
    "#     max_features=\"auto\",\n",
    "# )\n",
    "\n",
    "rf=rf_clf.best_estimator_\n",
    "# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "#                        n_jobs=None, oob_score=False, random_state=None,\n",
    "#                        verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.04) [RandomForestClassifier] \n",
      " [[0.63983432 0.72897533 0.74446245 0.76229065 0.77795786 0.77399604\n",
      " 0.76373132 0.76048983 0.78054054 0.76252252]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6966666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD4CAYAAAAUymoqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAR/ElEQVR4nO3df7Ddd13n8efL1Aa7nYZA62xMK7esgd2WsoXG8kMpUF1aKFDc7cwW3TGw1YyI7qzO6papa7fAH1lULCjoZAa21HE3rWzRjF2tdaWOzArlpoaGdmwb2iBpGTWkRGrZMA3v/eN8oieXk+R8cu85597k+Zg5k+/38/18vt/3+fb2+7rf8znn3FQVkiT1+LZZFyBJWnkMD0lSN8NDktTN8JAkdTM8JEndTpt1AdNy9tln19zc3KzLkKQVZceOHfuq6pyF7adMeMzNzTE/Pz/rMiRpRUnyxVHtvmwlSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6nbKfMJ81+MHmLv+ziXb354tVy3ZviRppfHOQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd2WRXgkuSHJA0nuT7IzycuS3JPkoba+M8nHW98PJvkvC8Z+aHbVS9KpZ+YfEkzyCuCNwEur6mCSs4HT2+YfqaqFfzv2F4CdSX4bKODHgJdMrWBJ0uzDA1gH7KuqgwBVtQ8gycjOVfV3SW4Afr01/WJVfXUahUqSBpbDy1Z/BJyX5OEkH07y6qFtvz30stUvHW6sqv8JrAXOqqrfOtqOk2xOMp9k/tDTByb3DCTpFDPzO4+qeirJJcCrgNcCtyW5vm0e9bIVSc4F/ilQSc6sqqeOsu+twFaA1es21ESegCSdgmYeHgBVdQi4B7gnyS5g03GGfAD4r8C/AG4Efm6S9UmSjjTz8EjyQuCbVfVIa7oY+CLwoqP0fz3wncCtwBnA55L896p6cBr1SpKWQXgAZwK/luTZwDPAbmAz8HEGcx5fb/32MXhX1s3ANVVVwN8n+XkGk+eXT71ySTpFzTw8qmoH8MoRm15zlCEvXDD+DuCOJS5LknQMy+HdVpKkFcbwkCR1MzwkSd0MD0lSN8NDktRt5u+2mpaL1q9hfstVsy5Dkk4K3nlIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSup026wKmZdfjB5i7/s5Zl6EZ2LPlqlmXIJ10vPOQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd1mHh5JfihJJfnnQ20bkvx+ki8k2ZHkk0kua9veluRvk+wcelwwu2cgSaeemYcH8FbgU8C1AEmeBdwJbK2qf1ZVlwA/DTx/aMxtVXXx0OPBqVctSaewmYZHkjOB7wOuo4UH8CPAn1fV9sP9qurzVXXL9CuUJI0y60+YvwX4w6p6OMn+JC8FLgTuO864f5vk+4fWX1FVX59YlZKkI8z6Zau3Atva8ra2foQkn0jy+SR3DDUvfNlqZHAk2ZxkPsn8oacPLH31knSKmtmdR5LnApcDL0pSwCqggJuAyw73q6ofSrIR+OXeY1TVVmArwOp1G2op6pYkzfbO4xrg1qp6XlXNVdV5wGPAw8D3JXnzUN8zZlKhJGmkWc55vBXYsqDtfwE/DLwReH+Sm4G/Br4GvHeo38I5j5+sqv87yWIlSf9oZuFRVa8Z0fbBodU3HGXcLcAtEylKkjSWWU+YS5JWIMNDktTN8JAkdTM8JEndDA9JUrdZfz3J1Fy0fg3zW66adRmSdFLwzkOS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LU7bRZFzAtux4/wNz1d866DGkse7ZcNesSpGPyzkOS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndxgqPJDckeSDJ/Ul2JnlZkvOTfCbJI0luS3J667u6re9u2+eG9vOu1v5Qkita27OS3Jvkc+0YNw317z6GJGnyjhseSV4BvBF4aVW9GPhB4EvAfwN+tao2AE8C17Uh1wFPVtX3AL/a+pHkAuBa4ELgSuDDSVYBB4HLq+pfAhcDVyZ5edtX1zEkSdMxzp3HOmBfVR0EqKp9wJeBy4GPtz4fA97Slq9u67TtP5AkrX1bVR2sqseA3cClNfBU6//t7VFtTO8xJElTME54/BFwXpKHk3w4yauB5wJfrapnWp+9wPq2vJ7BnQlt+4HW/x/aF45JsirJTuBvgLur6jMneIwjJNmcZD7J/KGnD4zxVCVJ4zhueLS7gkuAzcDfArcBbx/Vtf076g6gjtFOVR2qqouBc4FLk7zoWP2Ps2249q1VtbGqNq46Y82IIZKkEzHWhHm7uN9TVTcCPwVcBjw7yeEvVjwXeKIt7wXOA2jb1wD7h9tHjDl8nK8C9zCYE9l3AseQJE3BOBPmL0yyYajpYuCLwCeBa1rbJuD32vL2tk7b/idVVa392vZOqfOBDcC9Sc5J8ux2rO9gMCH/l21M7zEkSVMwzleynwn8WrvAP8NgonszcBawLcl7gb8APtL6fwT4rSS7GdwNXAtQVQ8kuR14sO3nnVV1KMk64GPtnVffBtxeVb/f9vWfe44hSZqOnCq/sK9et6HWbbp51mVIY/HveWi5SLKjqjYubPcT5pKkboaHJKmb4SFJ6mZ4SJK6GR6SpG7jvFX3pHDR+jXM+w4WSVoS3nlIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6GR6SpG6GhySpm+EhSepmeEiSup026wKmZdfjB5i7/s5ZlyFpyvZsuWrWJZyUvPOQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd3GCo8kT41ouyzJfUmeSXLNgm2bkjzSHptGjN2e5PML2n46yUNJHkjyvqH2dyXZ3bZdMdR+ZWvbneT6cZ6HJGlpLOZzHn8FvA34T8ONSZ4D3AhsBArYkWR7VT3Ztv9r4KkFY14LXA28uKoOJvnO1n4BcC1wIfBdwB8neUEb9iHgXwF7gc+2Yzy4iOcjSRrTCb9sVVV7qup+4JsLNl0B3F1V+1tg3A1cCZDkTOBngfcuGPMOYEtVHWz7/pvWfjWwraoOVtVjwG7g0vbYXVWPVtU3gG2tryRpCiYx57Ee+NLQ+t7WBvAe4FeApxeMeQHwqiSfSfKnSb73OPs61jEkSRM2ifDIiLZKcjHwPVX1iRHbTwPWAi8Hfg64PUmOtq9jtB9ZSLI5yXyS+UNPHxj7CUiSjm0S4bEXOG9o/VzgCeAVwCVJ9gCfAl6Q5J6hMXfUwL0MXgo7+xj7Olr7Eapqa1VtrKqNq85YswRPTZIEkwmPu4DXJVmbZC3wOuCuqvqNqvquqpoDvh94uKpe08b8LnA5QJsQPx3YB2wHrk2yOsn5wAbgXuCzwIYk5yc5ncGk+vYJPBdJ0gjjvtvqjCR7h9bfD/wZ8AkGLze9KclNVXVhVe1P8h4GF3iAd1fV/uPs/6PAR9vbd78BbKqqAh5IcjvwIPAM8M6qOgSQ5KcYBNUq4KNV9cCYz0WStEgZXKNPfqvXbah1m26edRmSpsyvZF+cJDuqauPCdj9hLknqZnhIkroZHpKkboaHJKmb4SFJ6raYL0ZcUS5av4Z533UhSUvCOw9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSN8NDktTN8JAkdTM8JEndDA9JUjfDQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSt9NmXcC07Hr8AHPX3znrMiRpqvZsuWoi+/XOQ5LUzfCQJHUzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd3GCo8kT41ouyzJfUmeSXLNgm2bkjzSHpuG2i9JsivJ7iQfTJLWfnGSTyfZmWQ+yaWtPa3f7iT3J3np8Y4hSZq8xdx5/BXwNuB/DDcmeQ5wI/Ay4FLgxiRr2+bfADYDG9rjytb+PuCmqroY+MW2DvD6ob6b2/jjHUOSNGEnHB5Vtaeq7ge+uWDTFcDdVbW/qp4E7gauTLIOOKuq/ryqCrgVeMvh3QFnteU1wBNt+Wrg1hr4NPDstp+RxzjR5yJJ6jOJrydZD3xpaH1va1vflhe2A/xH4K4kv8wg0F45xr5GtR8hyWYGdyysOuucE3s2kqRvMYkJ84xoq2O0A7wD+JmqOg/4GeAji9jXPzZUba2qjVW1cdUZa45buCRpPJMIj73AeUPr5zJ4GWpvW17YDrAJuKMt/w6DeYzj7WtUuyRpCiYRHncBr0uytk1ivw64q6q+DHwtycvbu6x+FPi9NuYJ4NVt+XLgkba8HfjR9q6rlwMH2n5GHmMCz0WSNMK4cx5nJBmer3g/8GfAJ4C1wJuS3FRVF1bV/iTvAT7b+r67qva35XcAtwDfAfxBewD8OPCBJKcB/482TwH8b+ANwG7gaeDtAMc5hiRpwjJ449PJb/W6DbVu082zLkOSpmqxf88jyY6q2riw3U+YS5K6GR6SpG6GhySpm+EhSepmeEiSuk3i60mWpYvWr2F+ke86kCQNeOchSepmeEiSuhkekqRuhockqZvhIUnqZnhIkroZHpKkboaHJKmb4SFJ6mZ4SJK6nTJ/DCrJ14CHZl1Hp7OBfbMuosNKqxeseRpWWr1gzcOeV1XnLGw8Zb7bCnho1F/DWs6SzK+kmldavWDN07DS6gVrHocvW0mSuhkekqRup1J4bJ11ASdgpdW80uoFa56GlVYvWPNxnTIT5pKkpXMq3XlIkpaI4SFJ6nZShEeSK5M8lGR3kutHbF+d5La2/TNJ5oa2vau1P5TkiuVcb5K5JF9PsrM9fnMa9Y5Z82VJ7kvyTJJrFmzblOSR9ti0Qmo+NHSety+Ten82yYNJ7k/yf5I8b2jbcj3Hx6p56ud4zJp/IsmuVtenklwwtG05Xi9G1jvx60VVregHsAr4AvB84HTgc8AFC/r8JPCbbfla4La2fEHrvxo4v+1n1TKudw74/DI9x3PAi4FbgWuG2p8DPNr+XduW1y7nmtu2p5bhOX4tcEZbfsfQz8VyPscja57FOe6o+ayh5TcDf9iWl+v14mj1TvR6cTLceVwK7K6qR6vqG8A24OoFfa4GPtaWPw78QJK09m1VdbCqHgN2t/0t13pn5bg1V9Weqrof+OaCsVcAd1fV/qp6ErgbuHKZ1zwL49T7yap6uq1+Gji3LS/nc3y0mmdlnJr/bmj1nwCH31W0LK8Xx6h3ok6G8FgPfGlofW9rG9mnqp4BDgDPHXPsUltMvQDnJ/mLJH+a5FUTrvVb6ml6ztMszvFSHPdZSeaTfDrJW5a2tJF6670O+IMTHLtUFlMzTP8cw5g1J3lnki8A7wP+Q8/YJbaYemGC14uT4etJRv1GvjB5j9ZnnLFLbTH1fhn47qr6SpJLgN9NcuGC3zwmYTHnaRbneCmO+91V9USS5wN/kmRXVX1hiWobZex6k/w7YCPw6t6xS2wxNcP0zzGMWXNVfQj4UJIfBn4B2DTu2CW2mHoner04Ge489gLnDa2fCzxxtD5JTgPWAPvHHLvUTrjedrv8FYCq2sHgtdAXTLjeI+ppes7TLM7xoo9bVU+0fx8F7gFespTFjTBWvUl+ELgBeHNVHewZOwGLqXkW5xj6z9U24PBd0XK9Xgz7h3onfr2Y5GTPNB4M7p4eZTCBdXhC6cIFfd7JkRPQt7flCzlyAuxRJj8Btph6zzlcH4MJtMeB5yyHczzU9xa+dcL8MQYTuWvb8nKveS2wui2fDTzCgknKGf1cvITBBWDDgvZle46PUfPUz3FHzRuGlt8EzLfl5Xq9OFq9E71eTPQ/1LQewBuAh9sP6Q2t7d0MftMBeBbwOwwmuO4Fnj809oY27iHg9cu5XuDfAA+0H6D7gDcto3P8vQx+S/p74CvAA0Nj/317LruBty/3moFXArvaed4FXLdM6v1j4K+Bne2xfQWc45E1z+ocj1nzB9r/ZzuBTzJ0sV6m14uR9U76euHXk0iSup0Mcx6SpCkzPCRJ3QwPSVI3w0OS1M3wkCR1MzwkSd0MD0lSt/8Pl2sijY/mYqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'S000300', 'AGE', 'SEX'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.999\n",
      "Accuracy on test set: 0.697\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>141</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  137   63    0\n",
       "1   53  141    6\n",
       "2    3   57  140"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       200\n",
      "           1       0.54      0.70      0.61       200\n",
      "           2       0.96      0.70      0.81       200\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.74      0.70      0.71       600\n",
      "weighted avg       0.74      0.70      0.71       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71 (+/- 0.04) [xgb_model] \n",
      " [[0.59949577 0.68539528 0.70772555 0.7376193  0.73725914 0.72375293\n",
      " 0.69421934 0.71168738 0.74072072 0.73333333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  136   64    0\n",
       "1   53  127   20\n",
       "2    1   27  172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       200\n",
      "           1       0.58      0.64      0.61       200\n",
      "           2       0.90      0.86      0.88       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.72      0.73       600\n",
      "weighted avg       0.73      0.72      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10, 15, 20, 25, 30, 70],\n",
       "                         'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# sorted(SVC_clf2.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC_clf = SVC_clf2.best_estimator_\n",
    "# SVC_clf = SVC(C=20, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "#     kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "#     shrinking=True, tol=0.001, verbose=False)\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.03) [SVC_clf] \n",
      " [[0.64091482 0.72069152 0.72105168 0.74878444 0.73905997 0.73095624\n",
      " 0.72285251 0.7376193  0.72216216 0.71873874]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7266666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>124</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  134   65    1\n",
       "1   51  124   25\n",
       "2    2   20  178"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       200\n",
      "           1       0.59      0.62      0.61       200\n",
      "           2       0.87      0.89      0.88       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, xtrain, ytrain, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, np_utils.to_categorical( ytrain.to_numpy()), \n",
    "                  epochs=100, batch_size=10,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "\n",
    "tempdata=data5\n",
    "\n",
    "diabetic = tempdata[tempdata.CLASS == 2]\n",
    "prediabetic = tempdata[tempdata.CLASS == 1].sample(diabetic.shape[0],random_state=0)\n",
    "normal = tempdata[tempdata.CLASS == 0].sample(diabetic.shape[0],random_state=0)\n",
    "\n",
    "tempdata5=pd.concat([diabetic,prediabetic,normal])\n",
    "tempdata5.iloc[:, 3:-2]=scaler.transform(tempdata5.iloc[:, 3:-2])\n",
    "\n",
    "pred5 = rf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata5Rcolumns=tempdata5.iloc[:, 3:-2]\n",
    "tempdata5Rcolumns.columns=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n",
    "pred5 = xgb_model.predict((tempdata5Rcolumns))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = SVC_clf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('_DiabeticClassifierModelForNextYear_rf_model', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_DiabeticClassifierModelForNextYear_scaler', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
