{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prediction model tires to model the current year feature values with the next year's class value\n",
    "# with out any prediction for the feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','S000300','AGE','SEX',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 13)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select only the important features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60035, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>S000300</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>20.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>25.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>21.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>24.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  S000300   AGE  SEX  CLASS\n",
       "2      78.0     5.28     20.2  46.0  1.0      0\n",
       "5      90.0     5.74     25.5  52.0  1.0      0\n",
       "10     86.0     5.83     21.2  37.0  1.0      0\n",
       "11     86.0     4.73     22.0  39.0  1.0      0\n",
       "20     87.0     5.60     24.6  59.0  1.0      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data=data[['L100800','L104600','S000300','AGE','SEX','CLASS']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    40171\n",
       "1    18708\n",
       "2     1156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='CLASS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Downsample the dataset\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156 18708 40171\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index).sample(\n",
    "    2 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    2 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': [10, 50, 100, 150, 200, 300, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "rf=rf_clf.best_estimator_\n",
    "rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6983333333333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'S000300', 'AGE', 'SEX'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.698\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>116</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  130   70    0\n",
       "1   63  116   21\n",
       "2    5   22  173"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65       200\n",
      "           1       0.56      0.58      0.57       200\n",
      "           2       0.89      0.86      0.88       200\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.70      0.70      0.70       600\n",
      "weighted avg       0.70      0.70      0.70       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=7,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.01) [xgb_model] \n",
      " [[0.72048611 0.76041667 0.70855148 0.73298429 0.72425829 0.72600349\n",
      " 0.71553229 0.7469459  0.72251309 0.72251309]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7133333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>120</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  132   67    1\n",
       "1   58  120   22\n",
       "2    2   22  176"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       200\n",
      "           1       0.57      0.60      0.59       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.71       600\n",
      "   macro avg       0.72      0.71      0.71       600\n",
      "weighted avg       0.72      0.71      0.71       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10, 15, 20, 25, 30, 70],\n",
       "                         'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# sorted(SVC_clf2.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf = SVC_clf2.best_estimator_\n",
    "# SVC_clf = SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "#     kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "#     shrinking=True, tol=0.001, verbose=False)\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.02) [SVC_clf] \n",
      " [[0.72743056 0.75868056 0.70855148 0.7434555  0.72251309 0.73298429\n",
      " 0.70506108 0.7556719  0.73123909 0.72949389]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>122</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  136   63    1\n",
       "1   53  122   25\n",
       "2    1   22  177"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "estimators = [\n",
    "    rf,\n",
    "    xgb_model,\n",
    "    SVC_clf\n",
    "]\n",
    "reg = StackingClassifier(\n",
    "    classifiers=estimators,\n",
    "    meta_classifier=RandomForestClassifier(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.77 (+/- 0.01) [rf]\n",
      "Accuracy: 0.73 (+/- 0.01) [xgb_model]\n",
      "Accuracy: 0.73 (+/- 0.02) [SVC_clf]\n",
      "Accuracy: 0.77 (+/- 0.01) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,reg], \n",
    "                      ['rf',\n",
    "    'xgb_model',\n",
    "    'SVC_clf',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=700,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random...\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=10,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=42,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>118</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  129   71    0\n",
       "1   62  118   20\n",
       "2    5   22  173"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65       200\n",
      "           1       0.56      0.59      0.57       200\n",
      "           2       0.90      0.86      0.88       200\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.70      0.70      0.70       600\n",
      "weighted avg       0.70      0.70      0.70       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, xtrain, ytrain, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, np_utils.to_categorical( ytrain.to_numpy()), \n",
    "                  epochs=100, batch_size=10,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "\n",
    "tempdata=data5\n",
    "\n",
    "diabetic = tempdata[tempdata.CLASS == 2]\n",
    "prediabetic = tempdata[tempdata.CLASS == 1].sample(diabetic.shape[0],random_state=0)\n",
    "normal = tempdata[tempdata.CLASS == 0].sample(diabetic.shape[0],random_state=0)\n",
    "\n",
    "tempdata5=pd.concat([diabetic,prediabetic,normal])\n",
    "tempdata5.iloc[:, 3:-2]=scaler.transform(tempdata5.iloc[:, 3:-2])\n",
    "\n",
    "pred5 = rf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata5Rcolumns=tempdata5.iloc[:, 3:-2]\n",
    "tempdata5Rcolumns.columns=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n",
    "pred5 = xgb_model.predict((tempdata5Rcolumns))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = SVC_clf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('_DiabeticClassifierModelForNextYear_rf_model', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_DiabeticClassifierModelForNextYear_scaler', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
