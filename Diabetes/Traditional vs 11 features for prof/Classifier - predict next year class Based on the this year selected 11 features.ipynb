{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prediction model tires to model the current year feature values with the next year's class value\n",
    "# with out any prediction for the feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original=x_original [['Unnamed: 0','L100800','L104600','L103000','S000300','L101700','L100700','FIELD_33',\n",
    "                       'FIELD_38','FIELD_40','FIELD_31','SEX','AGE',#'CLASS',\n",
    "                       'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24'\n",
    "                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','CLASS' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select only the important features\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56438, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "print(data.shape)\n",
    "data=data[['L100800','L104600', 'L103000', 'S000300', 'L101700', 'L100700',\n",
    "       'FIELD_33', 'FIELD_38', 'FIELD_40', 'FIELD_31', 'SEX', 'AGE','CLASS']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    38091\n",
       "1    17305\n",
       "2     1042\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='CLASS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Downsample the dataset\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042 17305 38091\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index).sample(\n",
    "    2 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    2 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "# rf=rf_clf.best_estimator_\n",
    "# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "#                        n_jobs=None, oob_score=False, random_state=None,\n",
    "#                        verbose=0, warm_start=False)\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.01) [RandomForestClassifier] \n",
      " [[0.71005917 0.74161736 0.74161736 0.70808679 0.74801587 0.7202381\n",
      " 0.74404762 0.73412698 0.74206349 0.73015873]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7416666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'L101700', 'S000300', 'L103000', 'AGE', 'L100700',\n",
      "       'SEX', 'FIELD_38', 'FIELD_40', 'FIELD_33', 'FIELD_31'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.815\n",
      "Accuracy on test set: 0.742\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  145   55    0\n",
       "1   49  133   18\n",
       "2    1   32  167"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       200\n",
      "           1       0.60      0.67      0.63       200\n",
      "           2       0.90      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=7,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.01) [xgb_model] \n",
      " [[0.71597633 0.74161736 0.72583826 0.71005917 0.75       0.7281746\n",
      " 0.75198413 0.73015873 0.72222222 0.71825397]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7433333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   52    0\n",
       "1   49  133   18\n",
       "2    3   32  165"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.61      0.67      0.64       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10, 15, 20, 25, 30, 70],\n",
       "                         'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# sorted(SVC_clf2.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC_clf = SVC_clf2.best_estimator_\n",
    "SVC_clf = SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.02) [SVC_clf] \n",
      " [[0.69822485 0.73964497 0.74556213 0.72781065 0.74404762 0.70634921\n",
      " 0.75992063 0.74007937 0.74007937 0.7202381 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7466666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>132</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  151   48    1\n",
       "1   52  132   16\n",
       "2    3   32  165"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       200\n",
      "           1       0.62      0.66      0.64       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, xtrain, ytrain, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, np_utils.to_categorical( ytrain.to_numpy()), \n",
    "                  epochs=100, batch_size=10,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "\n",
    "tempdata=data5\n",
    "\n",
    "diabetic = tempdata[tempdata.CLASS == 2]\n",
    "prediabetic = tempdata[tempdata.CLASS == 1].sample(diabetic.shape[0],random_state=0)\n",
    "normal = tempdata[tempdata.CLASS == 0].sample(diabetic.shape[0],random_state=0)\n",
    "\n",
    "tempdata5=pd.concat([diabetic,prediabetic,normal])\n",
    "tempdata5.iloc[:, 3:-2]=scaler.transform(tempdata5.iloc[:, 3:-2])\n",
    "\n",
    "pred5 = rf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata5Rcolumns=tempdata5.iloc[:, 3:-2]\n",
    "tempdata5Rcolumns.columns=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n",
    "pred5 = xgb_model.predict((tempdata5Rcolumns))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = SVC_clf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('_DiabeticClassifierModelForNextYear_rf_model', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_DiabeticClassifierModelForNextYear_scaler', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
