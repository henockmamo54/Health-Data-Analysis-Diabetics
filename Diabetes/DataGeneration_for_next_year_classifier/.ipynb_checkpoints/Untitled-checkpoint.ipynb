{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "randomseed=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('../sep19SexAndAgeAddedFINAL DATASET_ver2.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data set \n",
    "data=data[data.FIELD_16!=1] # exclude people who are diagnosed for (diabetes) \n",
    "data=data[data.FIELD_23!=1] # exclude people who are on medication for diabetes\n",
    "\n",
    "data=data[data.FIELD_15!=1] # exclude people who are diagnosed for (high blood pressure)\n",
    "data=data[data.FIELD_22!=1] # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data=data[data.FIELD_17!=1] # exclude people who are diagnosed for hyperlipidemia\n",
    "data=data[data.FIELD_24!=1] # exclude people who are on medication for hyperlipidemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Class to the dataset \n",
    "conditions = [\n",
    "    (data.L100800 < 100)  ,\n",
    "    (data.L100800 >= 100) & (data.L100800 < 126),\n",
    "    (data.L100800 >= 126)]\n",
    "choices = [0,1,2]\n",
    "data['CLASS'] = np.select(conditions, choices, default=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142716, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata=data.copy()[['L104600','L103000','S000300','L101700','L100700','FIELD_33','FIELD_38','FIELD_40','S000501', 'S000502',\n",
    "                    'FIELD_31','SEX','AGE','CLASS']].dropna()\n",
    "mydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 104030, 0: 104030, 2: 104030})\n",
      "104030 104030 104030\n",
      "(312090, 13) (312090,)\n"
     ]
    }
   ],
   "source": [
    "x=mydata[['L104600','L103000','S000300','L101700','L100700','FIELD_33','FIELD_38','FIELD_40','S000501', 'S000502',\n",
    "                    'FIELD_31','SEX','AGE']]\n",
    "y=mydata[['CLASS']]\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=randomseed)\n",
    "X_res, y_res = sm.fit_resample(x, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "print(y_res[y_res==0].shape[0], y_res[y_res==1].shape[0], y_res[y_res==2].shape[0])\n",
    "\n",
    "print(X_res.shape,y_res.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res2=y_res.copy()\n",
    "# from keras.utils import to_categorical\n",
    "# y_res2 = to_categorical(y_res) \n",
    "# np.unique(y_res2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(X_res,y_res2,random_state=randomseed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2451 36235 104030\n"
     ]
    }
   ],
   "source": [
    "diabetic = mydata[mydata.CLASS==2]\n",
    "prediabetic = mydata[mydata.CLASS==1]\n",
    "normal = mydata[mydata.CLASS==0]\n",
    "\n",
    "print(diabetic.shape[0],prediabetic.shape[0],normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(500,random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(500,random_state=randomseed)\n",
    "normal_test = normal.sample(500,random_state=randomseed)\n",
    "test=pd.concat([diabetic_test,prediabetic_test,normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index).sample(diabetic_train.shape[0],random_state=randomseed)\n",
    "normal_train = normal.drop(normal_test.index).sample(diabetic_train.shape[0],random_state=randomseed)\n",
    "train=pd.concat([diabetic_train,prediabetic_train,normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(random_state=randomseed,n_estimators=100,max_depth=10 )\n",
    "# rf.fit(train.iloc[:,:-1],train.iloc[:,-1])\n",
    "rf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215578839437342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81     20709\n",
      "           1       0.74      0.73      0.73     20827\n",
      "           2       0.94      0.91      0.92     20882\n",
      "\n",
      "    accuracy                           0.82     62418\n",
      "   macro avg       0.82      0.82      0.82     62418\n",
      "weighted avg       0.82      0.82      0.82     62418\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17075</td>\n",
       "      <td>3579</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4370</td>\n",
       "      <td>15210</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1843</td>\n",
       "      <td>18995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2\n",
       "0  17075   3579     55\n",
       "1   4370  15210   1247\n",
       "2     44   1843  18995"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred= rf.predict(xtest)\n",
    "score=rf.score(xtest,ytest)\n",
    "print(score)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(ytest,ypred))\n",
    "\n",
    "confmatrx=pd.DataFrame(confusion_matrix(ytest,ypred))\n",
    "confmatrx.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypred= rf.predict(test.iloc[:,:-1])\n",
    "\n",
    "# score=rf.score(test.iloc[:,:-1],test.iloc[:,-1])\n",
    "# print(score)\n",
    "\n",
    "# feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:,:-1].columns)\n",
    "# feat_importances.nlargest(16).plot(kind='barh')\n",
    "# plt.show()\n",
    "\n",
    "# print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(test.iloc[:,-1],ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy on training set: {:.3f}\".format(rf.score(train.iloc[:,:-1],train.iloc[:,-1])))\n",
    "# print(\"Accuracy on test set: {:.3f}\".format(rf.score(test.iloc[:,:-1],test.iloc[:,-1] ))) \n",
    "# ypred=rf.predict(test.iloc[:,:-1])\n",
    "\n",
    "# confmatrx=pd.DataFrame(confusion_matrix(test.iloc[:,-1],ypred))\n",
    "# confmatrx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import classification_report \n",
    "# print(classification_report(test.iloc[:,-1], ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(input_dim=13,units=128,activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=128, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=model.fit(xtrain, ytrain, validation_split=.2,epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',m.mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(m.mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',m.mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',m.r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=h\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
