{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# this prediction model tires to model the current year feature values with the next year's class value\\n# with out any prediction for the feature values\\n# smotenc added\";\n",
       "                var nbb_formatted_code = \"# this prediction model tires to model the current year feature values with the next year's class value\\n# with out any prediction for the feature values\\n# smotenc added\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this prediction model tires to model the current year feature values with the next year's class value\n",
    "# with out any prediction for the feature values\n",
    "# smotenc added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Read dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"S000300\",\n",
    "        \"AGE\",\n",
    "        \"SEX\",\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 13)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60035, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>S000300</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>20.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>25.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>21.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>24.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  S000300   AGE  SEX  CLASS\n",
       "2      78.0     5.28     20.2  46.0  1.0      0\n",
       "5      90.0     5.74     25.5  52.0  1.0      0\n",
       "10     86.0     5.83     21.2  37.0  1.0      0\n",
       "11     86.0     4.73     22.0  39.0  1.0      0\n",
       "20     87.0     5.60     24.6  59.0  1.0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data = data[[\"L100800\", \"L104600\", \"S000300\", \"AGE\", \"SEX\", \"CLASS\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    40171\n",
       "1    18708\n",
       "2     1156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"CLASS\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156 18708 40171\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0], random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 18508, 1: 18508, 0: 18508})\n",
      "18508 18508 18508\n",
      "(55524, 5) (55524,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[2],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Classifiers\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.Random Forest\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': [10, 50, 100, 150, 200, 300, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "# rf=rf_clf.best_estimator_\n",
    "# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=700,\n",
    "#                        n_jobs=None, oob_score=False, random_state=None,\n",
    "#                        verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.04) [RandomForestClassifier] \n",
      " [[0.62704844 0.73257699 0.74212138 0.76084999 0.77705745 0.76733297\n",
      " 0.75688817 0.75418693 0.78864865 0.76342342]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'S000300', 'AGE', 'SEX'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.792\n",
      "Accuracy on test set: 0.720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  137   63    0\n",
       "1   60  130   10\n",
       "2    1   34  165"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       200\n",
      "           1       0.57      0.65      0.61       200\n",
      "           2       0.94      0.82      0.88       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.74      0.72      0.73       600\n",
      "weighted avg       0.74      0.72      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.XGBoost\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\": [3, 5, 7, 9], \"n_estimators\": [10, 50, 100, 200, 700]}\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = GridSearchCV(xgb_clf, parameters)\n",
    "xgb_clf.fit(xtrain, ytrain)\n",
    "xgb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=7,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7216666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  133   66    1\n",
       "1   53  127   20\n",
       "2    1   26  173"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       200\n",
      "           1       0.58      0.64      0.61       200\n",
      "           2       0.89      0.86      0.88       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.73      0.72      0.72       600\n",
      "weighted avg       0.73      0.72      0.72       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 SVC\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10, 15, 20, 25, 30, 70],\n",
       "                         'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# sorted(SVC_clf2.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=7,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC_clf = SVC_clf2.best_estimator_\n",
    "SVC_clf = SVC(\n",
    "    C=30,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=\"auto_deprecated\",\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>124</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  133   66    1\n",
       "1   51  124   25\n",
       "2    2   20  178"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4Logistic regression\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7266666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  147   49    4\n",
       "1   60  105   35\n",
       "2    3   13  184"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       200\n",
      "           1       0.63      0.53      0.57       200\n",
      "           2       0.83      0.92      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.72      0.73      0.72       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 K-neighbors Classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=150)\n",
    "neigh.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7216666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>117</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  140   59    1\n",
       "1   54  117   29\n",
       "2    3   21  176"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = neigh.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71       200\n",
      "           1       0.59      0.58      0.59       200\n",
      "           2       0.85      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.72      0.72      0.72       600\n",
      "weighted avg       0.72      0.72      0.72       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.StackingClassifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "estimators = [\n",
    "    rf,\n",
    "    xgb_model,\n",
    "    SVC_clf\n",
    "]\n",
    "reg = StackingClassifier(\n",
    "    classifiers=estimators,\n",
    "    meta_classifier=RandomForestClassifier(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.75 (+/- 0.04) [rf]\n",
      "Accuracy: 0.70 (+/- 0.04) [xgb_model]\n",
      "Accuracy: 0.72 (+/- 0.03) [SVC_clf]\n",
      "Accuracy: 0.75 (+/- 0.04) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,reg], \n",
    "                      ['rf',\n",
    "    'xgb_model',\n",
    "    'SVC_clf',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62668828, 0.73041599, 0.74194129, 0.75994958, 0.77579687,\n",
       "       0.76877364, 0.7576085 , 0.75346659, 0.79045045, 0.76432432])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='sqrt',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=700,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random...\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=10,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=42,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.6966666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  141   59    0\n",
       "1   54  140    6\n",
       "2    1   62  137"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       200\n",
      "           1       0.54      0.70      0.61       200\n",
      "           2       0.96      0.69      0.80       200\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.74      0.70      0.71       600\n",
      "weighted avg       0.74      0.70      0.71       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, xtrain, ytrain, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, np_utils.to_categorical( ytrain.to_numpy()), \n",
    "                  epochs=100, batch_size=10,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "\n",
    "tempdata=data5\n",
    "\n",
    "diabetic = tempdata[tempdata.CLASS == 2]\n",
    "prediabetic = tempdata[tempdata.CLASS == 1].sample(diabetic.shape[0],random_state=0)\n",
    "normal = tempdata[tempdata.CLASS == 0].sample(diabetic.shape[0],random_state=0)\n",
    "\n",
    "tempdata5=pd.concat([diabetic,prediabetic,normal])\n",
    "tempdata5.iloc[:, 3:-2]=scaler.transform(tempdata5.iloc[:, 3:-2])\n",
    "\n",
    "pred5 = rf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata5Rcolumns=tempdata5.iloc[:, 3:-2]\n",
    "tempdata5Rcolumns.columns=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n",
    "pred5 = xgb_model.predict((tempdata5Rcolumns))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = SVC_clf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('_DiabeticClassifierModelForNextYear_rf_model', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_DiabeticClassifierModelForNextYear_scaler', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
