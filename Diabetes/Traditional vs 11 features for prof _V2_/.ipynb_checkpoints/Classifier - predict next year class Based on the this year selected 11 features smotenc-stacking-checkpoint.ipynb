{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# this prediction model tires to model the current year feature values with the next year's class value\\n# with out any prediction for the feature values\\n# smotenc added\";\n",
       "                var nbb_formatted_code = \"# this prediction model tires to model the current year feature values with the next year's class value\\n# with out any prediction for the feature values\\n# smotenc added\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this prediction model tires to model the current year feature values with the next year's class value\n",
    "# with out any prediction for the feature values\n",
    "# smotenc added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Read dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = pd.read_csv(\"../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56438, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    38091\n",
       "1    17305\n",
       "2     1042\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"CLASS\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042 17305 38091\n"
     ]
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17105, 1: 17105, 0: 17105})\n",
      "17105 17105 17105\n",
      "(51315, 12) (51315,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[6,7,8,9,10],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Classification\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.Random Forest\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "# rf=rf_clf.best_estimator_\n",
    "# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "#                        n_jobs=None, oob_score=False, random_state=None,\n",
    "#                        verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7283333333333334\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAZMklEQVR4nO3dfbBkdX3n8ffHYRlBAg6CLiJxcB3JAppRRgSjqEQBXRU1qBh3RZfNVFBMBSvWapFIEFPF+rjqKqy1ukpKBWQhzuID4gOJ1oo6IE9DBEZAnciqiKIuiAV894/+XeZwuU995nbfvsz7VdXVp3/nd8759WH6fjnndJ9PqgpJkvp4yFIPQJK0fFlEJEm9WUQkSb1ZRCRJvVlEJEm97bDUAxi3PfbYo1avXr3Uw5CkZeWyyy67tar2nN6+3RWR1atXs3HjxqUehiQtK0l+MFO7p7MkSb1ZRCRJvVlEJEm9bXdF5Op/uZ3Vb/ncUg9Dkh4UtrsiIklaPPMWkST3JLmi81id5NlJLmzzX5vkZ9P67N/6XTPD+j6e5KYkVya5PslZSfaeZwxfbP03JTkzyYrW/vLWdm+SdX13giSpn4UcidxZVWs7j5tn6HPOtD7XzrPON1fVHwL7Ad8FvpZkxzn6v6L1PxDYE3h5a78GeBnwTwt4H5KkRbakp7Nq4H3A/wWeP0e/X7XJHYAdgWrt/1xV1823nSTrk2xMsvGeO25fhJFLkmBhRWSnzmmqC2bp88ppp7N2GnIclwN/MFeHJBcBPwV+DZw3zMqr6iNVta6q1q3YebchhyZJms1CfrF+Z1WtnafPOVV1YrchyTDjmLdzVR2Z5KHAJ4HDgYuH2YAkafFNyrezngz883ydquq3wAbg6JGPSJI0ryUtIhn4C2Av4Iuz9NklyV5tegfgBcD3xjdKSdJsFquITL8m8vTWvl+SLZ3H1Leq3pXkSuB64KnAc6rqd7Os+2HAhiRXAVcyuC5yJkCSlybZAhwKfK5dN5nTE/fejZtP/3f936kk6T6pqqUew1itW7euvIuvJA0nyWVV9YDf403KNRFJ0jI0UXkiSb4FrJzW/B+q6uqlGI8kaW4TVUSq6mlLPQZJ0sJ5OkuS1JtFRJLUm0VEktSbRUSS1NtEXVgfh9mSDf0BoiQNzyMRSVJvyz3Z8LQkV7VtfinJo/vuCEnS8JZ7suG7qupJ7Vb1FwJvW8D7kSQtkuWebPirTreHTbVLksZj2ScbJvm7JD8CXs0sRyLG40rSaAx7Ouuls/SZfjrrziHHsaBkQwa5IysZJBtOtZ9cVfswSDw8cZZljceVpBGYlG9nLUay4aeAP1nkcUmS5rCskw2TrOl0fTEmHkrSWC3Wjw1fmeQZndevB35MSzbstJ/Unt+V5G+AnYFLWViy4UpgBfBVWrIhcHqS/YB7gR8Afz7fQJ+4925s9IeFkrQoTDaUJM3LZENJ0qKbqHtnmWwoScvLRBURkw0laXnxdJYkqTeLiCSpN4uIJKk3i4gkqbeJurA+DrMlG3aZcihJC+ORiCSpt+WebLg2yaVtmxuTHNx3R0iShrfckw3fCZzakg3f1l5LksZkWScbtudd2/RuDG76KEkak4VcWN8pyRVt+qZZgqmm38X30CHHMZVs+NnZOrRkw4OBL7A12fAvgYuSvJtBQXz6LMuuB9YDrNh1zyGHJkmazXJPNjwBOKklG54EfHSWZU02lKQRmJRvZ/VNNjwOOL9Nf4bBkYokaUyWdbIhg2sgz2rThwM3jHbEkqSu5Z5s+GfA+1tx+S3tusdcTDaUpMVjsqEkaV4mG0qSFt1E3TvLZENJWl4mqoiYbChJy4unsyRJvVlEJEm9WUQkSb1ZRCRJvU3UhfVxMNlQkhaPRyKSpN4sIpKk3pZFPG5n2Q3ddSbZPcnFSW5oz6uGefOSpG2zXOJxSfIy4DfTmt8CfKWq1gBfaa8lSWOyLOJxk+wCvAl4x7RZRwOfaNOfAF4yy/Lrk2xMsvGeO27f9oFLkoCFFZGdOqepLpilzyunnc7aachxTMXjzuY04D3AHdPaH1VVtwC050fOtLDJhpI0Ggv5iu+dVbV2nj7nVNWJ3YZk3sTb+3WfdUayFnh8VZ2UZPUwK5UkjdakfDtrrnjcQ4GDktwMfAN4QpJL2ryfdFIP9wJ+OuJxSpI6lvTHhhkcrryROeJxq+oM4IzWfzVwYVU9u83ewCBn/fT2/Nn5tmmyoSQtnsU6Epl+TeTprX2/JFs6j5e39ncluRK4Hngqc8fjzuV04HlJbgCe115LksbEeFxJ0ryMx5UkLbqJugGj8biStLxMVBExHleSlhdPZ0mSerOISJJ6s4hIknqbqGsi47CQZMOZmHYoSQ/kkYgkqbeJKiJJTk6yKclV7ZfvT0tySZLrOr+GP6/1/UCSv5m27IeWbvSStP2ZmNNZSQ4FXgg8paruSrIHMBVU9eqqmv4z878GrkjySaCA/8TgRo6SpDGZmCLC4CaMt1bVXQBVdSvMfkv5qvpVkpOB/9aa3lZVvxzHQCVJA5N0OutLwD4td/3DSZ7VmffJzumsd001VtWngVXArlX197Ot2GRDSRqNiTkSqarfJDkIeCbwHOCcJFOZ6TOdziLJY4B/DVSSXapqegb71Lo/AnwEYOVea7avO05K0ghNTBEBqKp7gEuAS5JczSAjZC7vB/4W+LfAKcCbRzk+SdL9TUwRSbIfcG9V3dCa1gI/AA6cpf/zGWSqnwXsDFyZ5H9W1bXjGK8kaYLyRNqprA8CDwfuBjYD64HzGFx0v7N1vZXBt7iuBI6ZusNvkpcBJ1bV4XNtxzwRSRrebHkiE3MkUlWXAU+fYdazZ1lkv2nLnw+cv8jDkiTNYZK+nSVJWmYsIpKk3iwikqTeLCKSpN4sIpKk3iwikqTeLCKSpN4m5nci49I32XAhTD+UtL3xSESS1NtQRSTJA+6Sm+SwJJcnuTvJMdPmHZfkhvY4rtN+UJKrk2xuCYVp7ed0bvl+c5IrOsu8tfW/LsmRnfajWtvmzl1/JUljsBins34IvBb4q25jkt0Z3Fl3HYPkwcuSbKiqXwBnMLgv1qXA54GjgC9U1Ss7y78HuL1N7w8cCxwAPBr4cpIntK4fAp4HbAG+07bhTRglaQy2+XRWVd1cVVcB906bdSRwcVXd1grHxcBRSfZiECL1zRrc/fEs4CXdBduRySuAT7emo4Gzq+quqrqJwc0ZD26PzVV1Y1X9Dji79ZUkjcEor4nsDfyo83pLa9u7TU9v73om8JPObeHnWtdM7fdjsqEkjcYoi8hM4eg1R3vXq9h6FLKt66KqPlJV66pq3Yqdd5tluJKkYY2yiGwB9um8fgzw49b+mBnaAUiyA/Ay4JwFrmumdknSGIyyiFwEHJFkVZJVwBHARVV1C/DrJIe0ax+vAT7bWe65wPeqqnvKawNwbJKVSfYF1gDfBr4DrEmyb5IdGVx83zDC9yRJ6hj221k7J+n+cX8v8HXgAmAV8KIkp1bVAVV1W5LTGPyhB3h7Vd3Wpk8APg7sBHyhPaYcy/1PZVFVm5KcC1zLIPXwDS2PnSQnMihYK4CPVdWmId+TJKmniYnHHRfjcSVpeLPF4/qLdUlSbxYRSVJvFhFJUm8WEUlSbxYRSVJvFhFJUm8WEUlSbxYRSVJvxuOOidG5kh6MJuZIJMlLk1SSP+i0rUlyYZLvJ7ksydeSHNbmvTbJzzpJiFe08CpJ0phMTBFhcPv3bzC4dxZJHgp8DvhIVf2bqjoIeCPwuM4y51TV2s7DRENJGqOJKCJJdgH+CDieVkSAVwPfrKr77spbVddU1cfHP0JJ0kwm5ZrIS4AvVtX1SW5L8hQGeeqXz7PcK5M8o/P60Kq6c3qnJOsZZLqzYtc9F2vMkrTdm4gjEQanss5u02e31/eT5IIk1yQ5v9M8/XTWAwoImGwoSaOy5EciSR4BHA4cmKQY5IIUcCpw2FS/qnppknXAu5dkoJKkB5iEI5FjgLOq6rFVtbqq9gFuAq4H/ijJizt9d16SEUqSZrTkRyIMTl2dPq3tfwF/CrwQeG+S/wr8BPg18I5Ov+nXRF5fVf9nlIOVJG1lsqEkaV4mG0qSFp1FRJLUm0VEktSbRUSS1JtFRJLUm0VEktSbRUSS1JtFRJLU2yT8Yn2slirZcCamHUpa7oY6EknymxnaDktyeZK7kxwzbd5xSW5oj+M67V9McmWSTUnOTLKite+e5OLW/+Ikq1p7knwgyeYkV7Vbxc+5DUnS6C3G6awfAq8FPtVtTLI7cArwNOBg4JSpogC8oqr+EDgQ2BN4eWt/C/CVqloDfKW9Bng+sKY91gNnLGAbkqQR2+YiUlU3V9VVwL3TZh0JXFxVt1XVL4CLgaPaMr9qfXYAdmRw63eAo4FPtOlPMAirmmo/qwYuBR6eZK+5tiFJGr1RXljfG/hR5/WW1gZAkouAnzK4M+95rflRVXULQHt+5DzrmnMbnW2tT7IxycZ77rh9W96TJKljlEUkM7Tdd8vgqjoS2AtYySCUqs+65txGZ1smG0rSCIyyiGwB9um8fgzw426HqvotsIHB6SqAn7TTVLTnn86zrnm3IUkanVEWkYuAI5Ksahe7jwAuSrJLp1DsALwA+F5bZgMw9Q2r44DPdtpf076ldQhwezvdNeM2RvieJEkdw/5OZOckWzqv3wt8HbgAWAW8KMmpVXVAVd2W5DTgO63v21vbo4ANSVYyyFP/KnBm63M6cG6S4xl862vqW1ufZ1BsNgN3AK8DmG0bQ74nSVJPJhtKkuZlsqEkadFZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvZlsOIFMPJS0XAybbHhySyO8KskVSZ6WZN8k32rJguck2bH1Xdleb27zV3fW89bWfl2SI1vbQ5N8u5N4eGqn/9DbkCSN3oKLSJJDgRcCT6mqJwHPZZDl8V+A97U0wl8Ax7dFjgd+UVWPB97X+pFkf+BY4AAGAVIfbvG4dwGHt8TDtcBR7WaLDLsNSdJ4DHMkshdwa1XdBVBVtwK3MMgCmQqVmp5GOJVSeB7wx0nS2s+uqruq6iYGN1U8uKUWTmW4/6v2qLbMsNuQJI3BMEXkS8A+Sa5P8uEkzwIeAfyyqu5ufbrJgvelDrb5t7f+s6YRJlmR5AoGOSIXV9W3em7jfkw2lKTRWHARaUcJBwHrgZ8B59BuyT69a3seOo2wqu6pqrUMwqUOTnLgXP3nmdcdu8mGkjQCQ11Yb3/kL6mqU4ATgcOAh7dwKbh/suB9qYNt/m7AbSws8fCXwCUMrpnc2mMbkqQxGObC+n5J1nSa1gI/AL4GHNPapqcRTqUUHgN8tQbhJRuAY9s3q/YF1gDfTrJnkoe3be3E4ML999oyw25DkjQGw/xOZBfgg+0P/d0MLoivB3YFzk7yDuC7wEdb/48Cf59kM4Ojg2MBqmpTknOBa9t63lBV97TI3E+0b2o9BDi3qi5s6/rPw2xDkjQeJhtKkuZlsqEkadFZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvZls+CBjKqKkcRo22fA3M7QdluTyJHcnOWbavONaGuENSY7rtP9dkh9NX1+S97XExCvaLed/uYB1HZTk6pZu+AHzRCRpfBbjdNYPgdcCn+o2JtkdOAV4GnAwcEqSVW32/25t91NVJ1XV2nY7+A8C5y9gXWcwuIfXmvY4ahHekyRpAba5iFTVzVV1FXDvtFlHMgiWuq2qfgFcTPsDX1WXVtUt86z6VcCn51pXu2njrlX1zXb33rPYmnooSRqxUV5YnzXBcD5JHgvsC3x1nnXt3aaH3oYkaduNsogsKHVwFscC51XVPfOsa0HbMB5XkkZjlEVk3gTDORzL1lNZc61rS5uecxvG40rSaIyyiFwEHJFkVbsIfkRrm1OS/YBVwDfnW1e7rvLrJIe0b2W9hq2ph5KkERu2iOycZEvn8aYkT02yBXg58N+TbAKoqtuA04DvtMfbWxtJ3tmWmVrf33a28Srg7G7M7VzrAk4A/geDpMXvA18Y8j1Jknoy2VCSNC+TDSVJi84iIknqzSIiSerNIiJJ6s0iIknqzSIiSerNIiJJ6s0iIknqzWRDScuGyZ2TZ0mSDTvzNyS5ZlrbG5Ncl2RTknd22t/a0guvS3Jkp/2o1rY5yVuGeT+SpG2zGEciU8mGf9Vt7KQRrmNwe/bLkmxooVIkeRkwPR73OcDRwJOq6q4kj2zt+zO4s+8BwKOBLyd5QlvsQ8DzGNzR9zttG9cuwvuSJM1jSZINk+wCvAl4x7RlTgBOr6q72rp/2tqPZnBTxruq6iYGN1s8uD02V9WNVfU74OzWV5I0BkuVbHga8B7gjmnLPAF4ZpJvJfnHJE+dZ1290xMlSdtu7MmGSdYCj6+qC2aYvwODLJFDgDcD57acEJMNJWkCLUWy4aHAQUluBr4BPCHJJZ1lzq+BbzM4RbbHHOtaUHqiyYaSNBpjTzasqjOq6tFVtRp4BnB9VT27LfMPwOEA7cL5jsCtwAbg2CQrk+wLrAG+zSCgak2SfZPsyODi+4YRvidJUsew387auSUSTnkv8HXgAganoV6U5NSqOqCqbksylUYI908jnM3HgI+1r/3+DjiuJRxuSnIucC1wN/CGqroHIMmJDArWCuBjVbVpyPckSerJZENJ0rxMNpQkLTqLiCSpN4uIJKk3i4gkqTeLiCSpN4uIJKk3i4gkqTeLiCSpN5MNJWk7MKpUSI9EJEm9LUk8bpKDklzdIm0/0G73TpK1SS5NckW7dfvBrT2t3+YkVyV5ynzbkCSN3mIciUzF436q29iJx30agwTCU9rdfAHOANYzuBvvGlriIfBO4NSqWgu8rb0GeH6n7/q2/HzbkCSN2NjjcZPsBexaVd9sd+g9C3jJ1OqAXdv0bmzNBjkaOKvljFwKPLytZ9YIXknS6I3ywvpckbZbZmgH+EvgoiTvZlDgnr6Adc0bj5tkPYMjGFbsume/dyNJeoCxx+PO0Q5wAnBSVe0DnAR8dBvWtbXBZENJGomliMfd0qantwMcB5zfpj/D4DrHfOuaNx5XkjQaSxGPewvw6ySHtG9lvQb4bFvmx8Cz2vThwA1tegPwmvYtrUOA29t6ZtzGCN+TJKljqeJxTwA+DuwEfKE9AP4MeH+SHYDf0q5jAJ8HXgBsBu4AXgfQJ4L3iXvvxsYR/ehGkrY3xuNKkuZlPK4kadFZRCRJvVlEJEm9bXfXRJL8Grhuqccxiz2AW5d6ELOY5LHBZI/PsfXj2PoZ1dgeW1UP+LX2dncreOC6mS4OTYIkGx1bP5M8PsfWj2PrZ9xj83SWJKk3i4gkqbftsYh8ZKkHMAfH1t8kj8+x9ePY+hnr2La7C+uSpMWzPR6JSJIWiUVEktTbg6qIJDkqyXUti/0tM8xfmeScNv9bSVZ35r21tV+X5MhJGVuS1UnubLnzVyQ5cwnGdliSy5PcneSYafNGmnG/jWO7p7PfNizB2N6U5NokVyX5SpLHduYt9X6ba2wj3W8LHN+fJ7m6jeEbSfbvzFvqz+qMY5uEz2qn3zFJKsm6Ttto9ltVPSgewArg+8DjgB2BK4H9p/V5PXBmmz4WOKdN79/6rwT2betZMSFjWw1cs8T7bTXwJAZRxsd02ncHbmzPq9r0qkkYW5v3myXeb88Bdm7TJ3T+m07CfptxbKPeb0OMb9fO9IuBL7bpSfiszja2Jf+stn6/B/wTcCmwbtT77cF0JHIwsLmqbqyq3wFnM8hm7zoa+ESbPg/44yRp7WdX1V1VdRODW84fzOLZlrGN2rxjq6qbq+oq4N5py446435bxjZqCxnb16rqjvbyUraGsU3CfpttbOOwkPH9qvPyYWxNLF3yz+ocYxu1hfwdATgNeCeDOI0pI9tvD6YispC89fv6VNXdwO3AIxa47FKNDWDfJN9N8o9JnrmI41ro2Eax7DjW/9AkG5NcmuQlizguGH5sx7M1N2fS9lt3bDDa/bbg8SV5Q5LvM/iD+BfDLLtEY4Ml/qwmeTKwT1VdOOyyfT2YbnuykLz1bcpq3wbbMrZbgN+vqp8nOQj4hyQHTPu/oVGPbRTLjmP9v19VP07yOOCrSa6uqu+Pe2xJ/j2wjq2pnROz32YYG4x2vy14fFX1IeBDSf4U+GsG8dkTse9mGduSflaTPAR4H/DaYZfdFg+mI5GF5K3f1yeD9MTdgNsWuOySjK0dfv4coKouY3Au8wljHtsolh35+qvqx+35RuAS4MnjHluS5wInAy+uqruGWXaJxjbq/bbg8XWcDUwdEU3EvptpbBPwWf094EDgkiQ3A4cAG9rF9dHtt1FdBBr3g8FR1Y0MLhpNXXQ6YFqfN3D/i9fntukDuP9FpxtZ3It12zK2PafGwuCC2r8Au49zbJ2+H+eBF9ZvYnBxeFWbnpSxrQJWtuk9gBuY4SLkiP+bPpnBH5I109qXfL/NMbaR7rchxremM/0iYGObnoTP6mxjm5jPaut/CVsvrI9svy3aP4xJeDDIYb++fThObm1vZ/B/WgAPBT7D4KLSt4HHdZY9uS13HfD8SRkb8CfApvYP4HLgRUswtqcy+D+Z/wf8HNjUWfY/tjFvBl43KWMDng5c3fbb1cDxSzC2LwM/Aa5ojw0TtN9mHNs49tsCx/f+9u/+CuBrdP5YTsBndcaxTcJndVrfS2hFZJT7zdueSJJ6ezBdE5EkjZlFRJLUm0VEktSbRUSS1JtFRJLUm0VEktSbRUSS1Nv/B5lfJHoeDiTNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'L101700', 'S000300', 'L103000', 'AGE', 'L100700',\n",
      "       'SEX', 'FIELD_40', 'FIELD_38', 'FIELD_33', 'FIELD_31'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.811\n",
      "Accuracy on test set: 0.728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>141</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  149   51    0\n",
       "1   48  141   11\n",
       "2    3   50  147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.58      0.70      0.64       200\n",
      "           2       0.93      0.73      0.82       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.75      0.73      0.73       600\n",
      "weighted avg       0.75      0.73      0.73       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.XGBoost\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[3,5,7,9],\n",
    "              'n_estimators':[10,50,100,200,700]}\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = GridSearchCV(xgb_clf, parameters)\n",
    "xgb_clf.fit(xtrain, ytrain)\n",
    "xgb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "# objective=\"multi:softmax\"\n",
    "# objective=\"binary:logistic\"\n",
    "# xgb_model=xgb_clf.best_estimator_\n",
    "\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  149   51    0\n",
       "1   49  134   17\n",
       "2    3   36  161"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.61      0.67      0.64       200\n",
      "           2       0.90      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 SVC\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# sorted(SVC_clf2.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# SVC_clf = SVC_clf2.best_estimator_\n",
    "SVC_clf=SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=randomseed,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7466666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  150   49    1\n",
       "1   49  134   17\n",
       "2    3   33  164"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       200\n",
      "           1       0.62      0.67      0.64       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4Logistic regression\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>104</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  158   41    1\n",
       "1   68  104   28\n",
       "2    3   24  173"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       200\n",
      "           1       0.62      0.52      0.56       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.72      0.72      0.72       600\n",
      "weighted avg       0.72      0.72      0.72       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 K-neighbors Classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=150)\n",
    "neigh.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.6366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>112</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  131   58   11\n",
       "1   61  112   27\n",
       "2    5   56  139"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = neigh.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       200\n",
      "           1       0.50      0.56      0.53       200\n",
      "           2       0.79      0.69      0.74       200\n",
      "\n",
      "    accuracy                           0.64       600\n",
      "   macro avg       0.65      0.64      0.64       600\n",
      "weighted avg       0.65      0.64      0.64       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.StackingClassifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "estimators = [\n",
    "    rf,\n",
    "    xgb_model,\n",
    "    SVC_clf\n",
    "]\n",
    "reg = StackingClassifier(\n",
    "    classifiers=estimators,\n",
    "    meta_classifier=RandomForestClassifier(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([rf,\n",
    "    xgb_model,\n",
    "    SVC_clf,reg], \n",
    "                      ['rf',\n",
    "    'xgb_model',\n",
    "    'SVC_clf',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, xtrain, ytrain, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, np_utils.to_categorical( ytrain.to_numpy()), \n",
    "                  epochs=100, batch_size=10,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "\n",
    "tempdata=data5\n",
    "\n",
    "diabetic = tempdata[tempdata.CLASS == 2]\n",
    "prediabetic = tempdata[tempdata.CLASS == 1].sample(diabetic.shape[0],random_state=0)\n",
    "normal = tempdata[tempdata.CLASS == 0].sample(diabetic.shape[0],random_state=0)\n",
    "\n",
    "tempdata5=pd.concat([diabetic,prediabetic,normal])\n",
    "tempdata5.iloc[:, 3:-2]=scaler.transform(tempdata5.iloc[:, 3:-2])\n",
    "\n",
    "pred5 = rf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata5Rcolumns=tempdata5.iloc[:, 3:-2]\n",
    "tempdata5Rcolumns.columns=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n",
    "pred5 = xgb_model.predict((tempdata5Rcolumns))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = SVC_clf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('_DiabeticClassifierModelForNextYear_rf_model', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_DiabeticClassifierModelForNextYear_scaler', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
