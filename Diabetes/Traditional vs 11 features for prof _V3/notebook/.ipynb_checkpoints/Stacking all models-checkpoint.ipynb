{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 19)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"x_original = pd.read_csv(\\\"../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_formatted_code = \"x_original = pd.read_csv(\\\"../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original = pd.read_csv(\"../dataset/XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"y_original = pd.read_csv(\\\"../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_formatted_code = \"y_original = pd.read_csv(\\\"../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_original = pd.read_csv(\"../dataset/TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\";\n",
       "                var nbb_formatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56542, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"data = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downsample the majority class and upsample the minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 17331 38166\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_formatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_formatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_formatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17131, 1: 17131, 0: 17131})\n",
      "17131 17131 17131\n",
      "(51393, 12) (51393,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "randomseed = 42\n",
    "\n",
    "sm = SMOTENC(\n",
    "    random_state=randomseed,\n",
    "    categorical_features=[6, 7, 8, 9, 10],\n",
    "    sampling_strategy=\"minority\",\n",
    ")\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate the classifier models based on the selected  features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\n\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_formatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\n\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "\n",
    "weakmodles = []\n",
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=1,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=False,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=False,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nweakmodles.append(rf_model_12)\\nweakmodles.append(xgb_model_12)\\nweakmodles.append(scv_model_12)\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_formatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=1,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=False,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=False,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nweakmodles.append(rf_model_12)\\nweakmodles.append(xgb_model_12)\\nweakmodles.append(scv_model_12)\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_12 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=\"log2\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=1,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_12 = svmgpu(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_12 = SVC(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "weakmodles.append(rf_model_12)\n",
    "weakmodles.append(xgb_model_12)\n",
    "weakmodles.append(scv_model_12)\n",
    "\n",
    "estimators.append((\"rf_model_12\", rf_model_12))\n",
    "estimators.append((\"xgb_model_12\", xgb_model_12))\n",
    "estimators.append((\"scv_model_12\", scv_model_cpu_12))\n",
    "\n",
    "# estimators = [\n",
    "#     (\"rf_model_12\", rf_model_12),\n",
    "#     (\"xgb_model_12\", xgb_model_12),\n",
    "#     (\"scv_model_12\", scv_model_12),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nweakmodles.append(rf_model_5)\\nweakmodles.append(xgb_model_5)\\nweakmodles.append(scv_model_5)\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_formatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nweakmodles.append(rf_model_5)\\nweakmodles.append(xgb_model_5)\\nweakmodles.append(scv_model_5)\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "xgb_model_5 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_5 = svmgpu(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "scv_model_cpu_5 = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "weakmodles.append(rf_model_5)\n",
    "weakmodles.append(xgb_model_5)\n",
    "weakmodles.append(scv_model_5)\n",
    "\n",
    "estimators.append((\"rf_model_5\", rf_model_5))\n",
    "estimators.append((\"xgb_model_5\", xgb_model_5))\n",
    "estimators.append((\"scv_model_5\", scv_model_cpu_5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-f4dc9eca7c8d>, line 112)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-f4dc9eca7c8d>\"\u001b[1;36m, line \u001b[1;32m112\u001b[0m\n\u001b[1;33m    \"rf_model_10\"str(i),\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot parse: 112:29:                 \"rf_model_10\"str(i),\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lab_black.py\", line 218, in format_cell\n",
      "    formatted_code = _format_code(cell)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lab_black.py\", line 29, in _format_code\n",
      "    return format_str(src_contents=code, mode=FileMode())\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\black.py\", line 669, in format_str\n",
      "    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\black.py\", line 758, in lib2to3_parse\n",
      "    raise exc from None\n",
      "black.InvalidInput: Cannot parse: 112:29:                 \"rf_model_10\"str(i),\n"
     ]
    }
   ],
   "source": [
    "top10colscomb = [\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_10 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_10 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=42,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_10 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_10 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_10\"str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_10\"str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_10\"str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. 9 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcols9comb = [\n",
    "    (0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
    "    (0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_9 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_9 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_9 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_9 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_9\"+str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_9\"+str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_9\"+str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top8colscomb = [\n",
    "    (0, 1, 2, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_8 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_8 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_8 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_8 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_8\",\n",
    "                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_8\",\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_8\",\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top7colscomb = [\n",
    "    (0, 1, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 10, 11),\n",
    "    (0, 1, 3, 6, 8, 10, 11),\n",
    "    (0, 1, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 6, 7, 8, 9, 10),\n",
    "    (0, 1, 2, 3, 8, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "\n",
    "rf_model_7 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_7 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_7 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_7 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_7\",\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_7\",\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_7\",\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top6colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_6 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_6 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_6 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_6 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_6\",\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_6\",\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_6\",\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8. 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "\n",
    "rf_model_5_2 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_5_2 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_5_2 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=False,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_5_2 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    # max_mem_size=-1,   n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_52\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weakmodles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "a = [\n",
    "    \"rf_model_5\",\n",
    "    \"xgb_model_5\",\n",
    "    \"scv_model_5\",\n",
    "    \n",
    "    \"rf_model_5_2\",\n",
    "    \"xgb_model_5_2\",\n",
    "    \"scv_model_cpu_5_2\",\n",
    "    \n",
    "    \"rf_model_5_2\",\n",
    "    \"xgb_model_5_2\",\n",
    "    \"scv_model_cpu_5_2\",\n",
    "    \"rf_model_5_2\",\n",
    "    \"xgb_model_5_2\",\n",
    "    \"scv_model_cpu_5_2\",\n",
    "    \"rf_model_5_2\",\n",
    "    \"xgb_model_5_2\",\n",
    "    \"scv_model_cpu_5_2\",\n",
    "    \"rf_model_5_2\",\n",
    "    \"xgb_model_5_2\",\n",
    "    \"scv_model_cpu_5_2\",\n",
    "]\n",
    "[len(list(group)) for key, group in groupby(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf = StackingClassifier(classifiers=weakmodles,verbose=2,\n",
    "                           meta_classifier=RandomForestClassifier(n_estimators=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sclf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = sclf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the performance of each model of the sclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sclf.clfs_)):\n",
    "#     ypred = sclf.clfs_[i].predict((xtest))\n",
    "#     print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stackedmodels = sclf.clfs_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Votting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingclf = VotingClassifier(estimators=estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "votingclf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ypred = votingclf.predict(xtest.astype(float))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stackedmodels = votingclf.estimators_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6  Generate Votting Classifer soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scv_model_cpu_withProb = SVC(\n",
    "  C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "#     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "#     max_mem_size=-1,\n",
    "#     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingclf2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rf_model\", rf_model),\n",
    "        (\"xgb_model\", xgb_model),\n",
    "        (\"scv_model\", scv_model_cpu_withProb),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingclf2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = votingclf2.predict(xtest.astype(float))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedmodels = votingclf2.estimators_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
