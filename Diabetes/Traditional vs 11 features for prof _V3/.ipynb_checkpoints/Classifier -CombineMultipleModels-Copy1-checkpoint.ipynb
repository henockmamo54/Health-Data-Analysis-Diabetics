{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# this prediction model tires to model the current year feature values with the next year's class value\\n# with out any prediction for the feature values\\n# smotenc added\";\n",
       "                var nbb_formatted_code = \"# this prediction model tires to model the current year feature values with the next year's class value\\n# with out any prediction for the feature values\\n# smotenc added\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this prediction model tires to model the current year feature values with the next year's class value\n",
    "# with out any prediction for the feature values\n",
    "# smotenc added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport warnings\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\n\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\nrandomseed = 7\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport warnings\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\n\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\nrandomseed = 7\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Read dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"x_original = pd.read_csv(\\\"../../XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\";\n",
       "                var nbb_formatted_code = \"x_original = pd.read_csv(\\\"../../XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original = pd.read_csv(\"../../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"y_original = pd.read_csv(\\\"../../TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\";\n",
       "                var nbb_formatted_code = \"y_original = pd.read_csv(\\\"../../TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_original = pd.read_csv(\"../../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\n\\nprint(data.shape)\";\n",
       "                var nbb_formatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\n\\nprint(data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56438, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"data = data.dropna()\\nprint(data.shape)\\ndata = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = data.dropna()\\nprint(data.shape)\\ndata = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    38091\n",
       "1    17305\n",
       "2     1042\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"data.groupby(by=\\\"CLASS\\\").size()\";\n",
       "                var nbb_formatted_code = \"data.groupby(by=\\\"CLASS\\\").size()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.groupby(by=\"CLASS\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042 17305 38091\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_formatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_formatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_formatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler \\nscaler = MinMaxScaler()\\nxtrain=scaler.fit_transform(xtrain)\\nxtest=scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17105, 1: 17105, 0: 17105})\n",
      "17105 17105 17105\n",
      "(51315, 12) (51315,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\nrandomseed=42\\n\\nsm = SMOTENC(random_state=randomseed,categorical_features=[6,7,8,9,10],sampling_strategy='minority')\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "randomseed=42\n",
    "\n",
    "sm = SMOTENC(random_state=randomseed,categorical_features=[6,7,8,9,10],sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Classification Models\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 models from the 12 features\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"rf_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"rf_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_12 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"xgb_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\";\n",
       "                var nbb_formatted_code = \"xgb_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"SVC_12 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_formatted_code = \"SVC_12 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVC_12 = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=\"auto_deprecated\",\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"lr_12 = LogisticRegression(random_state=0)\";\n",
       "                var nbb_formatted_code = \"lr_12 = LogisticRegression(random_state=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_12 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"kneigh_12 = KNeighborsClassifier(n_neighbors=150)\";\n",
       "                var nbb_formatted_code = \"kneigh_12 = KNeighborsClassifier(n_neighbors=150)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kneigh_12 = KNeighborsClassifier(n_neighbors=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 models from the tradional 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"rf_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\nrf_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), rf_5)\";\n",
       "                var nbb_formatted_code = \"rf_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\nrf_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), rf_5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "rf_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), rf_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"xgb_5 = xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed)\\nxgb_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), xgb_5)\";\n",
       "                var nbb_formatted_code = \"xgb_5 = xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed)\\nxgb_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), xgb_5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_5 = xgb.XGBClassifier(objective=\"multi:soft\", random_state=randomseed)\n",
    "xgb_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), xgb_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"SVC_5 = SVC(\\n    C=30,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\nSVC_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), SVC_5)\";\n",
       "                var nbb_formatted_code = \"SVC_5 = SVC(\\n    C=30,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\nSVC_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), SVC_5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVC_5 = SVC(\n",
    "    C=30,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=\"auto_deprecated\",\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "SVC_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), SVC_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"lr_5 = LogisticRegression(random_state=0)\\nlr_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), lr_5)\";\n",
       "                var nbb_formatted_code = \"lr_5 = LogisticRegression(random_state=0)\\nlr_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), lr_5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_5 = LogisticRegression(random_state=0)\n",
    "lr_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), lr_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"kneigh_5 = KNeighborsClassifier(n_neighbors=150)\\nkneigh_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), kneigh_5)\";\n",
       "                var nbb_formatted_code = \"kneigh_5 = KNeighborsClassifier(n_neighbors=150)\\nkneigh_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), kneigh_5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kneigh_5 = KNeighborsClassifier(n_neighbors=150)\n",
    "kneigh_5 = make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), kneigh_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stacking Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 classifiers...\n",
      "Fitting classifier1: pipeline (1/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier2: pipeline (2/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier3: pipeline (3/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=False, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier4: pipeline (4/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier5: pipeline (5/10)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 10, 11), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier6: randomforestclassifier (6/10)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier7: xgbclassifier (7/10)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier8: svc (8/10)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=42,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier9: logisticregression (9/10)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier10: kneighborsclassifier (10/10)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[Pipeline(memory=None,\n",
       "                                         steps=[('columnselector',\n",
       "                                                 ColumnSelector(cols=(0, 1, 3,\n",
       "                                                                      10, 11),\n",
       "                                                                drop_axis=False)),\n",
       "                                                ('randomforestclassifier',\n",
       "                                                 RandomForestClassifier(bootstrap=True,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=12,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=No...\n",
       "                                                 learning_rate=0.1,\n",
       "                                                 max_delta_step=0, max_depth=3,\n",
       "                                                 min_child_weight=1,\n",
       "                                                 missing=None,\n",
       "                                                 n_estimators=2000, n_jobs=1,\n",
       "                                                 nthread=None,\n",
       "                                                 objective='multi:soft',\n",
       "                                                 random_state=42, reg_alpha=0,\n",
       "                                                 reg_lambda=1,\n",
       "                                                 scale_pos_weight=1, seed=None,\n",
       "                                                 silent=None, subsample=1,\n",
       "                                                 verbosity=1),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"estimators = [rf_5, xgb_5, SVC_5, lr_5, kneigh_5,\\n             rf_12, xgb_12, SVC_12, lr_12, kneigh_12,]\\n\\nstcl = StackingClassifier(\\n    classifiers=estimators,verbose=2,\\n    meta_classifier=xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed,n_estimators=2000)\\n    #LogisticRegression(random_state=0)\\n    #xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed,n_estimators=2000)\\n    #RandomForestClassifier(n_estimators=100, random_state=42),\\n)\\n\\nstcl.fit(xtrain,ytrain)\";\n",
       "                var nbb_formatted_code = \"estimators = [\\n    rf_5,\\n    xgb_5,\\n    SVC_5,\\n    lr_5,\\n    kneigh_5,\\n    rf_12,\\n    xgb_12,\\n    SVC_12,\\n    lr_12,\\n    kneigh_12,\\n]\\n\\nstcl = StackingClassifier(\\n    classifiers=estimators,\\n    verbose=2,\\n    meta_classifier=xgb.XGBClassifier(\\n        objective=\\\"multi:soft\\\", random_state=randomseed, n_estimators=2000\\n    )\\n    # LogisticRegression(random_state=0)\\n    # xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed,n_estimators=2000)\\n    # RandomForestClassifier(n_estimators=100, random_state=42),\\n)\\n\\nstcl.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators = [rf_5, xgb_5, SVC_5, lr_5, kneigh_5,\n",
    "             rf_12, xgb_12, SVC_12, lr_12, kneigh_12,]\n",
    "\n",
    "stcl = StackingClassifier(\n",
    "    classifiers=estimators,verbose=2,\n",
    "    meta_classifier=xgb.XGBClassifier(objective=\"multi:soft\", random_state=randomseed,n_estimators=2000)\n",
    "    #LogisticRegression(random_state=0)\n",
    "    #xgb.XGBClassifier(objective=\"multi:soft\", random_state=randomseed,n_estimators=2000)\n",
    "    #RandomForestClassifier(n_estimators=100, random_state=42),\n",
    ")\n",
    "\n",
    "stcl.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>140</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   52    0\n",
       "1   49  140   11\n",
       "2    3   53  144"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"y_pred = stcl.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = stcl.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stcl.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.57      0.70      0.63       200\n",
      "           2       0.93      0.72      0.81       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.75      0.72      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75       200\n",
      "           1       0.59      0.69      0.63       200\n",
      "           2       0.92      0.73      0.82       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.75      0.73      0.73       600\n",
      "weighted avg       0.75      0.73      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"accuracy = []\\nfor i in range(len(stcl.clfs_)):\\n    model = stcl.clfs_[i]\\n    y_pred = model.predict((xtest))\\n    accuracy.append(m.accuracy_score(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"accuracy = []\\nfor i in range(len(stcl.clfs_)):\\n    model = stcl.clfs_[i]\\n    y_pred = model.predict((xtest))\\n    accuracy.append(m.accuracy_score(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for i in range(len(stcl.clfs_)):\n",
    "    model = stcl.clfs_[i]\n",
    "    y_pred = model.predict((xtest))\n",
    "    accuracy.append(m.accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7233333333333334,\n",
       " 0.745,\n",
       " 0.745,\n",
       " 0.7133333333333334,\n",
       " 0.7383333333333333,\n",
       " 0.7283333333333334,\n",
       " 0.74,\n",
       " 0.7466666666666667,\n",
       " 0.725,\n",
       " 0.6366666666666667]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"accuracy\";\n",
       "                var nbb_formatted_code = \"accuracy\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Votting classifer integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"estimators = [\\n    (\\\"rf_5\\\", rf_5),\\n    (\\\"xgb_5\\\", xgb_5),\\n    (\\\"SVC_5\\\", SVC_5),\\n    (\\\"lr_5\\\", lr_5),\\n    (\\\"kneigh_5\\\", kneigh_5),\\n    (\\\"rf_12\\\", rf_12),\\n    (\\\"xgb_12\\\", xgb_12),\\n    (\\\"SVC_12\\\", SVC_12),\\n    (\\\"lr_12\\\", lr_12),\\n    (\\\"kneigh_12\\\", kneigh_12),\\n]\";\n",
       "                var nbb_formatted_code = \"estimators = [\\n    (\\\"rf_5\\\", rf_5),\\n    (\\\"xgb_5\\\", xgb_5),\\n    (\\\"SVC_5\\\", SVC_5),\\n    (\\\"lr_5\\\", lr_5),\\n    (\\\"kneigh_5\\\", kneigh_5),\\n    (\\\"rf_12\\\", rf_12),\\n    (\\\"xgb_12\\\", xgb_12),\\n    (\\\"SVC_12\\\", SVC_12),\\n    (\\\"lr_12\\\", lr_12),\\n    (\\\"kneigh_12\\\", kneigh_12),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators = [\n",
    "    (\"rf_5\", rf_5),\n",
    "    (\"xgb_5\", xgb_5),\n",
    "    (\"SVC_5\", SVC_5),\n",
    "    (\"lr_5\", lr_5),\n",
    "    (\"kneigh_5\", kneigh_5),\n",
    "    (\"rf_12\", rf_12),\n",
    "    (\"xgb_12\", xgb_12),\n",
    "    (\"SVC_12\", SVC_12),\n",
    "    (\"lr_12\", lr_12),\n",
    "    (\"kneigh_12\", kneigh_12),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7516666666666667\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"eclf = VotingClassifier(\\n    estimators=[\\n        (\\\"rf_5\\\", rf_5),\\n        (\\\"xgb_5\\\", xgb_5),\\n        (\\\"SVC_5\\\", SVC_5),\\n        (\\\"lr_5\\\", lr_5),\\n        (\\\"kneigh_5\\\", kneigh_5),\\n        (\\\"rf_12\\\", rf_12),\\n        (\\\"xgb_12\\\", xgb_12),\\n        (\\\"SVC_12\\\", SVC_12),\\n        (\\\"lr_12\\\", lr_12),\\n        (\\\"kneigh_12\\\", kneigh_12),\\n    ],\\n    voting=\\\"soft\\\",\\n    # n_jobs=-1,\\n)\\neclf.fit(xtrain, ytrain)\\ny_pred = eclf.predict(xtest)\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"eclf = VotingClassifier(\\n    estimators=[\\n        (\\\"rf_5\\\", rf_5),\\n        (\\\"xgb_5\\\", xgb_5),\\n        (\\\"SVC_5\\\", SVC_5),\\n        (\\\"lr_5\\\", lr_5),\\n        (\\\"kneigh_5\\\", kneigh_5),\\n        (\\\"rf_12\\\", rf_12),\\n        (\\\"xgb_12\\\", xgb_12),\\n        (\\\"SVC_12\\\", SVC_12),\\n        (\\\"lr_12\\\", lr_12),\\n        (\\\"kneigh_12\\\", kneigh_12),\\n    ],\\n    voting=\\\"soft\\\",\\n    # n_jobs=-1,\\n)\\neclf.fit(xtrain, ytrain)\\ny_pred = eclf.predict(xtest)\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eclf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"rf_5\", rf_5),\n",
    "        (\"xgb_5\", xgb_5),\n",
    "        (\"SVC_5\", SVC_5),\n",
    "        (\"lr_5\", lr_5),\n",
    "        (\"kneigh_5\", kneigh_5),\n",
    "        (\"rf_12\", rf_12),\n",
    "        (\"xgb_12\", xgb_12),\n",
    "        (\"SVC_12\", SVC_12),\n",
    "        (\"lr_12\", lr_12),\n",
    "        (\"kneigh_12\", kneigh_12),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    # n_jobs=-1,\n",
    ")\n",
    "eclf.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7516666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>135</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  152   48    0\n",
       "1   49  135   16\n",
       "2    3   33  164"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 142;\n",
       "                var nbb_unformatted_code = \"y_pred = eclf.predict(xtest)\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\n\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = eclf.predict(xtest)\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\n\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = eclf.predict(xtest)\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       200\n",
      "           1       0.62      0.68      0.65       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.76      0.75      0.75       600\n",
      "weighted avg       0.76      0.75      0.75       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 143;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. generate weak classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"cols_range = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\";\n",
       "                var nbb_formatted_code = \"cols_range = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_range = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "    (0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
    "    (0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 10, 11),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# base estimators for the weak models\";\n",
       "                var nbb_formatted_code = \"# base estimators for the weak models\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# base estimators for the weak models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"rf_base = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"rf_base = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_base = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"xgb_base = xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed)\";\n",
       "                var nbb_formatted_code = \"xgb_base = xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_base = xgb.XGBClassifier(objective=\"multi:soft\", random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"SVC_base = SVC(\\n    C=30,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_formatted_code = \"SVC_base = SVC(\\n    C=30,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVC_base = SVC(\n",
    "    C=30,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=\"auto_deprecated\",\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"lr_base = LogisticRegression(random_state=0)\";\n",
       "                var nbb_formatted_code = \"lr_base = LogisticRegression(random_state=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_base = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"kneigh_base = KNeighborsClassifier(n_neighbors=150)\";\n",
       "                var nbb_formatted_code = \"kneigh_base = KNeighborsClassifier(n_neighbors=150)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kneigh_base = KNeighborsClassifier(n_neighbors=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# np.array(estimators).shape\";\n",
       "                var nbb_formatted_code = \"# np.array(estimators).shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# np.array(estimators).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"# generate the weak models\\nweakmodles2 = []\\nestimators2 = []\\n\\nfor i in range(len(cols_range)):\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), rf_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), xgb_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), SVC_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), lr_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), kneigh_base))\\n\\n    estimators2.append(\\n        (\\n            (\\\"rf_base\\\" + str(i)),\\n            make_pipeline(ColumnSelector(cols=cols_range[i]), rf_base),\\n        )\\n    )\\n\\n    estimators2.append(\\n        (\\n            \\\"xgb_base\\\" + str(i),\\n            make_pipeline(ColumnSelector(cols=cols_range[i]), xgb_base),\\n        )\\n    )\\n\\n    estimators2.append(\\n        (\\n            \\\"SVC_base\\\" + str(i),\\n            make_pipeline(ColumnSelector(cols=cols_range[i]), SVC_base),\\n        )\\n    )\\n#     estimators2.append(\\n#         (\\\"lr_base\\\" + str(i), make_pipeline(ColumnSelector(cols=cols_range[i]), lr_base))\\n#     )\\n#     estimators2.append(\\n#         (\\n#             \\\"kneigh_base\\\" + str(i),\\n#             make_pipeline(ColumnSelector(cols=cols_range[i]), kneigh_base),\\n#         )\\n#     )\";\n",
       "                var nbb_formatted_code = \"# generate the weak models\\nweakmodles2 = []\\nestimators2 = []\\n\\nfor i in range(len(cols_range)):\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), rf_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), xgb_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), SVC_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), lr_base))\\n    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), kneigh_base))\\n\\n    estimators2.append(\\n        (\\n            (\\\"rf_base\\\" + str(i)),\\n            make_pipeline(ColumnSelector(cols=cols_range[i]), rf_base),\\n        )\\n    )\\n\\n    estimators2.append(\\n        (\\n            \\\"xgb_base\\\" + str(i),\\n            make_pipeline(ColumnSelector(cols=cols_range[i]), xgb_base),\\n        )\\n    )\\n\\n    estimators2.append(\\n        (\\n            \\\"SVC_base\\\" + str(i),\\n            make_pipeline(ColumnSelector(cols=cols_range[i]), SVC_base),\\n        )\\n    )\\n#     estimators2.append(\\n#         (\\\"lr_base\\\" + str(i), make_pipeline(ColumnSelector(cols=cols_range[i]), lr_base))\\n#     )\\n#     estimators2.append(\\n#         (\\n#             \\\"kneigh_base\\\" + str(i),\\n#             make_pipeline(ColumnSelector(cols=cols_range[i]), kneigh_base),\\n#         )\\n#     )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the weak models\n",
    "weakmodles2 = []\n",
    "estimators2 = []\n",
    "\n",
    "for i in range(len(cols_range)):\n",
    "    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), rf_base))\n",
    "    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), xgb_base))\n",
    "    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), SVC_base))\n",
    "    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), lr_base))\n",
    "    weakmodles2.append(make_pipeline(ColumnSelector(cols=cols_range[i]), kneigh_base))\n",
    "\n",
    "    estimators2.append(\n",
    "        (\n",
    "            (\"rf_base\" + str(i)),\n",
    "            make_pipeline(ColumnSelector(cols=cols_range[i]), rf_base),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    estimators2.append(\n",
    "        (\n",
    "            \"xgb_base\" + str(i),\n",
    "            make_pipeline(ColumnSelector(cols=cols_range[i]), xgb_base),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    estimators2.append(\n",
    "        (\n",
    "            \"SVC_base\" + str(i),\n",
    "            make_pipeline(ColumnSelector(cols=cols_range[i]), SVC_base),\n",
    "        )\n",
    "    )\n",
    "#     estimators2.append(\n",
    "#         (\"lr_base\" + str(i), make_pipeline(ColumnSelector(cols=cols_range[i]), lr_base))\n",
    "#     )\n",
    "#     estimators2.append(\n",
    "#         (\n",
    "#             \"kneigh_base\" + str(i),\n",
    "#             make_pipeline(ColumnSelector(cols=cols_range[i]), kneigh_base),\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"estimators2 = np.concatenate([estimators, estimators2])\\nprint(estimators2.shape)\";\n",
       "                var nbb_formatted_code = \"estimators2 = np.concatenate([estimators, estimators2])\\nprint(estimators2.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators2 = np.concatenate([estimators, estimators2])\n",
    "print(estimators2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"len(estimators2)\";\n",
       "                var nbb_formatted_code = \"len(estimators2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(estimators2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(estimators=estimators2, voting=\"soft\"\n",
    "                         #, n_jobs=-1\n",
    "                        )\n",
    "eclf2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = eclf2.predict(xtest)\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       200\n",
      "           1       0.62      0.67      0.64       200\n",
      "           2       0.92      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.76      0.75      0.75       600\n",
      "weighted avg       0.76      0.75      0.75       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 168;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"weakmodles1 = []\\n\\n\\nweakmodles1.append(rf_12)\\nweakmodles1.append(xgb_12)\\nweakmodles1.append(SVC_12)\\nweakmodles1.append(lr_12)\\nweakmodles1.append(kneigh_12)\\n\\n\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), rf_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), xgb_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), SVC_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), lr_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), kneigh_5))\";\n",
       "                var nbb_formatted_code = \"weakmodles1 = []\\n\\n\\nweakmodles1.append(rf_12)\\nweakmodles1.append(xgb_12)\\nweakmodles1.append(SVC_12)\\nweakmodles1.append(lr_12)\\nweakmodles1.append(kneigh_12)\\n\\n\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), rf_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), xgb_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), SVC_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), lr_5))\\nweakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), kneigh_5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles1 = []\n",
    "\n",
    "weakmodles1.append(rf_12)\n",
    "weakmodles1.append(xgb_12)\n",
    "weakmodles1.append(SVC_12)\n",
    "weakmodles1.append(lr_12)\n",
    "weakmodles1.append(kneigh_12)\n",
    "\n",
    "\n",
    "weakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), rf_5))\n",
    "weakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), xgb_5))\n",
    "weakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), SVC_5))\n",
    "weakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), lr_5))\n",
    "weakmodles1.append(make_pipeline(ColumnSelector(cols=(0, 1, 3, 10, 11)), kneigh_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking all the classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 150 classifiers...\n",
      "Fitting classifier1: pipeline (1/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier2: pipeline (2/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier3: pipeline (3/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier4: pipeline (4/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier5: pipeline (5/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier6: pipeline (6/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier7: pipeline (7/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier8: pipeline (8/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier9: pipeline (9/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier10: pipeline (10/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier11: pipeline (11/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier12: pipeline (12/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier13: pipeline (13/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier14: pipeline (14/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier15: pipeline (15/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier16: pipeline (16/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier17: pipeline (17/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier18: pipeline (18/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier19: pipeline (19/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier20: pipeline (20/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier21: pipeline (21/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier22: pipeline (22/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier23: pipeline (23/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier24: pipeline (24/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier25: pipeline (25/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier26: pipeline (26/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier27: pipeline (27/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier28: pipeline (28/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier29: pipeline (29/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier30: pipeline (30/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 6, 11), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier31: pipeline (31/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier32: pipeline (32/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier33: pipeline (33/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier34: pipeline (34/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier35: pipeline (35/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 8, 10), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier36: pipeline (36/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier37: pipeline (37/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier38: pipeline (38/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier39: pipeline (39/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier40: pipeline (40/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 9, 10, 11), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier41: pipeline (41/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier42: pipeline (42/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier43: pipeline (43/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier44: pipeline (44/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier45: pipeline (45/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 10, 11), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier46: pipeline (46/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier47: pipeline (47/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier48: pipeline (48/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier49: pipeline (49/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier50: pipeline (50/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 5, 11), drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier51: pipeline (51/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier52: pipeline (52/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier53: pipeline (53/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier54: pipeline (54/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier55: pipeline (55/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier56: pipeline (56/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier57: pipeline (57/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier58: pipeline (58/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier59: pipeline (59/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier60: pipeline (60/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier61: pipeline (61/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier62: pipeline (62/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier63: pipeline (63/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier64: pipeline (64/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier65: pipeline (65/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier66: pipeline (66/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier67: pipeline (67/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier68: pipeline (68/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier69: pipeline (69/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier70: pipeline (70/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier71: pipeline (71/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier72: pipeline (72/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier73: pipeline (73/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier74: pipeline (74/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier75: pipeline (75/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier76: pipeline (76/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier77: pipeline (77/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier78: pipeline (78/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier79: pipeline (79/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier80: pipeline (80/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier81: pipeline (81/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier82: pipeline (82/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier83: pipeline (83/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier84: pipeline (84/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier85: pipeline (85/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier86: pipeline (86/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier87: pipeline (87/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier88: pipeline (88/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier89: pipeline (89/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier90: pipeline (90/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier91: pipeline (91/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier92: pipeline (92/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier93: pipeline (93/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier94: pipeline (94/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier95: pipeline (95/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier96: pipeline (96/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier97: pipeline (97/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier98: pipeline (98/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier99: pipeline (99/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier100: pipeline (100/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier101: pipeline (101/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier102: pipeline (102/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier103: pipeline (103/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier104: pipeline (104/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier105: pipeline (105/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier106: pipeline (106/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier107: pipeline (107/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier108: pipeline (108/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier109: pipeline (109/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier110: pipeline (110/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier111: pipeline (111/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier112: pipeline (112/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier113: pipeline (113/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier114: pipeline (114/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier115: pipeline (115/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier116: pipeline (116/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier117: pipeline (117/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier118: pipeline (118/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier119: pipeline (119/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier120: pipeline (120/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier121: pipeline (121/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier122: pipeline (122/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier123: pipeline (123/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier124: pipeline (124/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier125: pipeline (125/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier126: pipeline (126/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier127: pipeline (127/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier128: pipeline (128/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier129: pipeline (129/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier130: pipeline (130/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier131: pipeline (131/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier132: pipeline (132/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier133: pipeline (133/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier134: pipeline (134/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier135: pipeline (135/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier136: pipeline (136/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier137: pipeline (137/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier138: pipeline (138/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier139: pipeline (139/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier140: pipeline (140/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting classifier141: pipeline (141/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier142: pipeline (142/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier143: pipeline (143/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier144: pipeline (144/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier145: pipeline (145/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier146: pipeline (146/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier147: pipeline (147/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:soft', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier148: pipeline (148/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3,\n",
      "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
      "                     probability=True, random_state=42, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier149: pipeline (149/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=0, solver='warn',\n",
      "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier150: pipeline (150/150)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=150, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[Pipeline(memory=None,\n",
       "                                         steps=[('columnselector',\n",
       "                                                 ColumnSelector(cols=(0, 1, 8,\n",
       "                                                                      9, 10),\n",
       "                                                                drop_axis=False)),\n",
       "                                                ('randomforestclassifier',\n",
       "                                                 RandomForestClassifier(bootstrap=True,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=12,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=Non...\n",
       "                                                 learning_rate=0.1,\n",
       "                                                 max_delta_step=0, max_depth=3,\n",
       "                                                 min_child_weight=1,\n",
       "                                                 missing=None, n_estimators=500,\n",
       "                                                 n_jobs=1, nthread=None,\n",
       "                                                 objective='multi:soft',\n",
       "                                                 random_state=42, reg_alpha=0,\n",
       "                                                 reg_lambda=1,\n",
       "                                                 scale_pos_weight=1, seed=None,\n",
       "                                                 silent=None, subsample=1,\n",
       "                                                 verbosity=1),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"# estimators = [rf_5, xgb_5, SVC_5, lr_5, kneigh_5,\\n#              rf_12, xgb_12, SVC_12, lr_12, kneigh_12,]\\n\\nstcl = StackingClassifier(\\n    classifiers=weakmodles2,verbose=2,\\n    meta_classifier=xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed,n_estimators=500)\\n    #LogisticRegression(random_state=0)\\n    #xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed,n_estimators=2000)\\n    #RandomForestClassifier(n_estimators=100, random_state=42),\\n)\\n\\nstcl.fit(xtrain,ytrain)\";\n",
       "                var nbb_formatted_code = \"# estimators = [rf_5, xgb_5, SVC_5, lr_5, kneigh_5,\\n#              rf_12, xgb_12, SVC_12, lr_12, kneigh_12,]\\n\\nstcl = StackingClassifier(\\n    classifiers=weakmodles2,\\n    verbose=2,\\n    meta_classifier=xgb.XGBClassifier(\\n        objective=\\\"multi:soft\\\", random_state=randomseed, n_estimators=500\\n    )\\n    # LogisticRegression(random_state=0)\\n    # xgb.XGBClassifier(objective=\\\"multi:soft\\\", random_state=randomseed,n_estimators=2000)\\n    # RandomForestClassifier(n_estimators=100, random_state=42),\\n)\\n\\nstcl.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# estimators = [rf_5, xgb_5, SVC_5, lr_5, kneigh_5,\n",
    "#              rf_12, xgb_12, SVC_12, lr_12, kneigh_12,]\n",
    "\n",
    "stcl = StackingClassifier(\n",
    "    classifiers=weakmodles2,verbose=2,\n",
    "    meta_classifier=xgb.XGBClassifier(objective=\"multi:soft\", random_state=randomseed,n_estimators=500)\n",
    "    #LogisticRegression(random_state=0)\n",
    "    #xgb.XGBClassifier(objective=\"multi:soft\", random_state=randomseed,n_estimators=2000)\n",
    "    #RandomForestClassifier(n_estimators=100, random_state=42),\n",
    ")\n",
    "\n",
    "stcl.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7033333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  148   52    0\n",
       "1   54  136   10\n",
       "2    4   58  138"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"y_pred = stcl.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = stcl.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = stcl.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.55      0.68      0.61       200\n",
      "           2       0.93      0.69      0.79       200\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.73      0.70      0.71       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"len(stcl.clfs_)\";\n",
       "                var nbb_formatted_code = \"len(stcl.clfs_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(stcl.clfs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"accuracy = []\\nfor i in range(150):\\n    model = stcl.clfs_[i]\\n    y_pred = model.predict((xtest))\\n    accuracy.append(m.accuracy_score(ytest, y_pred))\\n#     print(i)\";\n",
       "                var nbb_formatted_code = \"accuracy = []\\nfor i in range(150):\\n    model = stcl.clfs_[i]\\n    y_pred = model.predict((xtest))\\n    accuracy.append(m.accuracy_score(ytest, y_pred))\\n#     print(i)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for i in range(150):\n",
    "    model = stcl.clfs_[i]\n",
    "    y_pred = model.predict((xtest))\n",
    "    accuracy.append(m.accuracy_score(ytest, y_pred))\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.723333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  index\n",
       "0  0.723333      0\n",
       "1  0.740000      1\n",
       "2  0.741667      2\n",
       "3  0.716667      3\n",
       "4  0.720000      4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"accuracypd = pd.DataFrame()\\naccuracypd[\\\"accuracy\\\"] = accuracy\\naccuracypd[\\\"index\\\"] = np.arange(0, len(accuracy), 1)\\naccuracypd.head()\";\n",
       "                var nbb_formatted_code = \"accuracypd = pd.DataFrame()\\naccuracypd[\\\"accuracy\\\"] = accuracy\\naccuracypd[\\\"index\\\"] = np.arange(0, len(accuracy), 1)\\naccuracypd.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracypd = pd.DataFrame()\n",
    "accuracypd[\"accuracy\"] = accuracy\n",
    "accuracypd[\"index\"] = np.arange(0, len(accuracy), 1)\n",
    "accuracypd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>122</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>117</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>132</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>127</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>121</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>112</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>91</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>87</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>147</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>62</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>61</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>142</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>86</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>92</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>97</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>102</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>77</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>57</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>107</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>136</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>76</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>52</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>71</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>81</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>51</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>126</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>106</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>101</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>141</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0  accuracy  index\n",
       "0        66  0.755000     66\n",
       "1        47  0.753333     47\n",
       "2        26  0.751667     26\n",
       "3        46  0.751667     46\n",
       "4        11  0.751667     11\n",
       "5        82  0.750000     82\n",
       "6        72  0.750000     72\n",
       "7       122  0.750000    122\n",
       "8       117  0.750000    117\n",
       "9        67  0.750000     67\n",
       "10      132  0.748333    132\n",
       "11      127  0.748333    127\n",
       "12      121  0.748333    121\n",
       "13      112  0.748333    112\n",
       "14       91  0.748333     91\n",
       "15       87  0.748333     87\n",
       "16      147  0.748333    147\n",
       "17       62  0.748333     62\n",
       "18       61  0.748333     61\n",
       "19      142  0.746667    142\n",
       "20       86  0.746667     86\n",
       "21       92  0.746667     92\n",
       "22       97  0.746667     97\n",
       "23       27  0.746667     27\n",
       "24      102  0.746667    102\n",
       "25       77  0.746667     77\n",
       "26       57  0.746667     57\n",
       "27      107  0.745000    107\n",
       "28       31  0.745000     31\n",
       "29       36  0.743333     36\n",
       "30      136  0.743333    136\n",
       "31       76  0.743333     76\n",
       "32       52  0.743333     52\n",
       "33       71  0.743333     71\n",
       "34       81  0.743333     81\n",
       "35       51  0.741667     51\n",
       "36      126  0.741667    126\n",
       "37      106  0.741667    106\n",
       "38      101  0.741667    101\n",
       "39      141  0.741667    141\n",
       "40        2  0.741667      2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 70;\n",
       "                var nbb_unformatted_code = \"selectedclassifiers_info = (\\n    accuracypd[accuracypd.accuracy > 0.74]\\n    .sort_values(by=\\\"accuracy\\\", ascending=False)\\n    .reset_index()\\n)\\nselectedclassifiers_info.head(100)\";\n",
       "                var nbb_formatted_code = \"selectedclassifiers_info = (\\n    accuracypd[accuracypd.accuracy > 0.74]\\n    .sort_values(by=\\\"accuracy\\\", ascending=False)\\n    .reset_index()\\n)\\nselectedclassifiers_info.head(100)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selectedclassifiers_info = (\n",
    "    accuracypd[accuracypd.accuracy > 0.74]\n",
    "    .sort_values(by=\"accuracy\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "selectedclassifiers_info.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('columnselector',\n",
       "  ColumnSelector(cols=(0, 1, 2, 3, 5, 8, 10, 11), drop_axis=False)),\n",
       " ('svc', SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "      kernel='linear', max_iter=-1, probability=True, random_state=42,\n",
       "      shrinking=True, tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 91;\n",
       "                var nbb_unformatted_code = \"weakmodles2[142].steps\";\n",
       "                var nbb_formatted_code = \"weakmodles2[142].steps\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles2[142].steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3, 5, 8, 10, 11)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"weakmodles2[142].steps[0][1].cols\";\n",
       "                var nbb_formatted_code = \"weakmodles2[142].steps[0][1].cols\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles2[142].steps[0][1].cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svc'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 106;\n",
       "                var nbb_unformatted_code = \"weakmodles2[142].steps[1][0]\";\n",
       "                var nbb_formatted_code = \"weakmodles2[142].steps[1][0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles2[142].steps[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 3, 4, 6, 7, 9, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 5, 11) svc\n",
      "(0, 1, 5, 6, 11) xgbclassifier\n",
      "(0, 1, 2, 5, 11) xgbclassifier\n",
      "(0, 1, 7, 9, 10) xgbclassifier\n",
      "(0, 1, 3, 4, 5, 6, 8, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 8, 9, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 6, 9, 11) svc\n",
      "(0, 1, 2, 3, 5, 9, 10, 11) svc\n",
      "(0, 1, 3, 4, 6, 7, 9, 10, 11) svc\n",
      "(0, 1, 3, 4, 8, 9, 10, 11) svc\n",
      "(0, 1, 3, 4, 6, 9, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 6, 9, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 4, 9, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 6, 7, 8, 11) xgbclassifier\n",
      "(0, 1, 3, 4, 6, 7, 8, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 6, 10, 11) svc\n",
      "(0, 1, 2, 3, 4, 5, 6, 9, 11) svc\n",
      "(0, 1, 2, 3, 4, 5, 6, 9, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 5, 8, 10, 11) svc\n",
      "(0, 1, 3, 4, 6, 7, 8, 10, 11) xgbclassifier\n",
      "(0, 1, 3, 4, 5, 6, 7, 8, 11) svc\n",
      "(0, 1, 3, 5, 6, 8, 9, 10, 11) svc\n",
      "(0, 1, 5, 6, 11) svc\n",
      "(0, 1, 2, 3, 5, 6, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 6, 9, 10, 11) svc\n",
      "(0, 1, 2, 3, 4, 6, 9, 10, 11) svc\n",
      "(0, 1, 2, 3, 4, 6, 10, 11) svc\n",
      "(0, 1, 7, 8, 10) xgbclassifier\n",
      "(0, 1, 9, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 6, 8, 9, 10, 11) xgbclassifier\n",
      "(0, 1, 3, 4, 5, 6, 9, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 5, 6, 8, 10, 11) svc\n",
      "(0, 1, 3, 4, 5, 8, 9, 10, 11) xgbclassifier\n",
      "(0, 1, 3, 4, 5, 6, 8, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 5, 6, 8, 10, 11) xgbclassifier\n",
      "(0, 1, 3, 4, 6, 9, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 4, 6, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 5, 6, 10, 11) xgbclassifier\n",
      "(0, 1, 2, 3, 5, 8, 10, 11) xgbclassifier\n",
      "(0, 1, 8, 9, 10) svc\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 111;\n",
       "                var nbb_unformatted_code = \"for i in range(selectedclassifiers_info.shape[0]):\\n    index = selectedclassifiers_info.iloc[i, 0]\\n    print(weakmodles2[index].steps[0][1].cols, weakmodles2[index].steps[1][0])\";\n",
       "                var nbb_formatted_code = \"for i in range(selectedclassifiers_info.shape[0]):\\n    index = selectedclassifiers_info.iloc[i, 0]\\n    print(weakmodles2[index].steps[0][1].cols, weakmodles2[index].steps[1][0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(selectedclassifiers_info.shape[0]):\n",
    "    index = selectedclassifiers_info.iloc[i, 0]\n",
    "    print(weakmodles2[index].steps[0][1].cols, weakmodles2[index].steps[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.Random Forest\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parameters = {'max_features':('auto', 'sqrt','log2'), 'n_estimators':[10,50,100,150,200,300,700]}\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(rf_clf, parameters)\n",
    "rf_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"from sklearn.ensemble import RandomForestClassifier\\n\\nrf = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\n# rf=rf_clf.best_estimator_\\n# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n#                        max_depth=None, max_features='auto', max_leaf_nodes=None,\\n#                        min_impurity_decrease=0.0, min_impurity_split=None,\\n#                        min_samples_leaf=1, min_samples_split=2,\\n#                        min_weight_fraction_leaf=0.0, n_estimators=150,\\n#                        n_jobs=None, oob_score=False, random_state=None,\\n#                        verbose=0, warm_start=False)\\n\\n\\nrf.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"from sklearn.ensemble import RandomForestClassifier\\n\\nrf = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\n# rf=rf_clf.best_estimator_\\n# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n#                        max_depth=None, max_features='auto', max_leaf_nodes=None,\\n#                        min_impurity_decrease=0.0, min_impurity_split=None,\\n#                        min_samples_leaf=1, min_samples_split=2,\\n#                        min_weight_fraction_leaf=0.0, n_estimators=150,\\n#                        n_jobs=None, oob_score=False, random_state=None,\\n#                        verbose=0, warm_start=False)\\n\\n\\nrf.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "# rf=rf_clf.best_estimator_\n",
    "# rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "#                        n_jobs=None, oob_score=False, random_state=None,\n",
    "#                        verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b546684e7d1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m scores = model_selection.cross_val_score(rf, xtrain, ytrain, \n\u001b[1;32m----> 3\u001b[1;33m                                           cv=10, scoring='accuracy')\n\u001b[0m\u001b[0;32m      4\u001b[0m print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n\u001b[0;32m      5\u001b[0m       % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 231\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"from sklearn import model_selection\\nscores = model_selection.cross_val_score(rf, xtrain, ytrain, \\n                                          cv=10, scoring='accuracy')\\nprint(\\\"Accuracy: %0.2f (+/- %0.2f) [%s] \\\\n [%s]\\\" \\n      % (scores.mean(), scores.std(), 'RandomForestClassifier',scores))\";\n",
       "                var nbb_formatted_code = \"from sklearn import model_selection\\n\\nscores = model_selection.cross_val_score(rf, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\")\\nprint(\\n    \\\"Accuracy: %0.2f (+/- %0.2f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"RandomForestClassifier\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "scores = model_selection.cross_val_score(rf, xtrain, ytrain, cv=10, scoring=\"accuracy\")\n",
    "print(\n",
    "    \"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"RandomForestClassifier\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD4CAYAAAAkRnsLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAaoUlEQVR4nO3df7RXdZ3v8edrDhcUCcSkLhITeDs6V8xQCLUpK6cEvSlZqFRzxcY7rCybla3pLl3M6Ki1lpOVk12T5ZpplFkZmFency0lUpmpdUVFQxBHhJSS0asRhjoqLvB9/9ifL2y+nvP9cc7+7u8+8Hqs9V1nfz/7s/f+fL+sc97svb/fz0sRgZmZWRH+oNsDMDOzfYeLipmZFcZFxczMCuOiYmZmhXFRMTOzwozo9gDKduihh8aUKVO6PQwzs2HloYce2hoRE5r12++KypQpU1i9enW3h2FmNqxI+nUr/Xz5y8zMCuOiYmZmhXFRMTOzwux3RWXdv29nysU/7vYwzMz2SU2LiqRdktbkHlMkfUjSHWn9eZJ+W9fnqNTv0X72d6OkpyQ9IukJSUskTWoyhrtS//WSFkvqSe1npbY3JM0c7JtgZmbFaOVM5dWImJ57bO6nz7K6Po812edXIuI9wJHAL4F7JY1s0P/s1P9oYAJwVmp/FPgE8K8tvA4zM+uwrl7+isw1wP8DTm3Q78W0OAIYCURq/7eI2NDxgZqZWUtaKSoH5i5r3T5An3PqLn8d2OY4Hgb+qFEHScuB54GXgFvb2bmkhZJWS1q965XtbQ7NzMxa1cqXH1+NiOlN+iyLiAvzDZLaGUfTzhExW9IBwPeBk4EVre48Im4AbgAYNbHXATJmZh1SlU9/HQv8W7NOEfEa0AfM7fiIzMysbV0tKsr8BTARuGuAPmMkTUzLI4DTgMfLG6WZmbWqqKJSf0/lfan9SElbco/ap7aulvQI8ATwXuDDEfH6APs+COiTtBZ4hOy+ymIASWdK2gKcCPw43Xdp6N2TxrH5qv82+FdqZmYD0v6WUT9z5szwhJJmZu2R9FBENP0+YFXuqZiZ2T6gUlPfS7ofGFXX/N8jYl03xmNmZu2pVFGJiOO7PQYzMxs8X/4yM7PCuKiYmVlhXFTMzKwwlbqnUoZGeSr+/oqZ2dD4TMXMzAoz3EO6rpS0Nh3zp5IOG+wbYWZmQzfcQ7qujohj0izKdwCXtvB6zMysQ4Z7SNeLuW4H1drrOU/FzKwcwz6kS9LXJD0NfIYBzlQi4oaImBkRM3tGj2tzaGZm1qp2L3+dOUCf+stfr7Y5jpZCusimyB9FFtJVa18UEZPJwrsuHGBzMzMrQVU+/VVESNfNwCcLHpeZmbVhWId0SerNdT0Dh3eZmXVVUV9+PEfS+3PPPw88QwrpyrVflH5eLemvgdHAKloL6RoF9AD3kEK6gKskHQm8Afwa+Fyzgb570jhW+0uOZmYd4ZAuMzNryiFdZmZWukrN/eWQLjOz4a1SRcUhXWZmw5svf5mZWWFcVMzMrDAuKmZmVphK3VMpQ6OQLnBQl5nZUPhMxczMCjMsQrpy2/bl9ynpEEkrJG1MP8e38+LNzKxYwyWkC0mfAF6ua74YuDsieoG703MzM+uSYRHSJWkM8GXgq3Wr5gI3peWbgI8PsL1DuszMSjBcQrquBL4JvFLX/vaIeBYg/Xxbfxs7pMvMrBytfPrr1ZQB38iyiNgrIEtqmru1V/cBV0jTgXdFxEWSprSzUzMzK1dVPv3VKKTrRGCGpM3AL4AjJK1M657LZa1MJIsbNjOzLunq91SUnc58kQYhXRFxPXB96j8FuCMiPpRW9wELgKvSzx81O6bzVMzMOqeoM5X6eyrvS+1HStqSe5yV2q+W9AjwBPBeGod0NXIV8FFJG4GPpudmZtYlDukyM7OmHNJlZmalq9TcXw7pMjMb3ipVVBzSZWY2vPnyl5mZFcZFxczMCuOiYmZmhanUPZUyOKTLzKxzfKZiZmaFGRYhXZLuSv3XS1osqSe1T5e0Kh1ztaRZg30jzMxs6IZLSNfZqf/RwASgNt3L14HL0yzKl6bnZmbWJcMipCsiXkyLI4CRQG1umQDGpuVxwDP9be+QLjOzcgyXkC4kLSeb2v4l4NbU/CWyySmfBr4BXNLftg7pMjMrR7uXv84coE/95a9X2xxH00SviJhNNkX+KODk1HwBcFFETAYuAv6hzeOamVmBqvLpr0YhXbtFxGtkGSpzU9MC4La0/EPAN+rNzLqo8iFdksYAb4mIZyWNAE4Dfp5WPwN8EFhJdvaysdkxHdJlZtY5RRWVcyS9P/f882R/8I+UtCXXflH6ebWkvwZGA6toHNJ1ENAnaRTQA9wDLE7r/hz4dio2rwELC3k1ZmY2KA7pMjOzphzSZWZmpavU3F8O6TIzG94qVVQc0mVmNrz58peZmRXGRcXMzApTqctfZWiWp9KIs1bMzBqr1JmKpEVpevu1aQ6x4yWtlLQhN6/Yranvtem7Lvltr+ve6M3MrDJnKpJOBD4GHBcROyQdSjYjMcBnIqL+yyV/BayR9H2y2Yr/B9l0L2Zm1iWVKSpkU7VsjYgdABGxFSCbyeXNIuJFSYuA/5WaLo2I35cxUDMz61+VLn/9FJic0iC/K+mDuXXfz13+urrWGBE/AMYDYyPin8oesJmZ7a0yZyoR8bKkGcAHgA8DyyRdnFb3d/kLSe8A/jMQksZExMv97VvSQtK8YD1jJ3Rk/GZmVqGiAhARu8hmHF4paR3Z1PaNfBv4G+C/ApcBXxlgvzcANwCMmti7f012ZmZWosoUFUlHAm9ERG36+unAr8ly6fvrfyrwNmAJ2WzHj0j6x4h4rIzxmpnZm1WmqABjgO9IOhjYCWwiu2R1K9k9lVqa5FayT4n9HTAvsmmW/0PS/yS7aX/ym/ZsZmal8NT3ZmbWlKe+NzOz0rmomJlZYVxUzMysMC4qZmZWGBcVMzMrjIuKmZkVxkXFzMwKU6UvP5ZiKCFdg+FgLzPbn7R1piLpTRM2SjpJ0sOSdkqaV7dugaSN6bEg136XpEdSINdiST2p/cpcQNdPJR2W2pVCuTal9cc1O4aZmZWviMtfvwHOA27ON0o6hGySx+OBWcBlksan1WdHxHvI5vWaAJyV2q+OiGMiYjpwB3Bpaj8V6E2PhcD1LRzDzMxKNuSiEhGbI2It8EbdqtnAiojYFhEvACuAOWmbF1OfEWTpjlHXDnBQrR2YCyyJzCrgYEkTGx3DzMzK18kb9ZOAp3PPt6Q2ACQtB54HXiKbNLLW/jVJTwOfYc+ZykD7aniM3D4XSlotafWuV7YP5TWZmVkDnSwq/eUA7569MiJmk0UIjyI3s3BELIqIycD3gQub7KvhMXL7vCEiZkbEzJ7R41p/BWZm1pZOFpUtwOTc83cAz+Q7RMRrQB/Z5a16NwOfbLKvpscwM7PydLKoLAdOkTQ+3Tw/BVguaUy6H4KkEcBpwOPpeW9u+zNq7WSF59z0KbATgO0R8exAx+jgazIzswba/Z7KaElbcs+/BfwcuB0YD5wu6fKImBYR2yRdCTyY+l6R2t4O9EkaBfQA9wCLU5+ragmQZKmPn0vtPyErPpuAV4DPAgx0jDZfk5mZFcQhXWZm1pRDuszMrHQuKmZmVhgXFTMzK4yLipmZFcZFxczMCuOiYmZmhXFRMTOzwjikq8Mc0mVm+5PKnKlIOlNSSPqjXFuvpDsk/UrSQ5LulXRSWneepN+mQK/a46juvQIzM6tMUQE+BfwCmA8g6QDgx8ANEfFfImIG8EXg8Nw2yyJieu7xWOmjNjOz3SpRVCSNAf4YOJ9UVMjyVO6LiL5av4h4NCJuLH+EZmbWiqrcU/k4cFdEPCFpW8qgnwY83GS7cyS9P/f8xIh4tb6TpIVkMcT0jJ1Q1JjNzKxOJc5UyC59LU3LS9PzvUi6XdKjkm7LNddf/npTQQGHdJmZlaXrZyqS3kqW/Hi0pCCbDj+Ay4GTav0i4kxJM4FvdGWgZmbWVBXOVOYBSyLinRExJUUJPwU8AfyxpDNyfUd3ZYRmZtaSrp+pkF3quqqu7X8DnwY+BnxL0t8BzwEvAV/N9au/p/L5iPi/jQ727knjWO3vjpiZdYRDuszMrCmHdJmZWelcVMzMrDAuKmZmVhgXFTMzK4yLipmZFcZFxczMCuOiYmZmhanClx9LVXZIV43Dusxsf9DWmYqkl/tpO0nSw5J2SppXt26BpI3psSDXPkPSOkmbJF0rSal9WS5wa7OkNbltLkn9N0ianWufk9o2Sbq4nddjZmbFKuJM5TfAecBf5hslHQJcBswkmyDyIUl9EfECcD3ZVPSrgJ8Ac4A7I+Kc3PbfBLan5aPIclamAYcBP5N0ROp6HfBRYAvwYDqGw7rMzLpgyPdUImJzRKwF3qhbNRtYERHbUiFZAcyRNBEYGxH3RTZHzBKyPJXd0pnL2cAPUtNcYGlE7IiIp4BNwKz02BQRT0bE62TT5s8d6msyM7PB6eSN+knA07nnW1LbpLRc3573AeC5iNjYwr76a9+LpIWSVktaveuV7YN4KWZm1opOFhX10xYN2vM+xZ6zlKHuyyFdZmYl6WRR2QJMzj1/B/BMan9HP+0ASBoBfAJY1uK++ms3M7Mu6GRRWQ6cImm8pPHAKcDyiHgWeEnSCeneybnAj3LbfQR4PCLyl8j6gPmSRkmaCvQCDwAPAr2SpkoaSXYzv6+Dr8nMzBpo99NfoyXl/9h/C/g5cDswHjhd0uURMS0itkm6kuwPP8AVEbEtLV8A3AgcCNyZHjXz2fvSFxGxXtItwGPATuALEbELQNKFZAWsB/heRKxv9AIc0mVm1jkO6TIzs6Yc0mVmZqVzUTEzs8K4qJiZWWFcVMzMrDAuKmZmVhgXFTMzK4zzVLrMOStmti/pVp7KXZIekbRe0mJJPan9EEkrUv8V6Zv4KHNtykxZK+m4ZscwM7PyFXH5q5ancnO+MZencjzZFPWX1YoEcHZEvAc4GpgAnJXaLwbujohe4O70HOBUsqlZeslyWK5v4RhmZlay0vNU0jYvpj4jgJHsmVl4LnBTWr6JPTkrc4ElkVkFHJxyWQY8hpmZla8beSoASFoOPA+8BNyamt+eJpwk/Xxbk321lKdiZmbl6EaeSrYQMRuYCIwCTh7kvlrKU3FIl5lZObqRp7JbRLxGNlV9LQL4uXRZi/Tz+Sb7ailPxSFdZmblKD1PRdKYXOEYAZwGPJ626QNqn+BawJ6clT7g3PQpsBOA7enyWL/H6OBrMjOzBkrPU5H0dqBP0iiyDJR7gMWpz1XALZLOJ/tUWe1TYT8hKz6bgFeAzwI0yWwxM7OSOU/FzMyacp6KmZmVzkXFzMwK46JiZmaFcVExM7PCuKiYmVlhXFTMzKwwLipmZlYYh3QNEw7zMrPhoN2QrkUpWGutpDWSjpc0VdL9KSRrmaSRqe+o9HxTWj8lt59LUvsGSbNT2wGSHsiFd12e69/2MczMrHwtFxVJJwIfA46LiGOAj5BNO/+3wDUpWOsF4Py0yfnACxHxLuCa1A9JRwHzgWlk2SffTcmPO4CTU3jXdGBOmueLdo9hZmbd0c6ZykRga0TsAIiIrcCzZNPW1/JQ6oO1aoFbtwJ/IkmpfWlE7IiIp8jm85qVArhqccX/KT0ibdPuMczMrAvaKSo/BSZLekLSdyV9EHgr8PuI2Jn65EOydgdopfXbU/8Bg7Uk9UhaQzbl/YqIuH+Qx9iL81TMzMrRclFJZxEzyDLifwssI80WXN81/Ww7WCsidkXEdLJclFmSjm7Uv8m6/Nidp2JmVoK2btSnP/orI+Iy4ELgJLK8+NqnyPIhWbsDtNL6ccA2Wgvv+j2wkuyey9ZBHMPMzLqgnRv1R0rqzTVNB34N3AvMS231wVq1wK15wD2RzbPfB8xPn9yaCvQCD0iaIOngdKwDyT4I8Hjapt1jmJlZF7ScpyJpBvAd4GBgJ9kN9oXAWGApcAjwS+BPI2KHpAOAfwKOJTt7mB8RT6Z9LQL+LO3nSxFxp6RjyG6695AVu1si4orU//B2jzEQ56mYmbWv1TwVh3SZmVlTDukyM7PSuaiYmVlhXFTMzKwwLipmZlYYFxUzMyuMi4qZmRXGRcXMzArjkK79kAO/zKxT2g3permftpMkPSxpp6R5desWpGCtjZIW5Nq/Junp+v1JuiaFf61JsyH/voV9zZC0LgV1Xeup783MuqeIy1+/Ac4Dbs43SjoEuAw4HpgFXCZpfFr9f1LbXiLiooiYnmYq/g5wWwv7up5supje9JhTwGsyM7NBGHJRiYjNEbEWeKNu1WyyTJRtEfECsIL0Bz8iVkXEs012/SngB432JWkiMDYi7ksTSS5hT4CXmZmVrJM36gcM42pG0juBqcA9TfY1KS03PIZDuszMytHJotJSgNYA5gO3RsSuJvtySJeZWYV0sqg0DeNqYD57Ln012teWtDyYY5iZWcE6WVSWA6dIGp9uqp+S2hqSdCQwHriv2b7SfZmXJJ2QPvV1LnsCvMzMrGTtfk9ltKT8PYxvAT8HbicrBKdLujwipkXENklXAg+mvldExDYASV8HPp3b399HxN+kfp8CluYTHBvtC7gAuBE4ELgzPQb07knjWO3vaZiZdYRDuszMrCmHdJmZWelcVMzMrDAuKmZmVhgXFTMzK4yLipmZFcZFxczMCuOiYmZmhXFIl5mVyiFx+7auhHTl1vdJerSu7YuSNkhan755X2u/JAVxbZA0O9c+J7VtknRxO6/HzMyKVcSZSi2k6y/zjblgrZlkMwc/JKkv5aEg6RNAffLjh4G5wDERsUPS21L7UWSTTE4DDgN+JumItNl1wEfJJpd8MB3jsQJel5mZtakrIV2SxgBfBr5at80FwFURsSPt+/nUPpdsPrAdEfEUsIksAXIWsCkinoyI14Glqa+ZmXVBt0K6rgS+CbxSt80RwAck3S/pXyS9t8m+WgoCc0iXmVk5Sg/pkjQdeFdE3N7P+hFksx2fAHwFuCVNae+QLjOzYaAbIV0nAjMkbQZ+ARwhaWVum9si8wDZJbVDG+xrKEFgZmZWsNJDuiLi+og4LCKmAO8HnoiID6Vt/hk4GSDdiB8JbAX6gPmSRkmaCvQCD5Dlq/RKmippJNnN/L4OviYzM2ugKyFdDXwP+F76mPHrwIIU1rVe0i3AY8BO4Au1/HpJF5IVsB7gexGxvtEBHNJlZtY5DukyM7OmHNJlZmalc1ExM7PCuKiYmVlhXFTMzKwwLipmZlYYFxUzMyuM81TMzPYDZeXYdCVPRdIMSetSBsq1aX4vJE2XtErSmjQB5KzUrtRvk6S1ko5rdgwzMytfEZe/ankqN+cbc3kqx5NNUX9Zmq4F4HpgIdl0K72kKfGBrwOXR8R04NL0HODUXN+FaftmxzAzs5KVnqciaSIwNiLuS1OwLAE+XtsdMDYtj2PP5JBzgSVposlVwMFpPwNmtpiZWfk6eU+lUQbKln7aAb4ELJf0DbKC974W9tVSngrZGQ49YycM7tWYmVlTpeepNGiHLPnxooiYDFwE/MMQ9rWnwXkqZmal6Eaeypa0XN8OsAC4LS3/kOw+SbN9OU/FzKwiupGn8izwkqQT0qe+zgV+lLZ5BvhgWj4Z2JiW+4Bz06fATgC2p/30e4wOviYzM2ugW3kqFwA3AgcCd6YHwJ8D35Y0AniNdB8E+AlwGrCJLNf+swCDzGwxM7MOcZ6KmZk15TwVMzMrnYuKmZkVxkXFzMwKs9/dU5H0ErCh2+No4lBga7cH0YTHWAyPsRgeYzEajfGdEdH02+P73SzFwIZWbjZ1k6TVHuPQeYzF8BiLsb+M0Ze/zMysMC4qZmZWmP2xqNzQ7QG0wGMshsdYDI+xGPvFGPe7G/VmZtY5++OZipmZdYiLipmZFWafKiqS5kjakLLsL+5n/ShJy9L6+yVNya27JLVvkDS7SuOTNEXSq5LWpMfiToyvxTGeJOlhSTslzatbt0DSxvRYUNEx7sq9j31dHOOXJT0maa2kuyW9M7euKu9jozFW5X38nKR1aRy/kHRUbl3Hf6eHMsYq/V7n+s2TFJJm5traex8jYp94AD3Ar4DDgZHAI8BRdX0+DyxOy/OBZWn5qNR/FDA17aenQuObAjxakfdwCnAMWQz0vFz7IcCT6ef4tDy+SmNM616uyPv4YWB0Wr4g929dpfex3zFW7H0cm1s+A7grLXf8d7qAMVbm9zr1ewvwr8AqYOZg38d96UxlFrApIp6MiNeBpWTZ9nlzgZvS8q3An0hSal8aETsi4imyKfZnUayhjK8sTccYEZsjYi3wRt22s4EVEbEtIl4AVgBzKjbGsrQyxnsj4pX0dBV7guuq9D4ONMaytDLGF3NPD2JP8msZv9NDHWNZWvnbA3Al8HWy2JGatt/HfamotJJXv7tPROwEtgNvbXHbbo4PYKqkX0r6F0kfKHhs7YyxE9u2Y6jHOUDSakmrJH282KHt1u4Yz2dPplBV38f8GKFC76OkL0j6FdkfxL9oZ9sujxEq8nst6VhgckTc0e629falaVpayasfUtb9EA1lfM8CfxgRv5M0A/hnSdPq/gdU1hg7sW07hnqcP4yIZyQdDtwjaV1E/KqgsdW0PEZJfwrMZE/iaeXex37GCBV6HyPiOuA6SZ8G/ooslrxS7+MAY6zE77WkPwCuAc5rd9v+7EtnKq3k1e/uoyxdchywrcVtuza+dOr5O4CIeIjsuuYRBY+v1TF2Ytt2DOk4EfFM+vkksBI4tsjBJS2NUdJHgEXAGRGxo51tuzzGSr2POUuB2llTpd7HnN1jrNDv9VuAo4GVkjYDJwB96WZ9++9jp28SlfUgO+t6kuxmUu1m1LS6Pl9g7xvht6Tlaex9M+pJir9RP5TxTaiNh+xm278Dh3TjPcz1vZE336h/iuzm8vi0XLUxjgdGpeVDgY30c8OypH/rY8n+iPTWtVfmfWwwxiq9j7255dOB1Wm547/TBYyxcr/Xqf9K9tyob/t9LHTw3X6Q5dg/kX4RFqW2K8j+lwVwAPBDsptNDwCH57ZdlLbbAJxapfEBnwTWp3/ch4HTu/gevpfsfy//AfwOWJ/b9s/S2DcBn63aGIH3AevS+7gOOL+LY/wZ8BywJj36Kvg+9jvGir2P306/G2uAe8n9sSzjd3ooY6zS73Vd35WkojKY99HTtJiZWWH2pXsqZmbWZS4qZmZWGBcVMzMrjIuKmZkVxkXFzMwK46JiZmaFcVExM7PC/H/rNx+5gMHTVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L100800', 'L104600', 'L101700', 'S000300', 'L103000', 'L100700', 'AGE',\n",
      "       'L103300', 'SEX', 'FIELD_38', 'FIELD_40', 'FIELD_33', 'FIELD_31'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"ypred = rf.predict(xtest)\\n\\nscore = rf.score(xtest, ytest)\\nprint(score)\\n\\nfeat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\\nfeat_importances.nlargest(16).plot(kind=\\\"barh\\\")\\nplt.show()\\n\\nprint(feat_importances.nlargest(16).index)\";\n",
       "                var nbb_formatted_code = \"ypred = rf.predict(xtest)\\n\\nscore = rf.score(xtest, ytest)\\nprint(score)\\n\\nfeat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\\nfeat_importances.nlargest(16).plot(kind=\\\"barh\\\")\\nplt.show()\\n\\nprint(feat_importances.nlargest(16).index)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=test.iloc[:, :-1].columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.823\n",
      "Accuracy on test set: 0.722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>138</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  143   57    0\n",
       "1   53  138    9\n",
       "2    3   45  152"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"print(\\\"Accuracy on training set: {:.3f}\\\".format(rf.score(xtrain, ytrain)))\\nprint(\\\"Accuracy on test set: {:.3f}\\\".format(rf.score(xtest, ytest)))\\n\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"print(\\\"Accuracy on training set: {:.3f}\\\".format(rf.score(xtrain, ytrain)))\\nprint(\\\"Accuracy on test set: {:.3f}\\\".format(rf.score(xtest, ytest)))\\n\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       200\n",
      "           1       0.57      0.69      0.63       200\n",
      "           2       0.94      0.76      0.84       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.75      0.72      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"from sklearn.metrics import classification_report\\n\\nprint(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"from sklearn.metrics import classification_report\\n\\nprint(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.XGBoost\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[3,5,7,9],\n",
    "              'n_estimators':[10,50,100,200,700]}\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = GridSearchCV(xgb_clf, parameters)\n",
    "xgb_clf.fit(xtrain, ytrain)\n",
    "xgb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=7,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"\\nfrom sklearn import metrics as m\\n\\nxgb_model = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n# objective=\\\"multi:softmax\\\"\\n# objective=\\\"binary:logistic\\\"\\n# xgb_model=xgb_clf.best_estimator_\\n\\n\\nxgb_model.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"from sklearn import metrics as m\\n\\nxgb_model = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n# objective=\\\"multi:softmax\\\"\\n# objective=\\\"binary:logistic\\\"\\n# xgb_model=xgb_clf.best_estimator_\\n\\n\\nxgb_model.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "# objective=\"multi:softmax\"\n",
    "# objective=\"binary:logistic\"\n",
    "# xgb_model=xgb_clf.best_estimator_\n",
    "\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(xgb_model, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'xgb_model',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>127</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  147   52    1\n",
       "1   58  127   15\n",
       "2    4   35  161"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"y_pred = xgb_model.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = xgb_model.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       200\n",
      "           1       0.59      0.64      0.61       200\n",
      "           2       0.91      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.72      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 SVC\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,5,10,15,20,25,30,70]}\n",
    "SVC_clf = SVC()\n",
    "SVC_clf2 = GridSearchCV(SVC_clf, parameters)\n",
    "SVC_clf2.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "# sorted(SVC_clf2.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=True, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 121;\n",
       "                var nbb_unformatted_code = \"# SVC_clf = SVC_clf2.best_estimator_\\nSVC_clf = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\nSVC_clf.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"# SVC_clf = SVC_clf2.best_estimator_\\nSVC_clf = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight=None,\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=\\\"auto_deprecated\\\",\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\nSVC_clf.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVC_clf = SVC_clf2.best_estimator_\n",
    "SVC_clf = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=\"auto_deprecated\",\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "SVC_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_score(SVC_clf, xtrain, ytrain, \n",
    "                                          cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\" \n",
    "      % (scores.mean(), scores.std(), 'SVC_clf',scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7466666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  150   49    1\n",
       "1   49  134   17\n",
       "2    3   33  164"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 122;\n",
       "                var nbb_unformatted_code = \"y_pred = SVC_clf.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = SVC_clf.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = SVC_clf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       200\n",
      "           1       0.62      0.67      0.64       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 123;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4Logistic regression\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>104</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  158   41    1\n",
       "1   68  104   28\n",
       "2    3   24  173"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       200\n",
      "           1       0.62      0.52      0.56       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.72      0.72      0.72       600\n",
      "weighted avg       0.72      0.72      0.72       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 K-neighbors Classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 124;\n",
       "                var nbb_unformatted_code = \"neigh = KNeighborsClassifier(n_neighbors=150)\\nneigh.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"neigh = KNeighborsClassifier(n_neighbors=150)\\nneigh.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=150)\n",
    "neigh.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.6366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>112</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  131   58   11\n",
       "1   61  112   27\n",
       "2    5   56  139"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 125;\n",
       "                var nbb_unformatted_code = \"y_pred = neigh.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = neigh.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = neigh.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       200\n",
      "           1       0.50      0.56      0.53       200\n",
      "           2       0.79      0.69      0.74       200\n",
      "\n",
      "    accuracy                           0.64       600\n",
      "   macro avg       0.65      0.64      0.64       600\n",
      "weighted avg       0.65      0.64      0.64       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 126;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.StackingClassifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "estimators = [rf, xgb_model, SVC_clf, lr, neigh]\n",
    "stcl = StackingClassifier(\n",
    "    classifiers=estimators,verbose=2,\n",
    "    meta_classifier=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    ")\n",
    "\n",
    "#     meta_classifier=RandomForestClassifier(n_estimators=100, random_state=42),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "Accuracy: 0.75 (+/- 0.04) [rf]\n",
      "Accuracy: 0.71 (+/- 0.04) [xgb_model]\n",
      "Accuracy: 0.73 (+/- 0.03) [SVC_clf]\n",
      "Accuracy: 0.71 (+/- 0.04) [lr]\n",
      "Accuracy: 0.65 (+/- 0.04) [Kneigh]\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold cross validation:\\n\")\n",
    "\n",
    "for clf, label in zip(\n",
    "    [rf, xgb_model, SVC_clf, lr, neigh],\n",
    "    [\"rf\", \"xgb_model\", \"SVC_clf\", \"lr\", \"Kneigh\", \"StackingClassifier\"],\n",
    "):\n",
    "\n",
    "    scores = model_selection.cross_val_score(\n",
    "        clf, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    "    )\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64017144 0.73193064 0.74712644 0.76193259 0.77810247 0.77933723\n",
      " 0.77563353 0.75867446 0.76081871 0.7625731 ]\n",
      "Accuracy: 0.75 (+/- 0.04) [Kneigh]\n"
     ]
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    stcl, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/5)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier2: xgbclassifier (2/5)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softprob', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/5)\n",
      "SVC(C=70, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=42,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier4: logisticregression (4/5)\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Fitting classifier5: kneighborsclassifier (5/5)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=150, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=12,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=10,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=None,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_...\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=100,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=42,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stcl.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>141</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  149   51    0\n",
       "1   48  141   11\n",
       "2    3   49  148"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = stcl.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.59      0.70      0.64       200\n",
      "           2       0.93      0.74      0.82       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.75      0.73      0.74       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting test\n",
    "# ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf, xgb_model, SVC_clf, lr, neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>SVC_clf</th>\n",
       "      <th>lr</th>\n",
       "      <th>neigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf  xgb  SVC_clf  lr  neigh\n",
       "0   0    0        0   0      0\n",
       "1   2    2        2   2      2\n",
       "2   2    2        2   2      2\n",
       "3   2    2        2   2      1\n",
       "4   2    2        2   2      0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train=pd.DataFrame()\n",
    "pd_train['rf']=rf.predict(xtrain)\n",
    "pd_train['xgb']=xgb_model.predict(xtrain)\n",
    "pd_train['SVC_clf']=SVC_clf.predict(xtrain)\n",
    "pd_train['lr']=lr.predict(xtrain)\n",
    "pd_train['neigh']=neigh.predict(xtrain)\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>SVC_clf</th>\n",
       "      <th>lr</th>\n",
       "      <th>neigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf  xgb  SVC_clf  lr  neigh\n",
       "0   0    0        0   0      1\n",
       "1   2    2        2   2      1\n",
       "2   0    0        0   1      1\n",
       "3   2    2        2   2      2\n",
       "4   2    2        2   2      2"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test=pd.DataFrame()\n",
    "pd_test['rf']=rf.predict(xtest)\n",
    "pd_test['xgb']=xgb_model.predict(xtest)\n",
    "pd_test['SVC_clf']=SVC_clf.predict(xtest)\n",
    "pd_test['lr']=lr.predict(xtest)\n",
    "pd_test['neigh']=neigh.predict(xtest)\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scltest= RandomForestClassifier(random_state=randomseed,n_estimators=5000)\n",
    "# scltest= xgb.XGBClassifier(objective=\"multi:softmax\", random_state=randomseed,n_estimators=1000 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=5000,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scltest.fit(pd_train,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>141</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  149   51    0\n",
       "1   48  141   11\n",
       "2    3   49  148"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = scltest.predict((pd_test))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rf', 'xgb', 'lr', 'SVC_clf', 'neigh'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feat_importances = pd.Series(scltest.feature_importances_, index=pd_test.columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd_test.mode(axis=1)\n",
    "y_pred.iloc[:,0].head()\n",
    "y_pred=y_pred.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7483333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  152   48    0\n",
       "1   49  134   17\n",
       "2    3   34  163"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.37633598e-01, 6.93903572e-02, 1.42674858e-03],\n",
       "       [5.09007753e-15, 6.10809252e-15, 2.08450704e-01],\n",
       "       [5.09008157e-15, 6.10809533e-15, 2.08450704e-01],\n",
       "       ...,\n",
       "       [3.79483714e-03, 6.89099933e-02, 1.35745874e-01],\n",
       "       [5.09007669e-15, 6.10809193e-15, 2.08450704e-01],\n",
       "       [1.03619479e-11, 1.24315220e-11, 2.08450704e-01]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 127;\n",
       "                var nbb_unformatted_code = \"# rf, xgb_model, SVC_clf, lr, neigh\\n(0.74 * SVC_clf.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_formatted_code = \"# rf, xgb_model, SVC_clf, lr, neigh\\n(0.74 * SVC_clf.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rf, xgb_model, SVC_clf, lr, neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.48639998e-02, 5.48207196e-02, 5.31321821e-02],\n",
       "       [7.05168664e-04, 2.20752991e-02, 1.80036434e-01],\n",
       "       [3.40281562e-03, 2.74780693e-02, 1.71936017e-01],\n",
       "       ...,\n",
       "       [1.16713095e-03, 3.23506894e-02, 1.69299081e-01],\n",
       "       [3.01445521e-05, 1.59566335e-03, 2.01191094e-01],\n",
       "       [4.04973327e-04, 3.99192407e-03, 1.98420004e-01]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 147;\n",
       "                var nbb_unformatted_code = \"(0.72 * rf.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_formatted_code = \"(0.72 * rf.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(0.72 * rf.predict_proba(xtrain) / 3.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12851986, 0.0749881 , 0.00494274],\n",
       "       [0.00058506, 0.00973582, 0.19812983],\n",
       "       [0.00085661, 0.01436699, 0.19322711],\n",
       "       ...,\n",
       "       [0.00281238, 0.04949711, 0.15614122],\n",
       "       [0.00031097, 0.0017616 , 0.20637815],\n",
       "       [0.00033181, 0.00436746, 0.20375143]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 148;\n",
       "                var nbb_unformatted_code = \"(0.74 * xgb_model.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_formatted_code = \"(0.74 * xgb_model.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(0.74 * xgb_model.predict_proba(xtrain) / 3.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.23383863e-01, 1.29808824e-01, 5.80749271e-02],\n",
       "       [1.29023016e-03, 3.18111189e-02, 3.78166266e-01],\n",
       "       [4.25942325e-03, 4.18450574e-02, 3.65163129e-01],\n",
       "       ...,\n",
       "       [3.97950929e-03, 8.18477983e-02, 3.25440303e-01],\n",
       "       [3.41111879e-04, 3.35725872e-03, 4.07569241e-01],\n",
       "       [7.36779812e-04, 8.35938643e-03, 4.02171434e-01]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 150;\n",
       "                var nbb_unformatted_code = \"(0.72 * rf.predict_proba(xtrain) / 3.55)    + (0.74 * xgb_model.predict_proba(xtrain) / 3.55)\";\n",
       "                var nbb_formatted_code = \"(0.72 * rf.predict_proba(xtrain) / 3.55) + (\\n    0.74 * xgb_model.predict_proba(xtrain) / 3.55\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(0.72 * rf.predict_proba(xtrain) / 3.55) + (\n",
    "    0.74 * xgb_model.predict_proba(xtrain) / 3.55\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 128;\n",
       "                var nbb_unformatted_code = \"temp_train = (\\n    (0.72 * rf.predict_proba(xtrain) / 3.55)\\n    + (0.74 * xgb_model.predict_proba(xtrain) / 3.55)\\n    + (0.74 * SVC_clf.predict_proba(xtrain) / 3.55)\\n    + (0.72 * lr.predict_proba(xtrain) / 3.55)\\n    + (0.63 * neigh.predict_proba(xtrain) / 3.55)\\n)\";\n",
       "                var nbb_formatted_code = \"temp_train = (\\n    (0.72 * rf.predict_proba(xtrain) / 3.55)\\n    + (0.74 * xgb_model.predict_proba(xtrain) / 3.55)\\n    + (0.74 * SVC_clf.predict_proba(xtrain) / 3.55)\\n    + (0.72 * lr.predict_proba(xtrain) / 3.55)\\n    + (0.63 * neigh.predict_proba(xtrain) / 3.55)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_train = (\n",
    "    (0.72 * rf.predict_proba(xtrain) / 3.55)\n",
    "    + (0.74 * xgb_model.predict_proba(xtrain) / 3.55)\n",
    "    + (0.74 * SVC_clf.predict_proba(xtrain) / 3.55)\n",
    "    + (0.72 * lr.predict_proba(xtrain) / 3.55)\n",
    "    + (0.63 * neigh.predict_proba(xtrain) / 3.55)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64530214, 0.34374211, 0.01095577],\n",
       "       [0.04084675, 0.28531265, 0.67384061],\n",
       "       [0.49757727, 0.48063588, 0.02178686],\n",
       "       ...,\n",
       "       [0.62540321, 0.36708375, 0.00751303],\n",
       "       [0.77594887, 0.21946576, 0.00458538],\n",
       "       [0.26568601, 0.64430359, 0.0900104 ]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 140;\n",
       "                var nbb_unformatted_code = \"temp_test = (\\n    (0.72 * rf.predict_proba(xtest) / 3.55)\\n    + (0.74 * xgb_model.predict_proba(xtest) / 3.55)\\n    + (0.74 * SVC_clf.predict_proba(xtest) / 3.55)\\n    + (0.72 * lr.predict_proba(xtest) / 3.55)\\n    + (0.63 * neigh.predict_proba(xtest) / 3.55)\\n)\\ntemp_test\";\n",
       "                var nbb_formatted_code = \"temp_test = (\\n    (0.72 * rf.predict_proba(xtest) / 3.55)\\n    + (0.74 * xgb_model.predict_proba(xtest) / 3.55)\\n    + (0.74 * SVC_clf.predict_proba(xtest) / 3.55)\\n    + (0.72 * lr.predict_proba(xtest) / 3.55)\\n    + (0.63 * neigh.predict_proba(xtest) / 3.55)\\n)\\ntemp_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_test = (\n",
    "    (0.72 * rf.predict_proba(xtest) / 3.55)\n",
    "    + (0.74 * xgb_model.predict_proba(xtest) / 3.55)\n",
    "    + (0.74 * SVC_clf.predict_proba(xtest) / 3.55)\n",
    "    + (0.72 * lr.predict_proba(xtest) / 3.55)\n",
    "    + (0.63 * neigh.predict_proba(xtest) / 3.55)\n",
    ")\n",
    "temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 146;\n",
       "                var nbb_unformatted_code = \"# temp_test = temp_test / 5\\n# temp_test\";\n",
       "                var nbb_formatted_code = \"# temp_test = temp_test / 5\\n# temp_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temp_test = temp_test / 5\n",
    "# temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 143;\n",
       "                var nbb_unformatted_code = \"temp_test = np.argmax(temp_test, axis=1)\";\n",
       "                var nbb_formatted_code = \"temp_test = np.argmax(temp_test, axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_test = np.argmax(temp_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2,\n",
       "       2, 2, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1,\n",
       "       1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1,\n",
       "       1, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1,\n",
       "       2, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 144;\n",
       "                var nbb_unformatted_code = \"temp_test\";\n",
       "                var nbb_formatted_code = \"temp_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7366666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>132</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  151   49    0\n",
       "1   52  132   16\n",
       "2    3   38  159"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 145;\n",
       "                var nbb_unformatted_code = \"y_pred = temp_test\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"y_pred = temp_test\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, y_pred))\\nconfmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = temp_test\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# estimator = KerasClassifier(build_fn=model, epochs=200, batch_size=5, verbose=0)\n",
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(estimator, xtrain, ytrain, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, np_utils.to_categorical( ytrain.to_numpy()), \n",
    "                  epochs=100, batch_size=10,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "\n",
    "tempdata=data5\n",
    "\n",
    "diabetic = tempdata[tempdata.CLASS == 2]\n",
    "prediabetic = tempdata[tempdata.CLASS == 1].sample(diabetic.shape[0],random_state=0)\n",
    "normal = tempdata[tempdata.CLASS == 0].sample(diabetic.shape[0],random_state=0)\n",
    "\n",
    "tempdata5=pd.concat([diabetic,prediabetic,normal])\n",
    "tempdata5.iloc[:, 3:-2]=scaler.transform(tempdata5.iloc[:, 3:-2])\n",
    "\n",
    "pred5 = rf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata5Rcolumns=tempdata5.iloc[:, 3:-2]\n",
    "tempdata5Rcolumns.columns=['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n",
    "pred5 = xgb_model.predict((tempdata5Rcolumns))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = SVC_clf.predict((tempdata5.iloc[:, 3:-2]))\n",
    "print(m.accuracy_score(tempdata5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(tempdata5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tempdata5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('_DiabeticClassifierModelForNextYear_rf_model', 'wb') as f:\n",
    "#     pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('_DiabeticClassifierModelForNextYear_scaler', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
