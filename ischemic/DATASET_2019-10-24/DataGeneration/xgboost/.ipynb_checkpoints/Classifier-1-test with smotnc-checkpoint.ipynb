{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %load_ext nb_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomseed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindata= pd.read_csv('../../DATASET_2019-10-24_light.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FIELD_1</th>\n",
       "      <th>FIELD_2</th>\n",
       "      <th>L100700</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L103300</th>\n",
       "      <th>L103100</th>\n",
       "      <th>L190900</th>\n",
       "      <th>L504700</th>\n",
       "      <th>L190300</th>\n",
       "      <th>L103000</th>\n",
       "      <th>FIELD_15</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>123111</td>\n",
       "      <td>20140729</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4.45</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>247895</td>\n",
       "      <td>20150729</td>\n",
       "      <td>6.1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.50</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>273354</td>\n",
       "      <td>20141111</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>273354</td>\n",
       "      <td>20151215</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.48</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>299264</td>\n",
       "      <td>20150729</td>\n",
       "      <td>6.9</td>\n",
       "      <td>29.4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>5.31</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  FIELD_1   FIELD_2  L100700  S000300  L101700  L103300  L103100  \\\n",
       "0           0   123111  20140729      4.2     18.9     13.0      2.3     75.0   \n",
       "1           1   247895  20150729      6.1     23.5     26.0      4.6     43.0   \n",
       "2           2   273354  20141111      4.1     18.6     29.0      2.1     89.0   \n",
       "3           3   273354  20151215      4.0     19.7     43.0      1.9    105.0   \n",
       "4           4   299264  20150729      6.9     29.4     87.0      6.1     35.0   \n",
       "\n",
       "   L190900  L504700  L190300  L103000  FIELD_15  FIELD_38  FIELD_33  SEX  \\\n",
       "0     13.0     0.86     4.45     64.0       0.0       2.0       1.0  1.0   \n",
       "1     12.7     0.60     4.50    114.0       0.0       1.0       3.0  0.0   \n",
       "2     12.9     1.00     4.51     76.0       0.0       3.0       3.0  1.0   \n",
       "3     13.6     0.70     4.48     34.0       0.0       5.0       3.0  1.0   \n",
       "4     13.1     2.90     5.31    242.0       0.0       1.0       1.0  0.0   \n",
       "\n",
       "    AGE  CLASS  \n",
       "0  25.0      1  \n",
       "1  29.0      1  \n",
       "2  29.0      1  \n",
       "3  30.0      1  \n",
       "4  30.0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"NextYearData_actualData_train.txt\")\n",
    "data2 = pd.read_csv(\"ThisYearData_actualData_train.txt\")\n",
    "data3 = pd.read_csv(\"ThisYearData_actualData_test.txt\")\n",
    "\n",
    "data4 = pd.read_csv(\"NextYearData_actualData_test.txt\")\n",
    "\n",
    "data5 = pd.read_csv(\"Predicted_NextYearData.txt\")\n",
    "\n",
    "data = pd.concat([data1, data2, data3])\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude test data from the main data\n",
    "tempdata= pd.merge(maindata,data4[['FIELD_1','FIELD_2']],  how='inner', \n",
    "                   left_on=['FIELD_1','FIELD_2'], right_on=['FIELD_1','FIELD_2'])\n",
    "maindata=maindata[~maindata['Unnamed: 0'].isin(tempdata[['Unnamed: 0']].values.ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS\n",
      "0    354541\n",
      "1      3017\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "maindata=maindata[['L100700','S000300','L101700','L103300','L190900','L504700',\n",
    "                   'L190300','FIELD_15','FIELD_38','FIELD_33','SEX','AGE','CLASS']].dropna()#,'L103000''L103100',\n",
    "\n",
    "print(maindata.groupby(by='CLASS').size())\n",
    "\n",
    "mydata=maindata.copy()\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(data.groupby(by='CLASS').size())\n",
    "# # maindata=data.copy()\n",
    "\n",
    "# class0=maindata[maindata.CLASS==0]\n",
    "# class1=maindata[maindata.CLASS==1]\n",
    "\n",
    "# class0=class0.sample(3*class1.shape[0],random_state=42)\n",
    "\n",
    "# data=pd.concat([class1,class0])\n",
    "\n",
    "# print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3017 354541\n",
      "CLASS\n",
      "0    8451\n",
      "1    2817\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class1 = mydata[mydata.CLASS == 1]\n",
    "class0 = mydata[mydata.CLASS == 0]\n",
    "\n",
    "print(class1.shape[0],class0.shape[0],)\n",
    "\n",
    "class1_test = class1.sample(200, random_state=42)\n",
    "class0_test = class0.sample(200, random_state=42)\n",
    "test = pd.concat([class1_test, class0_test])\n",
    "test=shuffle(test)\n",
    "\n",
    "\n",
    "class1_train = class1.drop(class1_test.index) #.sample( class2_train.shape[0], random_state=randomseed)\n",
    "class0_train = class0.drop(class0_test.index) .sample( 3*class1_train.shape[0], random_state=randomseed)\n",
    "\n",
    "train = pd.concat([class1_train, class0_train])\n",
    "train=shuffle(train, random_state=42)\n",
    "\n",
    "print(train.groupby('CLASS').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({0: 8451, 1: 8451})\n"
     ]
    }
   ],
   "source": [
    "# generate synthetic dataset to overcome class imbalance\n",
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "sm = SMOTENC(random_state=42, categorical_features=[2,9,10,11],k_neighbors=3,sampling_strategy = 1)\n",
    "X_res, y_res = sm.fit_resample(train.iloc[:,:-1],train.iloc[:,-1])\n",
    "print(\"Resampled dataset samples per class {}\".format(Counter(y_res)))\n",
    "\n",
    "train=pd.DataFrame(X_res,columns=list(train.columns[:-1]))\n",
    "train['CLASS']=y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, xtest, ytrain, ytest = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], random_state=42, test_size=0.3)\n",
    "\n",
    "xtrain=train.iloc[:,:-1]\n",
    "xtest=test.iloc[:,:-1] \n",
    "ytrain=train.iloc[:,-1]\n",
    "ytest=test.iloc[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=8,\n",
    ")\n",
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = rf.predict(xtest)\n",
    "\n",
    "score = rf.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=xtest.columns)\n",
    "feat_importances.nlargest(16).plot(kind=\"barh\")\n",
    "plt.show()\n",
    "\n",
    "print(feat_importances.nlargest(16).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(xtrain, ytrain)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(xtest, ytest)))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, ypred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "xgb_model.fit(xtrain, ytrain)\n",
    "\n",
    "y_pred = xgb_model.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, y_pred))\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(ytest, y_pred))\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=data4[['L100700','S000300','L101700','L103300','L190900','L504700',\n",
    "                   'L190300','FIELD_15','FIELD_38','FIELD_33','SEX','AGE','CLASS']]\n",
    "\n",
    "pred4 = rf.predict((data4.iloc[:, :-1]))\n",
    "\n",
    "print(m.accuracy_score(data4.iloc[:, -1], pred4))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(data4.iloc[:, -1], pred4))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(data4.iloc[:, -1], pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# =====================================\n",
    "# =====================================\n",
    "# =====================================\n",
    "\n",
    "data5=data5[['P_L100700','P_S000300','P_L101700','P_L103300','P_L190900','P_L504700','P_L190300',#'P_L103000','P_L103100'\n",
    "             'P_FIELD_15','P_FIELD_38','P_FIELD_33','P_SEX','P_AGE','CLASS']]\n",
    "data5.columns=data4.columns\n",
    "pred5 = rf.predict((data5.iloc[:, :-1]))\n",
    "\n",
    "\n",
    "\n",
    "print(m.accuracy_score(data5.iloc[:, -1], pred5))\n",
    "\n",
    "confmatrx = pd.DataFrame(m.confusion_matrix(data5.iloc[:, -1], pred5))\n",
    "confmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(data5.iloc[:, -1], pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
