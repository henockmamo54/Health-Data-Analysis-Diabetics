{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159381, 13)\n",
      "(159381, 2)\n"
     ]
    }
   ],
   "source": [
    "x_original=pd.read_csv('../../_xlable4_withNa_AllColumns.txt')\n",
    "y_original=pd.read_csv('../../_targelable4_withNa_AllColumns.txt')\n",
    " \n",
    "x_original['max']=np.min(x_original[['FIELD_6','FIELD_7']],axis=1)\n",
    "x_original=x_original.drop(columns=['FIELD_6','FIELD_7'])\n",
    "\n",
    "\n",
    "x_original=x_original[['Unnamed: 0','L101600', 'max', 'L103300', 'L103100', 'L101700', 'S000300', \n",
    "                       'L190300', 'L100700', 'L103000', 'S000501', 'L101300', 'FIELD_4']]\n",
    "\n",
    "y_original=y_original[['Unnamed: 0','L101600']]\n",
    "\n",
    "\n",
    "print(x_original.shape)\n",
    "print(y_original.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 159381\n",
      "L101600 152251\n",
      "max 58375\n",
      "L103300 135222\n",
      "L103100 158880\n",
      "L101700 158951\n",
      "S000300 159075\n",
      "L190300 159204\n",
      "L100700 152474\n",
      "L103000 158939\n",
      "S000501 159305\n",
      "L101300 159247\n",
      "FIELD_4 156956\n"
     ]
    }
   ],
   "source": [
    "for index,col in enumerate(x_original.columns):\n",
    "    print(col,x_original[col].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48844, 15)\n"
     ]
    }
   ],
   "source": [
    "data= pd.merge(x_original,y_original, how='inner',left_on='Unnamed: 0', right_on='Unnamed: 0')\n",
    "data=data.dropna(). reset_index()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48844, 15)\n",
      "Index(['index', 'Unnamed: 0', 'L101600_x', 'max', 'L103300', 'L103100',\n",
      "       'L101700', 'S000300', 'L190300', 'L100700', 'L103000', 'S000501',\n",
      "       'L101300', 'FIELD_4', 'L101600_y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>L101600_x</th>\n",
       "      <th>max</th>\n",
       "      <th>L103300</th>\n",
       "      <th>L103100</th>\n",
       "      <th>L101700</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L190300</th>\n",
       "      <th>L100700</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000501</th>\n",
       "      <th>L101300</th>\n",
       "      <th>FIELD_4</th>\n",
       "      <th>L101600_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  L101600_x  max  L103300  L103100  L101700  S000300  \\\n",
       "0      0           0       49.0  1.0      3.1     68.0     13.0     20.1   \n",
       "1      1           1       51.0  1.0      3.3     71.0     14.0     19.7   \n",
       "2      2           2       56.0  1.0      3.4     72.0     15.0     20.2   \n",
       "3      3           3       42.0  1.0      2.8     64.0     10.0     24.8   \n",
       "4      4           4       46.0  2.0      2.9     58.0     12.0     25.5   \n",
       "\n",
       "   L190300  L100700  L103000  S000501  L101300  FIELD_4  L101600_y  \n",
       "0     4.20      3.0     53.0    121.0      8.0      3.0       51.0  \n",
       "1     4.24      3.0     53.0    117.0      9.0      3.0       56.0  \n",
       "2     4.26      3.8     41.0    135.0     10.0      3.0       62.0  \n",
       "3     4.20      3.7     58.0    118.0     12.0      2.0       46.0  \n",
       "4     3.92      3.4     50.0    111.0     12.0      2.0       55.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=data[['L101600_x', 'max', 'L103300', 'L103100', 'L101700', 'S000300', \n",
    "                       'L190300', 'L100700', 'L103000', 'S000501', 'L101300', 'FIELD_4']]\n",
    "\n",
    "y=data[['L101600_y' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the correlation of the selected feature with the independent variables\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppd=pd.DataFrame(x.copy())\n",
    "temppd['y']=y.L101600_y\n",
    "temppd.head()\n",
    "corval=abs(temppd.corr()).sort_values(by='y', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y            1.000000\n",
       "L101600_x    0.736453\n",
       "max          0.380921\n",
       "L103300      0.249968\n",
       "L101700      0.222205\n",
       "S000300      0.219803\n",
       "S000501      0.215750\n",
       "L103000      0.195353\n",
       "L101300      0.158680\n",
       "L103100      0.132132\n",
       "L190300      0.115414\n",
       "FIELD_4      0.112000\n",
       "L100700      0.094371\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corval.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram plot of the features\n",
    "# import matplotlib.pyplot as plt\n",
    "# x[x.dtypes[(x.dtypes==\"float64\")|(x.dtypes==\"int64\")]\n",
    "#                         .index.values].hist(figsize=[11,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=8)\n",
    "# pca.fit(x)\n",
    "\n",
    "# print(pca.explained_variance_ratio_)   \n",
    "# print(np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# x=pca.fit_transform(x) \n",
    "# print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()  #StandardScaler()\n",
    "# x = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustring test\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# K = range(1,10)\n",
    "# distortions = []\n",
    "\n",
    "# for k in K:\n",
    "#     kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "#     kmeanModel.fit(x)\n",
    "#     distortions.append(sum(np.min(cdist(x, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / x.shape[0])\n",
    "\n",
    "# # Plot the elbow\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "# x['lbl']=kmeanModel.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylable=y[['L101600_y']]  \n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x, ylable, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=7, random_state=0,verbose =0,n_estimators=500)\n",
    "regr.fit(xtrain, ytrain) \n",
    "print(regr.feature_importances_)\n",
    "ypred=regr.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(30)\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempdata=pd.DataFrame(xtest.copy())\n",
    "# tempdata['ytest']=ytest\n",
    "# # temp=temp.dropna()\n",
    "# # tempdata.head()\n",
    "# # tempdata[tempdata.ytest.isna()].index\n",
    "\n",
    "# tempdata=tempdata.drop(tempdata[tempdata.ytest.isna()].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg boost\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor()\n",
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, \n",
    "#                           learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred = xg_reg.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "# ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "# ypredPD['t + 1']=ytest.values\n",
    "# ypredPD['pred (t +1)']=ypred\n",
    "# ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytest[ytest.isna()].shape\n",
    "# tempdata.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(input_dim=34,units=128,activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=128, activation='relu', kernel_initializer='uniform')) \n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=64, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=32, activation='relu', kernel_initializer='uniform')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))  \n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform'))\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam', metrics=['mean_squared_error' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h=model.fit(xtrain, ytrain, validation_split=.2,epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(xtest)\n",
    "\n",
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=h\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredPD['diff']=abs(ypredPD['t + 1']- ypredPD['pred (t +1)'])\n",
    "print(np.mean(ypredPD['diff']))\n",
    "print(np.std(ypredPD['diff']))\n",
    "print(100*ypredPD[ypredPD['diff']<=5].shape[0]/ypredPD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('index')\n",
    "red_patch = mpatches.Patch(color='red', label='Actual data')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted data')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "\n",
    "ypredPD=ypredPD.sort_values(by=['t + 1'])\n",
    "plt.scatter(np.arange(0,ypredPD.shape[0],1),ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "plt.plot(np.arange(0,ypredPD.shape[0],1),ypredPD['t + 1'][:ypredPD.shape[0]],color='red')\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel('p*(t+1), Predicted data')\n",
    "plt.xlabel('p(t+1), Actual data')\n",
    "plt.scatter(ypredPD['t + 1'][:ypredPD.shape[0]],ypredPD['pred (t +1)'][:ypredPD.shape[0]])\n",
    "\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# svr_rbf = SVR(kernel='rbf', C=10, gamma=0.02, epsilon=.001)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=svr_rbf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print('mean_squared_error',mean_squared_error(ytest, ypred))\n",
    "print('root mean_squared_error',math.sqrt(mean_squared_error(ytest, ypred)))\n",
    "print('mean_absolute_error',mean_absolute_error(ytest, ypred))\n",
    "print('r2_score',r2_score(ytest, ypred))\n",
    "\n",
    "ypredPD=pd.DataFrame()\n",
    "# ypredPD['t']=xtest['S000501_x'].values\n",
    "ypredPD['t + 1']=ytest.values.ravel()\n",
    "ypredPD['pred (t +1)']=ypred\n",
    "ypredPD.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
