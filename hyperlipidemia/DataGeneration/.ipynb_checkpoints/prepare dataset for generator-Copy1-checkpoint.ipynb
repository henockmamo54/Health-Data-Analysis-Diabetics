{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics as m\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=['L100700', 'SEX', 'S000300', 'L103000', 'L103100', 'L103300',\n",
    "       'S000501', 'S000100', 'L101300', 'L190300', 'L100500', 'L101700',\n",
    "      \n",
    "      'S000300', 'SEX', 'L103300', 'S000501', \n",
    "                       'L103100', 'L101300', 'S000502', 'L190300', 'L190400', 'L100700', 'L103000', 'L100800'\n",
    "      \n",
    "      'L101700', 'SEX', 'L101300', 'FIELD_38', 'S000300', 'L101200', \n",
    "                       'L100700', 'L190400', 'L103000', 'L103300', 'L190300', 'L100800',\n",
    "      \n",
    "      'L100800', 'L104600', 'SEX', 'AGE', 'L101300', 'S000300', \n",
    "                       'L103000', 'L103300', 'S000501', 'S000502', 'L101700', 'FIELD_38',\n",
    "      \n",
    "      'L103300', 'L103100', 'L103000', 'L103200', 'S000300', 'L102900', 'SEX', \n",
    "                       'L100700', 'L190300', 'L190400', 'L190500', 'L100500',\n",
    "      \n",
    "      'L103100', 'L103300', 'SEX', 'S000300', 'L103000', 'L190300', \n",
    "        'L100700', 'L190400', 'L190500', 'L100500', 'S000100', 'L101300',\n",
    "      \n",
    "      'L102900', 'L103000', 'L103200','L104600', 'L100700',\n",
    "       'S000501', 'S000300', 'L103300', 'L100800', 'L101700', 'AGE','FIELD_4',\n",
    "      \n",
    "      'L103200', 'L102900', 'L103100', 'L100700', 'S000501',\n",
    "       'L190300', 'L104600', 'S000300', 'L103300', 'AGE', 'FIELD_41','FIELD_4',\n",
    "      \n",
    "      \n",
    "      'L102900', 'L103000', 'L103200' \n",
    "     \n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE' 'FIELD_1' 'FIELD_15' 'FIELD_16' 'FIELD_17' 'FIELD_2' 'FIELD_22'\n",
      " 'FIELD_23' 'FIELD_24' 'FIELD_33' 'FIELD_38' 'FIELD_40' 'L100500'\n",
      " 'L100700' 'L100800' 'L101200' 'L101300' 'L101700' 'L102900' 'L103000'\n",
      " 'L103100' 'L103200' 'L103300' 'L104600' 'L190300' 'L190400' 'L190500'\n",
      " 'S000100' 'S000300' 'S000501' 'S000502' 'SEX']\n"
     ]
    }
   ],
   "source": [
    "# collected form each main diabetic indicator features regressors\n",
    "cols = np.unique(\n",
    "    [\n",
    "        'L100700', 'SEX', 'S000300', 'L103000', 'L103100', 'L103300',  \n",
    "       'S000501', 'S000100', 'L101300', 'L190300', 'L100500', 'L101700',\n",
    "      \n",
    "      'S000300', 'SEX', 'L103300', 'S000501',  \n",
    "                       'L103100', 'L101300', 'S000502', 'L190300', 'L190400', 'L100700', 'L103000', 'L100800',\n",
    "      \n",
    "      'L101700', 'SEX', 'L101300', 'FIELD_38', 'S000300', 'L101200', \n",
    "                       'L100700', 'L190400', 'L103000', 'L103300', 'L190300', 'L100800',\n",
    "      \n",
    "      'L100800', 'L104600', 'SEX', 'AGE', 'L101300', 'S000300', \n",
    "                       'L103000', 'L103300', 'S000501', 'S000502', 'L101700', 'FIELD_38',\n",
    "        \n",
    "        'L103300', 'L103100', 'L103000', 'L103200', 'S000300', 'L102900', 'SEX', \n",
    "                       'L100700', 'L190300', 'L190400', 'L190500', 'L100500',\n",
    "        \n",
    "        'L103100', 'L103300', 'SEX', 'S000300', 'L103000', 'L190300', \n",
    "        'L100700', 'L190400', 'L190500', 'L100500', 'S000100', 'L101300',\n",
    "        \n",
    "#         'L102900', 'L103000', 'L103200','L104600', 'L100700',\n",
    "#        'S000501', 'S000300', 'L103300', 'L100800', 'L101700', 'AGE','FIELD_4',\n",
    "                \n",
    "#       'L103200', 'L102900', 'L103100', 'L100700', 'S000501',\n",
    "#        'L190300', 'L104600', 'S000300', 'L103300', 'AGE', 'FIELD_41','FIELD_4',\n",
    "      \n",
    "        'FIELD_16','FIELD_23','FIELD_15','FIELD_22','FIELD_17','FIELD_24','FIELD_33','FIELD_40','FIELD_1','FIELD_2',\n",
    "        \n",
    "        'L102900', 'L103000', 'L103200' \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcols=[]\n",
    "ycols=[]\n",
    "allxycols=[]\n",
    "\n",
    "for i in cols:\n",
    "    xcols.append (i+'_x')\n",
    "    ycols.append (i+'_y')\n",
    "    \n",
    "    allxycols.append (i+'_x')\n",
    "    allxycols.append (i+'_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Dataset\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original=pd.read_csv('../../_xlable4_withNa_AllColumns.txt')\n",
    "y_original=pd.read_csv('../../_targelable4_withNa_AllColumns.txt')\n",
    "\n",
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38877, 64)\n"
     ]
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16_x != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23_x != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15_x != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22_x != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17_x != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24_x != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "\n",
    "data = data[allxycols].dropna()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[xcols]\n",
    "y = data[ycols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Regression Models\n",
    "=========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L100700_x # Uric Acid\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.7495283164438555\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    max_depth=10, random_state=random_seed, verbose=0, n_estimators=500, max_features=8\n",
    ")\n",
    "regr.fit(\n",
    "    xtrain[\n",
    "        [\n",
    "            'L100700_x', 'SEX_x', 'S000300_x', 'L103000_x', 'L103100_x', 'L103300_x',\n",
    "       'S000501_x', 'S000100_x', 'L101300_x', 'L190300_x', 'L100500_x', 'L101700_x'\n",
    "        ]\n",
    "    ],\n",
    "    ytrain[[\"L100700_y\"]],\n",
    ")\n",
    "\n",
    "ypred = regr.predict(\n",
    "    xtest[\n",
    "        [\n",
    "            'L100700_x', 'SEX_x', 'S000300_x', 'L103000_x', 'L103100_x', 'L103300_x',\n",
    "       'S000501_x', 'S000100_x', 'L101300_x', 'L190300_x', 'L100500_x', 'L101700_x'\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"r2_score\", m.r2_score(ytest[[\"L100700_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11664,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_L100700 = ypred\n",
    "pred_L100700.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S000300 #BMI\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.8063549250250258\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    max_depth=10, random_state=random_seed, verbose=0, n_estimators=500, max_features=4\n",
    ")\n",
    "regr.fit(\n",
    "    xtrain[\n",
    "        [            \n",
    "      'S000300_x', 'SEX_x', 'L103300_x', 'S000501_x','L103100_x', 'L101300_x', 'S000502_x', \n",
    "            'L190300_x', 'L190400_x', 'L100700_x', 'L103000_x', 'L100800_x',\n",
    "        ]\n",
    "    ],\n",
    "    ytrain[[\"S000300_y\"]],\n",
    ")\n",
    "\n",
    "ypred = regr.predict(\n",
    "    xtest[\n",
    "        [\n",
    "            'S000300_x', 'SEX_x', 'L103300_x', 'S000501_x','L103100_x', 'L101300_x', 'S000502_x', \n",
    "            'L190300_x', 'L190400_x', 'L100700_x', 'L103000_x', 'L100800_x',\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"r2_score\", m.r2_score(ytest[[\"S000300_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_S000300 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L101700 # r-GTP gamma\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.6532186558739068\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    max_depth=8, random_state=random_seed, verbose=0, n_estimators=1000\n",
    ")\n",
    "regr.fit(\n",
    "    xtrain[\n",
    "        ['L101700_x', 'SEX_x', 'L101300_x', 'FIELD_38_x', 'S000300_x', 'L101200_x', \n",
    "        'L100700_x', 'L190400_x', 'L103000_x', 'L103300_x', 'L190300_x', 'L100800_x',\n",
    "        ]\n",
    "    ],\n",
    "    ytrain[[\"L101700_y\"]],\n",
    ")\n",
    "\n",
    "ypred = regr.predict(\n",
    "    xtest[\n",
    "        ['L101700_x', 'SEX_x', 'L101300_x', 'FIELD_38_x', 'S000300_x', 'L101200_x', \n",
    "        'L100700_x', 'L190400_x', 'L103000_x', 'L103300_x', 'L190300_x', 'L100800_x',\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"r2_score\", m.r2_score(ytest[[\"L101700_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_L101700 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L100800 # fasting glucose level\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.5110169860008122\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    max_depth=10, random_state=random_seed, verbose=0, n_estimators=1000, max_features=6\n",
    ")\n",
    "regr.fit(\n",
    "    xtrain[\n",
    "        [\n",
    "           'L100800_x', 'L104600_x', 'SEX_x', 'AGE_x', 'L101300_x', 'S000300_x', \n",
    "                       'L103000_x', 'L103300_x', 'S000501_x', 'S000502_x', 'L101700_x', 'FIELD_38_x',\n",
    "        ]\n",
    "    ],\n",
    "    ytrain[[\"L100800_y\"]],\n",
    ")\n",
    "\n",
    "ypred = regr.predict(\n",
    "    xtest[\n",
    "        [\n",
    "            'L100800_x', 'L104600_x', 'SEX_x', 'AGE_x', 'L101300_x', 'S000300_x', \n",
    "                       'L103000_x', 'L103300_x', 'S000501_x', 'S000502_x', 'L101700_x', 'FIELD_38_x',\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"r2_score\", m.r2_score(ytest[[\"L100800_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_L100800 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1033 # Cardiac risk factor\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.6922451953919426\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    max_depth=10, random_state=random_seed, verbose=0, n_estimators=1000, max_features=7\n",
    ")\n",
    "regr.fit(\n",
    "    xtrain[\n",
    "        [\n",
    "           'L103300_x', 'L103100_x', 'L103000_x', 'L103200_x', 'S000300_x', 'L102900_x', 'SEX_x', \n",
    "                       'L100700_x', 'L190300_x', 'L190400_x', 'L190500_x', 'L100500_x'\n",
    "        ]\n",
    "    ],\n",
    "    ytrain[[\"L103300_y\"]],\n",
    ")\n",
    "\n",
    "ypred = regr.predict(\n",
    "    xtest[\n",
    "        [\n",
    "            'L103300_x', 'L103100_x', 'L103000_x', 'L103200_x', 'S000300_x', 'L102900_x', 'SEX_x', \n",
    "                       'L100700_x', 'L190300_x', 'L190400_x', 'L190500_x', 'L100500_x'\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"r2_score\", m.r2_score(ytest[[\"L103300_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_L103300 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "103100 # HDL\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.6269254364268014\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    max_depth=10, random_state=random_seed, verbose=0, n_estimators=1000, max_features=7\n",
    ")\n",
    "regr.fit(\n",
    "    xtrain[\n",
    "        [\n",
    "           'L103100_x', 'L103300_x', 'SEX_x', 'S000300_x', 'L103000_x', 'L190300_x', \n",
    "        'L100700_x', 'L190400_x', 'L190500_x', 'L100500_x', 'S000100_x', 'L101300_x'\n",
    "        ]\n",
    "    ],\n",
    "    ytrain[[\"L103100_y\"]],\n",
    ")\n",
    "\n",
    "ypred = regr.predict(\n",
    "    xtest[\n",
    "        [\n",
    "           'L103100_x', 'L103300_x', 'SEX_x', 'S000300_x', 'L103000_x', 'L190300_x', \n",
    "        'L100700_x', 'L190400_x', 'L190500_x', 'L100500_x', 'S000100_x', 'L101300_x'\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"r2_score\", m.r2_score(ytest[[\"L103100_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_L103100 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "102900 # total cholestrol\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr = RandomForestRegressor(\n",
    "#     max_depth=10, random_state=random_seed, verbose=0, n_estimators=1000, max_features=7\n",
    "# )\n",
    "# regr.fit(\n",
    "#     xtrain[\n",
    "#         [\n",
    "#            'L102900_x', 'L103000_x', 'L103200_x','L104600_x', 'L100700_x',\n",
    "#        'S000501_x', 'S000300_x', 'L103300_x', 'L100800_x', 'L101700_x', 'AGE_x','FIELD_4_x'\n",
    "#         ]\n",
    "#     ],\n",
    "#     ytrain[[\"L103100_y\"]],\n",
    "# )\n",
    "\n",
    "# ypred = regr.predict(\n",
    "#     xtest[\n",
    "#         [\n",
    "#            'L102900_x', 'L103000_x', 'L103200_x','L104600_x', 'L100700_x',\n",
    "#        'S000501_x', 'S000300_x', 'L103300_x', 'L100800_x', 'L101700_x', 'AGE_x','FIELD_4_x'\n",
    "#         ]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(\"r2_score\", m.r2_score(ytest[[\"L103100_y\"]], ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_L102900 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1032 # LDL\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr = RandomForestRegressor(\n",
    "#     max_depth=10, random_state=random_seed, verbose=0, n_estimators=1000, max_features=7\n",
    "# )\n",
    "# regr.fit(\n",
    "#     xtrain[\n",
    "#         [\n",
    "#            'L103200_x', 'L102900_x',  'L103100_x', 'L100700_x', 'S000501_x',\n",
    "#        'L190300_x', 'L104600_x', 'S000300_x', 'L103300_x', 'AGE_x', 'FIELD_41_x','FIELD_4_x'\n",
    "#         ]\n",
    "#     ],\n",
    "#     ytrain[[\"L103200_y\"]],\n",
    "# )\n",
    "\n",
    "# ypred = regr.predict(\n",
    "#     xtest[\n",
    "#         [\n",
    "#            'L103200_x', 'L102900_x',  'L103100_x', 'L100700_x', 'S000501_x',\n",
    "#        'L190300_x', 'L104600_x', 'S000300_x', 'L103300_x', 'AGE_x', 'FIELD_41_x','FIELD_4_x'\n",
    "#         ]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(\"r2_score\", m.r2_score(ytest[[\"L103200_y\"]], ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_L103200 = ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical values\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_FIELD_33 = ytest.FIELD_33_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_FIELD_38 = ytest.FIELD_38_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_FIELD_40 = ytest.FIELD_40_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_SEX = ytest.SEX_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_AGE = ytest.AGE_y + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the predicted values to make dataframe\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_FIELD_1</th>\n",
       "      <th>P_FIELD_2</th>\n",
       "      <th>P_L100700</th>\n",
       "      <th>P_S000300</th>\n",
       "      <th>P_L101700</th>\n",
       "      <th>P_L100800</th>\n",
       "      <th>P_L103300</th>\n",
       "      <th>P_L103100</th>\n",
       "      <th>P_FIELD_33</th>\n",
       "      <th>P_FIELD_38</th>\n",
       "      <th>P_FIELD_40</th>\n",
       "      <th>P_SEX</th>\n",
       "      <th>P_AGE</th>\n",
       "      <th>A_L102900</th>\n",
       "      <th>A_L103200</th>\n",
       "      <th>A_L103000</th>\n",
       "      <th>A_L103300</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1071928</td>\n",
       "      <td>20141120</td>\n",
       "      <td>6.320051</td>\n",
       "      <td>25.232440</td>\n",
       "      <td>62.670661</td>\n",
       "      <td>96.016331</td>\n",
       "      <td>4.715410</td>\n",
       "      <td>49.074521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>938071</td>\n",
       "      <td>20140528</td>\n",
       "      <td>5.587522</td>\n",
       "      <td>25.297303</td>\n",
       "      <td>45.286098</td>\n",
       "      <td>106.422303</td>\n",
       "      <td>3.487461</td>\n",
       "      <td>55.345414</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2686302</td>\n",
       "      <td>20151031</td>\n",
       "      <td>6.051631</td>\n",
       "      <td>24.564815</td>\n",
       "      <td>45.092373</td>\n",
       "      <td>97.162257</td>\n",
       "      <td>4.835118</td>\n",
       "      <td>42.209086</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>840189</td>\n",
       "      <td>20150706</td>\n",
       "      <td>6.890798</td>\n",
       "      <td>25.934557</td>\n",
       "      <td>25.726559</td>\n",
       "      <td>105.361735</td>\n",
       "      <td>5.450269</td>\n",
       "      <td>39.816235</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1254540</td>\n",
       "      <td>20140718</td>\n",
       "      <td>4.582151</td>\n",
       "      <td>24.858771</td>\n",
       "      <td>57.534269</td>\n",
       "      <td>108.641355</td>\n",
       "      <td>4.917339</td>\n",
       "      <td>39.164730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_FIELD_1  P_FIELD_2  P_L100700  P_S000300  P_L101700   P_L100800  \\\n",
       "0    1071928   20141120   6.320051  25.232440  62.670661   96.016331   \n",
       "1     938071   20140528   5.587522  25.297303  45.286098  106.422303   \n",
       "2    2686302   20151031   6.051631  24.564815  45.092373   97.162257   \n",
       "3     840189   20150706   6.890798  25.934557  25.726559  105.361735   \n",
       "4    1254540   20140718   4.582151  24.858771  57.534269  108.641355   \n",
       "\n",
       "   P_L103300  P_L103100  P_FIELD_33  P_FIELD_38  P_FIELD_40  P_SEX  P_AGE  \\\n",
       "0   4.715410  49.074521         1.0         1.0         1.0    1.0   51.0   \n",
       "1   3.487461  55.345414         2.0         2.0         0.0    0.0   46.0   \n",
       "2   4.835118  42.209086         3.0         2.0         1.0    0.0   36.0   \n",
       "3   5.450269  39.816235         2.0         1.0         0.0    0.0   44.0   \n",
       "4   4.917339  39.164730         1.0         1.0         1.0    0.0   66.0   \n",
       "\n",
       "   A_L102900  A_L103200  A_L103000  A_L103300  CLASS  \n",
       "0      253.0      178.0       86.0        4.4      1  \n",
       "1      140.0       89.0       51.0        3.4      0  \n",
       "2      227.0      145.0      190.0        5.2      1  \n",
       "3      189.0       98.0      281.0        5.4      1  \n",
       "4      186.0      131.0       95.0        5.2      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NextYearData = pd.DataFrame()\n",
    "NextYearData[\"P_FIELD_1\"] = ytest.FIELD_1_y.values\n",
    "NextYearData[\"P_FIELD_2\"] = ytest.FIELD_2_y.values\n",
    "\n",
    "NextYearData[\"P_L100700\"] = pred_L100700\n",
    "NextYearData[\"P_S000300\"] = pred_S000300\n",
    "NextYearData[\"P_L101700\"] = pred_L101700\n",
    "NextYearData[\"P_L100800\"] = pred_L100800\n",
    "NextYearData[\"P_L103300\"] = pred_L103300\n",
    "NextYearData[\"P_L103100\"] = pred_L103100\n",
    "# NextYearData[\"P_L102900\"] = pred_L102900\n",
    "# NextYearData[\"P_L103200\"] = pred_L103200\n",
    "\n",
    "NextYearData[\"P_FIELD_33\"] = pred_FIELD_33.values\n",
    "NextYearData[\"P_FIELD_38\"] = pred_FIELD_38.values\n",
    "NextYearData[\"P_FIELD_40\"] = pred_FIELD_40.values\n",
    "\n",
    "NextYearData[\"P_SEX\"] = pred_SEX.values\n",
    "NextYearData[\"P_AGE\"] = pred_AGE.values\n",
    "\n",
    "NextYearData[\"A_L102900\"] = ytest.L102900_y.values\n",
    "NextYearData[\"A_L103200\"] = ytest.L103200_y.values\n",
    "NextYearData[\"A_L103000\"] = ytest.L103000_y.values\n",
    "NextYearData[\"A_L103300\"] = ytest.L103300_y.values\n",
    "\n",
    "_class = []\n",
    "for i in range(NextYearData.shape[0]):\n",
    "    if((NextYearData.A_L102900[i] <= 200) & (NextYearData.A_L103200[i] <= 130) & (NextYearData.A_L103000[i] <=150)):\n",
    "        _class.append(0)\n",
    "    else:\n",
    "        _class.append(1)\n",
    "NextYearData[\"CLASS\"] = _class\n",
    "\n",
    "NextYearData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NextYearData.to_csv(\"Predicted_NextYearData.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the actual next year values\n",
    "\n",
    "NextYearData_actualData = pd.DataFrame()\n",
    "NextYearData_actualData[\"FIELD_1\"] = ytest.FIELD_1_y.values\n",
    "NextYearData_actualData[\"FIELD_2\"] = ytest.FIELD_2_y.values\n",
    "NextYearData_actualData[\"L100700\"] = ytest.L100700_y.values\n",
    "NextYearData_actualData[\"S000300\"] = ytest.S000300_y.values\n",
    "NextYearData_actualData[\"L101700\"] = ytest.L101700_y.values\n",
    "NextYearData_actualData[\"L100800\"] = ytest.L100800_y.values\n",
    "NextYearData_actualData[\"L103300\"] = ytest.L103300_y.values \n",
    "\n",
    "NextYearData_actualData[\"L103100\"] = ytest.L103100_y.values \n",
    "# NextYearData_actualData[\"L102900\"] = ytest.L102900_y.values\n",
    "# NextYearData_actualData[\"L103200\"] = ytest.L103200_y.values \n",
    "\n",
    "NextYearData_actualData[\"FIELD_33\"] = ytest.FIELD_33_y.values\n",
    "NextYearData_actualData[\"FIELD_38\"] = ytest.FIELD_38_y.values\n",
    "NextYearData_actualData[\"FIELD_40\"] = ytest.FIELD_40_y.values\n",
    "NextYearData_actualData[\"SEX\"] = ytest.SEX_y.values\n",
    "NextYearData_actualData[\"AGE\"] = ytest.AGE_y.values\n",
    "\n",
    "NextYearData_actualData[\"L102900\"] = ytest.L102900_y.values\n",
    "NextYearData_actualData[\"L103200\"] = ytest.L103200_y.values\n",
    "NextYearData_actualData[\"L103000\"] = ytest.L103000_y.values\n",
    "NextYearData_actualData[\"L103300\"] = ytest.L103300_y.values\n",
    "\n",
    "_class = []\n",
    "for i in range(NextYearData_actualData.shape[0]):\n",
    "    if((NextYearData_actualData.L102900[i] <= 200) & \n",
    "       (NextYearData_actualData.L103200[i] <= 130) & \n",
    "       (NextYearData_actualData.L103000[i] <=150)):\n",
    "        _class.append(0)\n",
    "    else:\n",
    "        _class.append(1)\n",
    "NextYearData_actualData[\"CLASS\"] = _class\n",
    " \n",
    "\n",
    "NextYearData_actualData.to_csv(\"NextYearData_actualData_test.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the actual this year values\n",
    "\n",
    "ThisYearData_actualData = pd.DataFrame()\n",
    "ThisYearData_actualData[\"FIELD_1\"] = xtest.FIELD_1_x.values\n",
    "ThisYearData_actualData[\"FIELD_2\"] = xtest.FIELD_2_x.values\n",
    "ThisYearData_actualData[\"L100700\"] = xtest.L100700_x.values\n",
    "ThisYearData_actualData[\"S000300\"] = xtest.S000300_x.values\n",
    "ThisYearData_actualData[\"L101700\"] = xtest.L101700_x.values\n",
    "ThisYearData_actualData[\"L100800\"] = xtest.L100800_x.values\n",
    "ThisYearData_actualData[\"L103300\"] = xtest.L103300_x.values\n",
    "\n",
    "ThisYearData_actualData[\"L103100\"] = xtest.L103100_x.values\n",
    "# ThisYearData_actualData[\"L102900\"] = xtest.L102900_x.values\n",
    "# ThisYearData_actualData[\"L103200\"] = xtest.L103200_x.values\n",
    "\n",
    "ThisYearData_actualData[\"FIELD_33\"] = xtest.FIELD_33_x.values\n",
    "ThisYearData_actualData[\"FIELD_38\"] = xtest.FIELD_38_x.values\n",
    "ThisYearData_actualData[\"FIELD_40\"] = xtest.FIELD_40_x.values\n",
    "ThisYearData_actualData[\"SEX\"] = xtest.SEX_x.values\n",
    "ThisYearData_actualData[\"AGE\"] = xtest.AGE_x.values \n",
    "\n",
    "\n",
    "ThisYearData_actualData[\"L102900\"] = xtest.L102900_x.values\n",
    "ThisYearData_actualData[\"L103200\"] = xtest.L103200_x.values\n",
    "ThisYearData_actualData[\"L103000\"] = xtest.L103000_x.values\n",
    "ThisYearData_actualData[\"L103300\"] = xtest.L103300_x.values\n",
    "\n",
    "_class = []\n",
    "for i in range(ThisYearData_actualData.shape[0]):\n",
    "    if((ThisYearData_actualData.L102900[i] <= 200) & \n",
    "       (ThisYearData_actualData.L103200[i] <= 130) & \n",
    "       (ThisYearData_actualData.L103000[i] <=150)):\n",
    "        _class.append(0)\n",
    "    else:\n",
    "        _class.append(1)\n",
    "ThisYearData_actualData[\"CLASS\"] = _class\n",
    "\n",
    "ThisYearData_actualData.to_csv(\"ThisYearData_actualData_test.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the actual next year values train\n",
    "\n",
    "NextYearData_actualData_train = pd.DataFrame()\n",
    "NextYearData_actualData_train[\"FIELD_1\"] = ytrain.FIELD_1_y.values\n",
    "NextYearData_actualData_train[\"FIELD_2\"] = ytrain.FIELD_2_y.values\n",
    "NextYearData_actualData_train[\"L100700\"] = ytrain.L100700_y.values\n",
    "NextYearData_actualData_train[\"S000300\"] = ytrain.S000300_y.values\n",
    "NextYearData_actualData_train[\"L101700\"] = ytrain.L101700_y.values\n",
    "NextYearData_actualData_train[\"L100800\"] = ytrain.L100800_y.values\n",
    "NextYearData_actualData_train[\"L103300\"] = ytrain.L103300_y.values \n",
    "\n",
    "NextYearData_actualData_train[\"L103100\"] = ytrain.L103100_y.values \n",
    "# NextYearData_actualData_train[\"L102900\"] = ytrain.L102900_y.values\n",
    "# NextYearData_actualData_train[\"L103200\"] = ytrain.L103200_y.values \n",
    "\n",
    "\n",
    "NextYearData_actualData_train[\"FIELD_33\"] = ytrain.FIELD_33_y.values\n",
    "NextYearData_actualData_train[\"FIELD_38\"] = ytrain.FIELD_38_y.values\n",
    "NextYearData_actualData_train[\"FIELD_40\"] = ytrain.FIELD_40_y.values\n",
    "NextYearData_actualData_train[\"SEX\"] = ytrain.SEX_y.values\n",
    "NextYearData_actualData_train[\"AGE\"] = ytrain.AGE_y.values\n",
    "\n",
    "\n",
    "NextYearData_actualData_train[\"L102900\"] = ytrain.L102900_y.values\n",
    "NextYearData_actualData_train[\"L103200\"] = ytrain.L103200_y.values\n",
    "NextYearData_actualData_train[\"L103000\"] = ytrain.L103000_y.values\n",
    "NextYearData_actualData_train[\"L103300\"] = ytrain.L103300_y.values\n",
    "\n",
    "_class = []\n",
    "for i in range(NextYearData_actualData_train.shape[0]):\n",
    "    if((NextYearData_actualData_train.L102900[i] <= 200) & \n",
    "       (NextYearData_actualData_train.L103200[i] <= 130) & \n",
    "       (NextYearData_actualData_train.L103000[i] <=150)):\n",
    "        _class.append(0)\n",
    "    else:\n",
    "        _class.append(1)\n",
    "NextYearData_actualData_train[\"CLASS\"] = _class \n",
    "\n",
    "NextYearData_actualData_train.to_csv(\"NextYearData_actualData_train.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the actual this year values train\n",
    "\n",
    "ThisYearData_actualData_train = pd.DataFrame()\n",
    "ThisYearData_actualData_train[\"FIELD_1\"] = xtrain.FIELD_1_x.values\n",
    "ThisYearData_actualData_train[\"FIELD_2\"] = xtrain.FIELD_2_x.values\n",
    "ThisYearData_actualData_train[\"L100700\"] = xtrain.L100700_x.values\n",
    "ThisYearData_actualData_train[\"S000300\"] = xtrain.S000300_x.values\n",
    "ThisYearData_actualData_train[\"L101700\"] = xtrain.L101700_x.values\n",
    "ThisYearData_actualData_train[\"L100800\"] = xtrain.L100800_x.values\n",
    "ThisYearData_actualData_train[\"L103300\"] = xtrain.L103300_x.values\n",
    "\n",
    "ThisYearData_actualData_train[\"L103100\"] = xtrain.L103100_x.values\n",
    "# ThisYearData_actualData_train[\"L102900\"] = xtrain.L102900_x.values\n",
    "# ThisYearData_actualData_train[\"L103200\"] = xtrain.L103200_x.values\n",
    "\n",
    "\n",
    "ThisYearData_actualData_train[\"FIELD_33\"] = xtrain.FIELD_33_x.values\n",
    "ThisYearData_actualData_train[\"FIELD_38\"] = xtrain.FIELD_38_x.values\n",
    "ThisYearData_actualData_train[\"FIELD_40\"] = xtrain.FIELD_40_x.values\n",
    "ThisYearData_actualData_train[\"SEX\"] = xtrain.SEX_x.values\n",
    "ThisYearData_actualData_train[\"AGE\"] = xtrain.AGE_x.values\n",
    "\n",
    "\n",
    "ThisYearData_actualData_train[\"L102900\"] = ytrain.L102900_y.values\n",
    "ThisYearData_actualData_train[\"L103200\"] = ytrain.L103200_y.values\n",
    "ThisYearData_actualData_train[\"L103000\"] = ytrain.L103000_y.values\n",
    "ThisYearData_actualData_train[\"L103300\"] = ytrain.L103300_y.values\n",
    "\n",
    "_class = []\n",
    "for i in range(ThisYearData_actualData_train.shape[0]):\n",
    "    if((ThisYearData_actualData_train.L102900[i] <= 200) & \n",
    "       (ThisYearData_actualData_train.L103200[i] <= 130) & \n",
    "       (ThisYearData_actualData_train.L103000[i] <=150)):\n",
    "        _class.append(0)\n",
    "    else:\n",
    "        _class.append(1)\n",
    "ThisYearData_actualData_train[\"CLASS\"] = _class \n",
    "\n",
    "\n",
    "\n",
    "ThisYearData_actualData_train.to_csv(\"ThisYearData_actualData_train.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
